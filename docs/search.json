[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Többváltozós statisztika jamovi-ban és R-ben",
    "section": "",
    "text": "Előszó\nA statisztika alapfogalmai nagyon jól szemléltethetők az egyváltozós statisztikai eljárásokkal. Ezek az eljárások tipikusan egy (vagy két) változó vizsgálatával járulnak hozzá az empirikus vizsgálatok során felmerülő statisztikai jellegű kérdések megválaszolásához.\nA kutatómunka során azonban szükség lehet egyszerre több változó bevonására az elemzésbe, ezeket az eljárásokat többváltozós statisztikai eljárásoknak nevezzük. Ilyen eljárás például:\n\nLineáris regresszió (1)\nFőkomponens elemzés (2)\nMegbízhatóság elemzés (3)\nFeltáró faktorelemzés (4)\nMegerősítő faktorelemzés (5)\nTöbbszempontos varianciaelemzés (6)\nKlaszterelemzés (7)\nDiszkriminancia elemzés (8)\nTöbbváltozós varianciaelemzés (9)\nLogisztikus regresszióelemzés (10)\nTöbbdimenziós skálázás (11)\n\nA jegyzet elkészítéséhez elsősorban a kurzus tankönyvét (Münnich és mtsai., 2006) használtuk fel, de támaszkodtunk egyéb forrásokra is (Csallner, 2015; Ketskeméty és Izsó, 2005; Malhotra és Simon, 2008; Moksony, 2006; Sajtos és Mitev, 2007; Székelyi és Barna, 2002; Takács, 2017; Varga, 2019).\n\n\n\n\nCsallner, A. E. (2015). Bevezetés az SPSS statisztikai programcsomag használatába. http://www.jgypk.hu/tamop15e/tananyag_html/spss/index.html\n\n\nKetskeméty, L. és Izsó, L. (2005). Bevezetés az SPSS programrendszerbe - Módszertani útmutató és feladatgyűjtemény statisztikai elemzésekhez. ELTE Eötvös Kiadó.\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó.\n\n\nMoksony, F. (2006). Gondolatok és adatok. Társadalomtudományi elméletek empirikus ellenőrzése. Aula Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési kézikönyv. Alinea Kiadó.\n\n\nSzékelyi, M. és Barna, I. (2002). Túlélőkészlet az SPSS-hez. Többváltozós elemzési technikáról társadalomkutatók számára. Typotex Kiadó.\n\n\nTakács, S. (2017). Bevezetés a matematikai statisztikába 2. Többváltozós statisztikai módszerek. Antarész Kiadó.\n\n\nVarga, A. (2019). Többváltozós statisztika dióhéjban: Változó-orientált módszerek. Pólya Kiadó."
  },
  {
    "objectID": "sec_linearis_regresszio.html#egyszerű-lineáris-regresszió",
    "href": "sec_linearis_regresszio.html#egyszerű-lineáris-regresszió",
    "title": "1  Lineáris regresszió",
    "section": "1.1 Egyszerű lineáris regresszió",
    "text": "1.1 Egyszerű lineáris regresszió\nAz egyszerű lineáris regressziós modell: \\(Y=\\beta_0+β_1 X+\\epsilon\\), amely egy egyenessel (regressziós egyenes) írja le a két változó függvényszerű kapcsolatát, ahol\n\n\\(\\beta_0\\) – tengelymeszet, a regressziós egyenes itt metszi az y tengelyt\n\\(\\beta_1\\) – meredekség, a regressziós egyenes és az x tengely szögének tangense\n\\(\\epsilon\\) – hibatag, amelyről feltételezzük, hogy normális eloszlású 0 várható értékkel.\n\nA \\(\\beta_0\\) és \\(\\beta_1\\) populációbeli paramétereket a minta alapján becsüljük a legkisebb négyzetek módszere segítségével, így kapjuk a \\(b_0\\) és \\(b_1\\) becsléseket.\nA regressziós egyenes birtokában tetszőleges \\(X\\) értékhez tudunk \\(Y\\) értéket előre jelezni, vagyis jósolni bizonyos hibával: \\(\\hat{Y}=b_0+b_1 X\\).\nPéldául egy fiktív adatbázison vizsgálhatjuk a fizetés és a munkahellyel való elégedettség kapcsolatát (Münnich és mtsai., 2006).\n\nd <- rio::import(file = \"adat/lin_reg_fizetes_elegedettseg_02.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  2 variables:\n#>  $ fizetes     : num  44 66 89 155 130\n#>  $ elegedettseg: num  30 45 60 100 85\nd\n#>   fizetes elegedettseg\n#> 1      44           30\n#> 2      66           45\n#> 3      89           60\n#> 4     155          100\n#> 5     130           85\n\n\nlm_1 <- lm(elegedettseg ~ fizetes, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes, data = d)\n#> \n#> Residuals:\n#>       1       2       3       4       5 \n#> -0.8423  0.3420  0.8983 -0.5488  0.1508 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3.210890   0.931791   3.446   0.0411 *  \n#> fizetes     0.627987   0.008873  70.774 6.22e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8077 on 3 degrees of freedom\n#> Multiple R-squared:  0.9994, Adjusted R-squared:  0.9992 \n#> F-statistic:  5009 on 1 and 3 DF,  p-value: 6.216e-06\n\nJamovi-ban a Regression / Linear Regression menüpontot kell használnunk.\n\n\n\nFizetés és elégedettésg kapcsolata (N=5): együtthatók\n\n\nA fenti elemzés alapján például a \\(\\hat{Y}=b_0+b_1 X\\) konkrét formája:\nbecsült elégedettség = 3,211+ 0,628 * fizetés\n\nA \\(b_0\\) értelmezése: a zérus \\(X\\)-hez tartozó \\(Y\\) érték.\nA \\(b_1\\) értelmezése: az \\(X\\) egy egységnyi növekedéséhez ilyen nagyságú \\(Y\\) változás tartozik.\n\nTudjuk, hogy az \\(r_{XY}\\) Pearson-féle korrelációs együttható, az \\(X\\) és \\(Y\\) változók közötti kapcsolat erősségét és irányát mutatja meg. A \\(b_1\\) és \\(r_{XY}\\) kapcsolatban áll:\n\nazonos az előjelük,\naz \\(X\\) egy szórásnyi növekedéséhez tartozó \\(Y\\) változás megegyezik az \\(Y\\) szórásának \\(r_{XY}\\) szeresével (rövidebben, a populációbeli paraméterekkel megfogalmazva: \\(\\beta_1=\\frac{\\sigma_Y}{\\sigma_X}\\rho_{XY}\\)\n\nA determinációs együttható (\\(R^2\\)) a korrelációs együttható négyzete \\((R^2=r_{XY}^2)\\), amely szimmetrikus mutató, megmutatja, hogy \\(Y\\) varianciájának mekkora hányadát magyarázza \\(X\\) varianciája, vagy fordítva, \\(X\\) varianciájának mekkora hányadát magyarázza \\(Y\\) varianciája.\nA fenti példában látható, hogy 99%-ban lehet a függő változó varianciáját magyarázni a független változóval (az arányt legtöbbször százalékos formában adjuk meg).\n\nsummary(lm_1)$r.squared\n#> [1] 0.9994014\n\n\n\n\nFizetés és elégedettésg kapcsolata (N=5): determinációs együttható\n\n\nA \\(\\beta_0\\) és \\(\\beta_1\\) együtthatók értékét hipotézisvizsgálatokkal vizsgálhatjuk:\n\n\\(H_0\\): \\(\\beta_0=0\\), \\(H_1: \\beta_0 \\neq 0\\) Kérdés: origón átmenő a regresszió? (\\(H_0\\) megtartása esetén igen)\n\\(H_0\\): \\(\\beta_1=0\\), \\(H_1: \\beta_1 \\neq 0\\) Kérdés: \\(Y\\) függ \\(X\\)-től? (\\(H_1\\) elfogadása esetén igen)\n\nA példában látható, hogy nem origón átmenő a regresszió, és az elégedettség függ a fizetéstől.\n\nsummary(lm_1)$coefficients\n#>              Estimate  Std. Error   t value     Pr(>|t|)\n#> (Intercept) 3.2108896 0.931790852  3.445934 4.105805e-02\n#> fizetes     0.6279867 0.008873152 70.773796 6.216433e-06\n\n\n\n\nFizetés és elégedettésg kapcsolata (N=5): hipotézisvizsgálat az együtthatókra"
  },
  {
    "objectID": "sec_linearis_regresszio.html#többszörös-lineáris-regresszió",
    "href": "sec_linearis_regresszio.html#többszörös-lineáris-regresszió",
    "title": "1  Lineáris regresszió",
    "section": "1.2 Többszörös lineáris regresszió",
    "text": "1.2 Többszörös lineáris regresszió\nA többszörös lineáris regressziós modell: \\(Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\dots + \\beta_r X_r+\\epsilon\\).\nMíg az egyszerű lineáris regresszió esetén a regressziós egyenes írta le a két változó kapcsolatát, a többszörös lineáris regresszió esetén a lineáris függvény egy \\(r\\) dimenziós sík az \\(r+1\\) dimenziós térben.\nAz egyes \\(\\beta_i\\) együtthatók becslése itt is a legkisebb négyzetek elve alapján történik, így kapjuk a \\(b_0, b_1, \\dots, b_r\\) becsléseket.\nA lineáris függvény birtokában tetszőleges \\(X_1,X_2,\\dots,X_r\\) értékekhez tudunk \\(Y\\) értéket előre jelezni, vagyis jósolni bizonyos hibával: \\(\\hat{Y}=b_0+b_1 X_1+\\dots+ b_r X_r\\).\n\nd <- rio::import(file = \"adat/lin_reg_fizetes_eletkor_elegedettseg_01.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  3 variables:\n#>  $ fizetes     : num  44 66 89 155 130\n#>  $ eletkor     : num  25 65 21 35 40\n#>  $ elegedettseg: num  37 36 61 92 76\nd\n#>   fizetes eletkor elegedettseg\n#> 1      44      25           37\n#> 2      66      65           36\n#> 3      89      21           61\n#> 4     155      35           92\n#> 5     130      40           76\n\n\nlm_1 <- lm(elegedettseg ~ fizetes + eletkor, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes + eletkor, data = d)\n#> \n#> Residuals:\n#>        1        2        3        4        5 \n#>  0.28596  0.08556 -0.30015  0.71047 -0.78184 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 21.508055   1.292166   16.64  0.00359 ** \n#> fizetes      0.519198   0.008847   58.69  0.00029 ***\n#> eletkor     -0.305549   0.023279  -13.12  0.00575 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8047 on 2 degrees of freedom\n#> Multiple R-squared:  0.9995, Adjusted R-squared:  0.9989 \n#> F-statistic:  1841 on 2 and 2 DF,  p-value: 0.000543\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): együtthatók\n\n\nA fenti példában a lineáris regresszió futtatása után azt mondhatjuk:\nbecsült elégedettség = 21,05 -0,306*életkor + 0,519*fizetés\nMás szavakkal a fizetés tekintetében a magasabb fizetés nagyobb mértékű elégedettséggel jár, addig az életkor esetében az évek számának növekedése a munkahellyel való elégedetlenséget vonja maga után.\n\nA \\(b_0\\) értelmezése: a csupa zérus \\(X_1, X_2,\\dots,X_r\\)-ekhez tartozó \\(Y\\) érték.\nA \\(b_i\\) \\((i=1,\\dots,r)\\) értelmezése: az \\(X_i\\) hatása úgy, hogy a többi független változót is figyelembe vesszük.\n\nA fenti többszörös lineáris regressziós együtthatók nem alkalmasak az egyes magyarázó változóktól való függés erősségének mérésére, ugyanis a nagyságuk függ a változó értékeinek nagyságától is. Ezért a standard lineáris regressziós együtthatókat használjuk, amelyek már mértékegység nélküli, egymással összehasonlítható arányszámok, így abszolút értékeiket összevetve megtudhatjuk, milyen relatív fontossággal bírnak az egyes független változók a függő változó magyarázásában.\n\nlsr::standardCoefs(lm_1)\n#>                  b       beta\n#> fizetes  0.5191980  0.9677518\n#> eletkor -0.3055489 -0.2164358\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): standardizált együtthatók\n\n\nA fenti példában láthatjuk, hogy a fizetés erősebb kapcsolatban van az elégedettséggel, hiszen a standardizált együtthatójának értéke abszolút értékben nagyobb, mint az életkor standardizált együtthatójának abszolút értéke.\nTöbbszörös lineáris regresszió esetén több hipotézisvizsgálat végezhető:\n\nminden együtthatót külön tesztelhetünk t-próbákkal \\((n-r-1)\\) szabadsági fokkal\n\n\\(H_0:\\beta_i=0\\), \\(H_1:\\beta_i\\neq0\\), \\(i=1,\\dots,r\\) Kérdés: \\(Y\\) függ \\(X_i\\)-től? (\\(H_1\\) elfogadása esetén igen)\n\na teljes modellt tesztelhetjük F-próbával \\((r,n-r-1)\\) szabadsági fokkal\n\n\\(H_0: \\text{minden } \\beta_i=0\\), \\(H_1: \\text{van olyan i, melyre } \\beta_i\\neq0\\) Kérdés: a modell bír valamilyen bejósló erővel? (\\(H_1\\) elfogadása esetén igen)\n\n\n\nsummary(lm_1)$coefficients\n#>               Estimate Std. Error   t value     Pr(>|t|)\n#> (Intercept) 21.5080549 1.29216584  16.64496 0.0035899688\n#> fizetes      0.5191980 0.00884672  58.68819 0.0002902081\n#> eletkor     -0.3055489 0.02327903 -13.12550 0.0057544940\nsummary(lm_1)$fstatistic\n#>    value    numdf    dendf \n#> 1840.547    2.000    2.000\npf(q = summary(lm_1)$fstatistic[1], df1 = summary(lm_1)$fstatistic[2],\n    df2 = summary(lm_1)$fstatistic[3], lower.tail = F)\n#>        value \n#> 0.0005430217\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): hipotézisvizsgálatok\n\n\nA lenti példában látható, hogy mindkét magyarázó változótól függ az elégedettség (életkor p-értéke: 0,006, a fizetés p-értéke p < 0,001), és a teljes modell bír magyarázó erővel (p-érték: p < 0,001).\nA függő változó és a független változók közötti korreláció erősségének leírására több mennyiséget használhatunk\n\ntöbbszörös korrelációs együttható: \\(R\\), amely a függő változó és a becsült értékek közötti korrelációs együttható értékével egyezik meg, azaz \\(R(Y,X_1,X_2,…,X_r )=R(Y,\\hat{Y})\\). Valójában a lineáris regresszió ennek a korrelációs együtthatónak az értékét maximalizálja, mikor az \\(\\hat{Y}\\)-t \\(X\\)-ek speciális lineáris kombinációjaként előállítja.\ntöbbszörös determinációs együttható: \\(R^2\\), amely a többszörös korrelációs együttható négyzete, és megmutatja, hogy a magyarázó változók a függő változó ingadozásának hányad részét magyarázzák.\nkorrigált determinációs együttható: \\(R_{adj}^2\\), amely kiküszöböli az \\(R^2\\) azon tulajdonságát, hogy a magyarázó változók számának növekedésével, függetlenül azok hatásától, nő az értéke. Így alkalmas több modell esetén a magyarázó erők összehasonlítására, akkor is, ha azok eltérő számú független változót használnak.\n\n\nsummary(lm_1)$r.squared\n#> [1] 0.999457\nsummary(lm_1)$adj.r.squared\n#> [1] 0.998914\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): magyarázó erő\n\n\nA fenti példában látható mindhárom fenti mutató. Az \\(R_{adj}^2\\) leolvasásával láthatjuk, hogy a két független változó, az életkor és a fizetés a függő változó 99%-át magyarázza."
  },
  {
    "objectID": "sec_linearis_regresszio.html#parciális-korrelációs-együttható",
    "href": "sec_linearis_regresszio.html#parciális-korrelációs-együttható",
    "title": "1  Lineáris regresszió",
    "section": "1.3 Parciális korrelációs együttható",
    "text": "1.3 Parciális korrelációs együttható\nParciális korrelációs együttható: két változó (\\(S_1,S_2\\)) közötti korreláció mértéke, miután változók egy halmazának \\((T_1,T_2,\\dots,T_g)\\) a két változó korrelációjára vonatkozó hatását többszörös lineáris regresszióval kiküszöböljük:\n\n\\(R( S_1,S_2 |T_1,T_2,\\dots,T_g )= R(S_1- \\hat{S_1},S_2- \\hat{S_2})\\), ahol \\(\\hat{S_1}\\) és \\(\\hat{S_2}\\) az \\(S_1\\) és \\(S_2\\) változó többszörös lineáris regresszióból származó becslése a \\(T_1,T_2,\\dots,T_g\\) magyarázó változók esetén.\n\n\nd <- rio::import(file = \"adat/lin_reg_intelligencia_testmagassag_eletkor_01.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  3 variables:\n#>  $ intelligencia: num  81 86 91 101 111\n#>  $ testmagassag : num  138 145 156 163 167\n#>  $ eletkor      : num  9 12 14 18 22\nd\n#>   intelligencia testmagassag eletkor\n#> 1            81          138       9\n#> 2            86          145      12\n#> 3            91          156      14\n#> 4           101          163      18\n#> 5           111          167      22\n\n\ncor.test(d$intelligencia, d$testmagassag)\n#> \n#>  Pearson's product-moment correlation\n#> \n#> data:  d$intelligencia and d$testmagassag\n#> t = 5.4629, df = 3, p-value = 0.01205\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  0.4463631 0.9970093\n#> sample estimates:\n#>      cor \n#> 0.953235\nRcmdrMisc::partial.cor(d, tests = T)\n#> \n#>  Partial correlations:\n#>               intelligencia testmagassag eletkor\n#> intelligencia       0.00000     -0.46317 0.97875\n#> testmagassag       -0.46317      0.00000 0.62856\n#> eletkor             0.97875      0.62856 0.00000\n#> \n#>  Number of observations: 5 \n#> \n#>  Pairwise two-sided p-values:\n#>               intelligencia testmagassag eletkor\n#> intelligencia               0.5368       0.0213 \n#> testmagassag  0.5368                     0.3714 \n#> eletkor       0.0213        0.3714              \n#> \n#>  Adjusted p-values (Holm's method)\n#>               intelligencia testmagassag eletkor\n#> intelligencia               0.7429       0.0638 \n#> testmagassag  0.7429                     0.7429 \n#> eletkor       0.0638        0.7429\n\n A fenti példában látható, hogy míg szignifikáns erős pozitív kapcsolat van az intelligencia és a magasság között (korrelációs együttható: \\(r=0,95; p=0,012\\)), ez a kapcsolat eltűnik, ha figyelembe vesszük az életkor változót is (parciális korreláció: \\(r_{par}=-0,46; p=0,537\\)). Vagyis sikerült az intelligencia és a testmagasság közötti kapcsolat erősségét megállapítani, miközben az életkor hatását erre a kapcsolatra kiküszöböltük.\nA többszörös lineáris regressziós modell \\((Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\dots+\\beta_r X_r+\\epsilon)\\) becsült paraméterei \\((b_1,b_2,…,b_r)\\) nagyban hasonlítanak a parciális korrelációs együtthatókra, mivel minden \\(b_i\\) az \\(Y\\) és \\(X_i\\) közötti kapcsolat erősségét írja le, miközben a többi magyarázó változó (\\(X_1,X_2,\\dots,X_r\\), összesen \\((r-1)\\) db, \\(X_i\\) nincs köztük) hatását kiküszöböljük a két változó korrelációjából.\nA parciális korrelációs együtthatók és a többszörös lineáris regresszió együtthatói között annyira közvetlen a kapcsolat, hogy azonos p-érték tartozik hozzájuk, mint a lenti példában ez látható is lesz.\nA lenti példában két modell szerepel, először az intelligencia és a testmagasság függvényszerű kapcsolatát vizsgáljuk és azt a meglepő dolgot tapasztaljuk, hogy minél magasabb valaki, annál intelligensebb \\((p=0,012)\\), majd ha bevonjuk az életkor változót, akkor azt tapasztalhatjuk, hogy eltűnik az intelligencia és a testmagasság közötti kapcsolat \\((p=0,537)\\).\n\nlm_1 <- lm(intelligencia ~ testmagassag, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = intelligencia ~ testmagassag, data = d)\n#> \n#> Residuals:\n#>       1       2       3       4       5 \n#>  1.9228  0.3114 -5.0779 -1.6892  4.5328 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)  \n#> (Intercept)  -51.2613    26.6569  -1.923   0.1502  \n#> testmagassag   0.9445     0.1729   5.463   0.0121 *\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 4.202 on 3 degrees of freedom\n#> Multiple R-squared:  0.9087, Adjusted R-squared:  0.8782 \n#> F-statistic: 29.84 on 1 and 3 DF,  p-value: 0.01205\nlm_2 <- lm(intelligencia ~ testmagassag + eletkor, data = d)\nsummary(lm_2)\n#> \n#> Call:\n#> lm(formula = intelligencia ~ testmagassag + eletkor, data = d)\n#> \n#> Residuals:\n#>        1        2        3        4        5 \n#>  0.89121 -1.16330 -0.09995  0.21170  0.16034 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)  \n#> (Intercept)   73.1026    19.6042   3.729   0.0650 .\n#> testmagassag  -0.1210     0.1637  -0.739   0.5368  \n#> eletkor        2.6338     0.3902   6.750   0.0213 *\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.055 on 2 degrees of freedom\n#> Multiple R-squared:  0.9962, Adjusted R-squared:  0.9923 \n#> F-statistic: 259.3 on 2 and 2 DF,  p-value: 0.003841\n\n\n\n\nAz intelligencia és a testmagasság kapcsolata (N=5): két modell, életkor nélkül és életkorral"
  },
  {
    "objectID": "sec_linearis_regresszio.html#a-többszörös-lineáris-regresszió-esetei",
    "href": "sec_linearis_regresszio.html#a-többszörös-lineáris-regresszió-esetei",
    "title": "1  Lineáris regresszió",
    "section": "1.4 A többszörös lineáris regresszió esetei",
    "text": "1.4 A többszörös lineáris regresszió esetei\n\n1.4.1 Egyetlen dichotóm magyarázó változó\nA magyarázó változóink eddig kvantitatívak voltak, de kategorikus változók is lehetnek. Ha a kategorikus változónk csupán 2 értékű, akkor a becsült (\\(b_0\\), \\(b_1\\)) együtthatók értelmezése módosul. A tengelymetszet (\\(b_0\\)) a kategorikus változó referencia szintjén a függő változó átlagát tartalmazza, míg a (\\(b_1\\)) a kategorikus változó másik szintjén számolt átlag eltérését a \\(b_0\\)-hoz képest.\n\nd <- rio::import(file = \"adat/lin_reg_magassag_hajhossz_nem_01.xlsx\")\nd$nem <- factor(d$nem, levels = c(\"nő\", \"férfi\"))\nstr(d)\n#> 'data.frame':    6 obs. of  3 variables:\n#>  $ magassag: num  158 159 162 170 182 179\n#>  $ hajhossz: num  28 25 20 1 1.5 3\n#>  $ nem     : Factor w/ 2 levels \"nő\",\"férfi\": 1 1 1 2 2 2\nd\n#>   magassag hajhossz   nem\n#> 1      158     28.0    nő\n#> 2      159     25.0    nő\n#> 3      162     20.0    nő\n#> 4      170      1.0 férfi\n#> 5      182      1.5 férfi\n#> 6      179      3.0 férfi\n\n\nlm_1 <- lm(magassag ~ nem, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = magassag ~ nem, data = d)\n#> \n#> Residuals:\n#>       1       2       3       4       5       6 \n#> -1.6667 -0.6667  2.3333 -7.0000  5.0000  2.0000 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  159.667      2.687  59.413 4.81e-07 ***\n#> nemférfi      17.333      3.801   4.561   0.0103 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 4.655 on 4 degrees of freedom\n#> Multiple R-squared:  0.8387, Adjusted R-squared:  0.7984 \n#> F-statistic:  20.8 on 1 and 4 DF,  p-value: 0.01033\n\n\n\n\nA magasság és a nem kapcsolata\n\n\nA fenti példa a nem hatását vizsgálja testmagasságra. A p-érték alapján ez a hatás szignifikáns, tehát a függés fennáll, a paraméterek pedig a nők átlagáról \\((b_0=159,67)\\) és a férfiak és nők átlagának eltéréséről tájékoztatnak \\((b_1=17,33)\\)."
  },
  {
    "objectID": "sec_linearis_regresszio.html#modellválasztás",
    "href": "sec_linearis_regresszio.html#modellválasztás",
    "title": "1  Lineáris regresszió",
    "section": "1.5 Modellválasztás",
    "text": "1.5 Modellválasztás\nElőfordulhat, hogy egy jelenség vizsgálatakor több lineáris regressziós modellt is meg tudunk fogalmazni, nem csak egyetlen modell létezik. Ez a probléma leggyakrabban úgy jelenik meg, hogy rengeteg független változónk van, és nem tudjuk eldönteni, hogy elég egy kisebb modell, néhány változóval, vagy vegyük inkább a nagyobb modellt több változóval.\nA megfelelő modell megtaláláshoz a modelleket összehasonlíthatjuk F-próba segítségével, szignifikáns eredmény esetén a két modell magyarázó ereje eltér egymástól. Ilyenkor a célunk a legszűkebb (legkevesebb magyarázó változót tartalmazó), de a legbővebbtől szignifikánsan nem különböző modell megtalálása.\nA korrigált determinációs együttható \\((R_{adj}^2)\\) is alkalmas mód a modellek összehasonlítására: az 1-hez legközelebbi értékkel bíró modell rendelkezik a legnagyobb magyarázó erővel. Léteznek már kritériumok is:\n\nAIC (Akaike-kritérium): minél kisebb az AIC értéke, annál nagyobb a modell magyarázó ereje.\nBIC (Bayes-kritérium): minél kisebb a BIC értéke, annál nagyobb a modell magyarázó ereje.\nRMSE (négyzetes középérték, Root Mean Square Error) az a mennyiség, amennyivel a vizsgált értékek eltérnek az előre megbecsült értékektől. Minél kisebb ez az érték, annál jobban becsül a modell.\n\n\nd <- rio::import(file = \"adat/lin_reg_fizetes_eletkor_elegedettseg_01.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  3 variables:\n#>  $ fizetes     : num  44 66 89 155 130\n#>  $ eletkor     : num  25 65 21 35 40\n#>  $ elegedettseg: num  37 36 61 92 76\nd\n#>   fizetes eletkor elegedettseg\n#> 1      44      25           37\n#> 2      66      65           36\n#> 3      89      21           61\n#> 4     155      35           92\n#> 5     130      40           76\n\n\nlm_1 <- lm(elegedettseg ~ fizetes, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes, data = d)\n#> \n#> Residuals:\n#>      1      2      3      4      5 \n#>  4.249 -8.272  4.684  1.123 -1.785 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)   \n#> (Intercept)  9.71048    7.07562   1.372  0.26355   \n#> fizetes      0.52365    0.06738   7.772  0.00443 **\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 6.134 on 3 degrees of freedom\n#> Multiple R-squared:  0.9527, Adjusted R-squared:  0.9369 \n#> F-statistic:  60.4 on 1 and 3 DF,  p-value: 0.004432\nlm_2 <- lm(elegedettseg ~ fizetes + eletkor, data = d)\nsummary(lm_2)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes + eletkor, data = d)\n#> \n#> Residuals:\n#>        1        2        3        4        5 \n#>  0.28596  0.08556 -0.30015  0.71047 -0.78184 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 21.508055   1.292166   16.64  0.00359 ** \n#> fizetes      0.519198   0.008847   58.69  0.00029 ***\n#> eletkor     -0.305549   0.023279  -13.12  0.00575 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8047 on 2 degrees of freedom\n#> Multiple R-squared:  0.9995, Adjusted R-squared:  0.9989 \n#> F-statistic:  1841 on 2 and 2 DF,  p-value: 0.000543\nanova(lm_1, lm_2)\n#> Analysis of Variance Table\n#> \n#> Model 1: elegedettseg ~ fizetes\n#> Model 2: elegedettseg ~ fizetes + eletkor\n#>   Res.Df     RSS Df Sum of Sq      F   Pr(>F)   \n#> 1      3 112.864                                \n#> 2      2   1.295  1    111.57 172.28 0.005754 **\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nperformance::model_performance(lm_1)\n#> # Indices of model performance\n#> \n#> AIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n#> ------------------------------------------------------------\n#> 35.773 | 59.773 | 34.601 | 0.953 |     0.937 | 4.751 | 6.134\nperformance::model_performance(lm_2)\n#> # Indices of model performance\n#> \n#> AIC    | AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n#> ----------------------------------------------------------\n#> 15.436 |  Inf | 13.873 | 0.999 |     0.999 | 0.509 | 0.805\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): modellek összehasonlítása\n\n\nA fenti példán látható, hogy két modellt építettünk. Az 1. modell az elégedettséget a fizetés segítségével próbálja jósolni. A 2. modell az elégedettséget a fizetéssel és az életkorral. Láthatjuk a 2. modell szignifikánsan eltér magyarázó erőben a az 1. modelltől, valamint a modell “jóságát” leíró mutatók mindegyike kedvezőbb a 2. modell esetén: \\(R_{adj}^2\\), \\(AIC\\), \\(BIC\\), \\(RMSE\\)."
  },
  {
    "objectID": "sec_linearis_regresszio.html#alkalmazási-feltételek",
    "href": "sec_linearis_regresszio.html#alkalmazási-feltételek",
    "title": "1  Lineáris regresszió",
    "section": "1.6 Alkalmazási feltételek",
    "text": "1.6 Alkalmazási feltételek\nA regressziós modellt ne használjuk, ha az alkalmazási feltételek valamelyike nem teljesül. Melyek ezek?\n\nKiugró értékek. A kiugró értékek torzítják a regresszió eredményét, így lehetőség szerint az ilyen eseteket ki kell szűrnünk. Szűrésük történhet a Cook-féle távolság segítégével. A Cook-féle távolság egy eset általános hatását méri a modellre. A Cook-féle távolságnál a 4/N-nél nagyobb értékek jelenthetnek problémát. A megjelölt esetek így kiszűrésre kerülnek az adatbázisból.\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): kiugró értékek vizsgálata\n\n\n\nMultikollinearitás. A multikollinearitás a független változók közötti erős korrelációra utal. Multikollinearitás bizonytalanná teszi és korlátozza a modell magyarázó erejét, bizonyos esetekben a regressziós számítást el sem lehet végezni. Ki lehet szűrni a multikollinearitásban érintett változókat a variancianövelő tényezők (variance inflation factor, VIF) és a tolerancia értékek elemzésével. Ha legnagyobb VIF érték tíznél nagyobb, illetve ha az átlagos VIF érték jelentősen nagyobb, mint egy, akkor az problémát jelenthet. A tolerancia értékek gyakorlatilag a VIF értékek reciprok értékei (1/VIF). Az érintett változókat kihagyhatjuk a modellből, vagy származtatott adatokkal dolgozunk tovább (például főkomponens elemzéssel nyert adatokkal).\n\nA VIF megmutatja a becsült regressziós együttható varianciája „felfújódásának” mértékét a hibatag varianciájához viszonyítva. A mutató értéke bármilyen nagy lehet. A tolerancia mutató megmutatja, hogy a magyarázóváltozó szórásnégyzetének mekkora része nem magyarázható együttesen a többi magyarázó változóval. Ennek értéke nulla és egy közé esik. Minél nagyobb a multikollinearitás mértéke annál közelebb van a mutató értéke a nullához.\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): multikollinearitás vizsgálata\n\n\n\nHomoszkedaszticitás. A homoszkedaszticitás azt jelenti, hogy az eltérésváltozók varianciája állandó és független kell legyen, tehát a függő változó szórásának minden esetben ugyanannyinak kell lennie, függetlenül a független változóktól. Ha a Breusch-Pagan próba nem szignifikáns, akkor a homoszkedaszticitási előfeltétel teljesül.\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): homoszkedaszticitás vizsgálata\n\n\n\nAutokorreláció. A hibatagok szignifikáns együttmozgása az autokorreláció.A lineáris regresszió szempontjából fontos, hogy a hibatagok (reziduálisok) (vagyis a függő változó azon része, amit a független változók nem magyaráznak) ne korreláljanak egymással. Az autokorrelációt a Durbin-Watson próbával lehet ellenőrizni. A próba nullhipotézisének megtartása zat jelenti, hogy a hibatagokat nem tekintjük autokorreláltnak. (A Durbin-Watson próba esetében az egynél kisebb, illetve a háromnál nagyobb DW próbastatisztika értékek jelenthetnek problémát, a kettő közeli értékek kívánatosak.)\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): autokorreláció vizsgálata\n\n\n\nReziduálisok normális eloszlása. A reziduális normális eloszlását a szokásos próbákkal és a QQ-ábrával is ellenőrizhetjük.\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): reziduális normális eloszlása"
  },
  {
    "objectID": "sec_linearis_regresszio.html#példa-befolyásolja-e-a-munkahellyel-való-elégedettséget-a-fizetés-nagysága-és-az-életkor",
    "href": "sec_linearis_regresszio.html#példa-befolyásolja-e-a-munkahellyel-való-elégedettséget-a-fizetés-nagysága-és-az-életkor",
    "title": "1  Lineáris regresszió",
    "section": "1.7 Példa: Befolyásolja-e a munkahellyel való elégedettséget a fizetés nagysága és az életkor?",
    "text": "1.7 Példa: Befolyásolja-e a munkahellyel való elégedettséget a fizetés nagysága és az életkor?\n\nA példa forrása: Münnich és mtsai. (2006, o. 1.6.1 probléma)\nKapcsolódó jamovi állomány: lin_reg_elegedettseg.omv\n\n\nd <- rio::import(file = \"adat/lin_reg_elegedettseg.xlsx\")\nstr(d)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ fizetes     : num  109 125 98 124 115 132 124 99 165 187 ...\n#>  $ elegedettseg: num  69.2 90.8 71 90.1 77.8 ...\n#>  $ kor         : num  20 46.3 36.2 46 31 ...\n#>  $ nem         : chr  \"nő\" \"férfi\" \"nő\" \"férfi\" ...\npsych::headTail(d)\n#>     fizetes elegedettseg   kor   nem\n#> 1       109        69.15    20    nő\n#> 2       125        90.85 46.33 férfi\n#> 3        98        71.04  36.2    nő\n#> 4       124        90.12 45.95 férfi\n#> ...     ...          ...   ...  <NA>\n#> 27      129        96.32    53 férfi\n#> 28      135        97.86  49.4 férfi\n#> 29      145          100  46.9 férfi\n#> 30      120        81.08    32 férfi\n\n\nlm_1 <- lm(elegedettseg ~ fizetes + kor, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes + kor, data = d)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -10.248  -1.543   1.188   2.437   4.333 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  8.13712    3.26797   2.490   0.0192 *  \n#> fizetes      0.44404    0.02321  19.128  < 2e-16 ***\n#> kor          0.53361    0.07127   7.487 4.71e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 3.59 on 27 degrees of freedom\n#> Multiple R-squared:  0.953,  Adjusted R-squared:  0.9496 \n#> F-statistic: 273.9 on 2 and 27 DF,  p-value: < 2.2e-16\nlsr::standardCoefs(lm_1)\n#>                 b      beta\n#> fizetes 0.4440418 0.8322319\n#> kor     0.5336111 0.3257287\n\n\n\n\nElégedettség kapcsolata a fizetéssel és lektkorra (N=30)\n\n\nA fenti outputból láthatjuk, hogy a fizetés és a kor változó is szignifikánsan befolyásolja az elégedettséget, hiszen a hozzájuk tartozó szignifikanciaszint \\(p<0,05\\). A teljes modell vonatkozó F-próba is szignifikáns. A fizetés változó együtthatója \\((b_1)\\) 0,44, a kor változó együtthatója \\((b_2)\\) pedig 0,53, ami arra utal, hogy pozitív kapcsolat van a változó között: minél magasabb a fizetés, és minél idősebbek az emberek, annál elégedettebbek a munkahelyükkel.\nA pontos becslés a regressziós egyenlet alapján a következőképpen fest:\nelégedettség = 8,14 + 0,44 * fizetés + 0,53 * kor\nMivel a többszörös regresszió esetében a független változók hatása csak a standardizált együtthatók mentén hasonlítható össze, így kiszámoltuk a standardizált együtthatókat is. Az adatok jól példázzák, hogy miért fontos a standardizált együtthatókat is vizsgálni, hiszen a nem standardizált együtthatók esetén a kor változó együtthatójának értéke a magasabb, míg a standardizált értékeknél fordítva. Vagyis, ha az egyes változók relatív fontosságának vizsgálatakor nem nézzük a dimenziómentes értékeket, akkor könnyen téves következtetésre juthatunk.\nA négyzetes korrelációs együttható értéke 0,9, ami arra utal, hogy a független változók igen jól magyarázzák a függő változót."
  },
  {
    "objectID": "sec_linearis_regresszio.html#példa-befolyásolja-e-a-kalandvágy-a-hivatásos-katonai-szolgálatnál-eltöltött-időt",
    "href": "sec_linearis_regresszio.html#példa-befolyásolja-e-a-kalandvágy-a-hivatásos-katonai-szolgálatnál-eltöltött-időt",
    "title": "1  Lineáris regresszió",
    "section": "1.8 Példa: Befolyásolja-e a kalandvágy a hivatásos katonai szolgálatnál eltöltött időt?",
    "text": "1.8 Példa: Befolyásolja-e a kalandvágy a hivatásos katonai szolgálatnál eltöltött időt?\n\nA példa forrása: Münnich és mtsai. (2006, o. 1.6.2 probléma)\nKapcsolódó jamovi állomány: lin_reg_katonasag.omv\n\n\nd <- rio::import(file = \"adat/lin_reg_katonasag.xlsx\")\nstr(d)\n#> 'data.frame':    156 obs. of  4 variables:\n#>  $ kaland  : num  3 3 5 1 3 4 2 2 3 5 ...\n#>  $ egyhangu: num  3 2 4 1 3 1 2 1 2 3 ...\n#>  $ sport   : num  1 1 2 1 2 2 2 1 2 2 ...\n#>  $ evek    : num  4 7 10 3 6 15 5 6 9 13 ...\npsych::headTail(d)\n#>     kaland egyhangu sport evek\n#> 1        3        3     1    4\n#> 2        3        2     1    7\n#> 3        5        4     2   10\n#> 4        1        1     1    3\n#> ...    ...      ...   ...  ...\n#> 153      2        4     2    1\n#> 154      3        5     3    2\n#> 155      1        3     2    2\n#> 156      3        2     4   12\n\n\nlm_1 <- lm(evek ~ egyhangu + sport + kaland, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = evek ~ egyhangu + sport + kaland, data = d)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -1.6611 -0.5925 -0.0798  0.2726  9.7833 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  0.63951    0.33263   1.923   0.0564 .  \n#> egyhangu    -2.28197    0.09160 -24.912   <2e-16 ***\n#> sport        1.52987    0.09447  16.194   <2e-16 ***\n#> kaland       3.17525    0.09884  32.125   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.213 on 152 degrees of freedom\n#> Multiple R-squared:  0.9195, Adjusted R-squared:  0.9179 \n#> F-statistic: 578.4 on 3 and 152 DF,  p-value: < 2.2e-16\nlsr::standardCoefs(lm_1)\n#>                  b       beta\n#> egyhangu -2.281974 -0.5927751\n#> sport     1.529871  0.3821476\n#> kaland    3.175249  0.7676009\n\n\n\n\nBefolyásolja-e a kalandvágy a hivatásos katonai szolgálatnál eltöltött időt? (N=156)\n\n\nA fenti output a többszörös lineáris regresszió eredményét mutatja:\n\nA lineáris regressziós modellt megtarthatjuk, hiszen az F-statisztika értékét tekintve a modell szignifikáns, a változók együtthatóinak az értéke nem nulla.\nA modell magyarázóértéke igen jó, hiszen a korrigált determinációs együttható értéke 0,92, vagyis a független változók a függő változó varianciájának kb. 92%-át magyarázzák.\nMinden egyes független változó hatással van a függő változóra, vagyis mind a kalandvágy, az extrém sportok szeretete és a nyugalom utáni vágy is befolyásolja azt, hogy mennyi időt tölt valaki a hivatásos katonai szolgálatban.\nEllenben a \\(b_0\\) vagyis a konstans értéke most nulla, hiszen a táblázatban szereplő érték nem szignifikáns.\nMaga a regressziós egyenlet a pontos együtthatók ismeretében a következőképpen alakul:\n\n    evek=3,18*kaland+1,53*sport-2,28*egyhangu\n\nVagyis minél jobban kedveli valaki a kalandos életet és az extrém sportokat, és minél jobban irtózik a szürke hétköznapoktól, annál több időt tölt a katonaság kötelékében.\nA standardizált változók alapján a kaland szeretetének a hatása a legerősebb (0,768), a második legerősebb hatás az egyhangúság kedvelése, ám hatásának iránya negatív (-0,593), leggyengébb hatása pedig az extrém sportok szeretetének van (0,382).\n\n\n\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-menete",
    "href": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-menete",
    "title": "2  Főkomponens elemzés",
    "section": "2.1 A főkomponens elemzés menete",
    "text": "2.1 A főkomponens elemzés menete\nAz eredeti \\(X_1,X_2,\\dots,X_p\\) változókból a \\(Z_i=a_i1 X_1+ a_i2 X_2+\\dots + a_ip X_p\\) lineáris kombinációk segítségével kapjuk meg a főkomponenseket, azzal feltétellel, hogy \\(a_{i1}^2+a_{i2}^2+\\dots+a_{ip}^2=1\\), és az egymás után létrejövő \\(Z_1,Z_2,…,Z_p\\) főkomponensek nem korrelálnak egymással.\nGyakran az \\(X_1,X_2,\\dots,X_p\\) változó standardizált értékeiből indulunk ki, hogy a változók arányosan fejtsék ki hatásukat a főkomponensekre. A jamovi is így végzi az elemzést. Ekkor a változok átlaga nulla, szórása és variancia pedig 1 lesz.\nA részletek ismertetése nélkül a keresett \\(a_{i1},a_{i2},\\dots,a_{ip}\\) együtthatók megtalálása egy sajátérték-sajátvektor keresési feladat az eredeti \\(X_1,X_2,\\dots,X_p\\) változók korrelációs mátrixában. A megtalált \\(p\\) darab sajátérték $_1_2_p>0 $sorrendjét feltételezve, \\(\\lambda_i\\) az \\(i.\\) főkomponens varianciáját adja \\((\\lambda_i=var(Z_i))\\), és a megtalált \\(p\\) darab sajátvektorból az \\(i.\\) egyes elemei lesznek a \\(Z_i=a_{i1} X_1+ a_{i2} X_2+\\dots+ a_{ip} X_p\\) főkomponens \\(a_{i1},a_{i2},\\dots,a_{ip}\\) együtthatói.\nFontos összefüggés, hogy a főkomponensek (\\(Z_i\\)-k) varianciájának az összege egyenlő az eredeti standardizált változók (\\(X_i\\)-k) varianciájának összegével, azaz \\(\\lambda_1+\\lambda_2+\\dots+\\lambda_p=1+1+\\dots+1=p.\\)"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-alkalmazási-feltételei",
    "href": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-alkalmazási-feltételei",
    "title": "2  Főkomponens elemzés",
    "section": "2.2 A főkomponens elemzés alkalmazási feltételei",
    "text": "2.2 A főkomponens elemzés alkalmazási feltételei\n\nA főkomponens elemzés során általában 4-5-ször (egyes szerzőknél 10-szer) nagyobb a mintaelemszám a vizsgált változók számánál.\nA faktoranalízis feltétele, hogy egymással korreláló változókból induljunk ki. A Bartlett-féle szferikus próba nullhipotézise, hogy a változók korrelálatlanok (vagyis a korrelációs mátrixnak a főátlón kívüli elemei csak véletlenül térnek el a nullától). A szignifikáns p-érték a kedvező a főkomponens elemzés számára. (Megjegyezzük, hogy a túlságosan magas egyirányú korrelációk sem jók, ugyanis ez azt okozhatja, hogy a főkomponens elemzésnek nem lesz megoldása, ugyanis minden változó egy faktorba kerül.)\nAz MSA (Measure of Sampling Adequecy) az egyes változók esetében mutatja meg, hogy mennyire van szoros kapcsolatban a többi változóval. Érdemes a 0,5 alatti MSA értékkel rendelkező változókat kizárni az elemzésből. Értéke 0 és 1 közötti lehet.\nA Kaiser-Meyer-Olkin- (KMO) kritérium az MSA értékek átlaga. Míg az MSA érték az egyes változókra vonatkozik, a KMO az összes változóra egyidejűleg. A KMO mutatószám jelentését a következőképpen ítélhetjük meg:\n\nKMO ≥ 0,9 kiváló\nKMO ≥ 0,8 nagyon jó\nKMO ≥ 0,7 megfelelő\nKMO ≥ 0,6 közepes\nKMO ≥ 0,5 gyenge\nKMO < 0,5 elfogadhatatlan."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponensek-forgatása-rotáció",
    "href": "sec_fokomponens_elemzes.html#a-főkomponensek-forgatása-rotáció",
    "title": "2  Főkomponens elemzés",
    "section": "2.3 A főkomponensek forgatása (rotáció)",
    "text": "2.3 A főkomponensek forgatása (rotáció)\nA faktorkiválasztás (extrakció) során az elemzés elsődleges célja, hogy maximalizálja a főkomponensek varianciáját, amely eredményeként megkapjuk a rotálatlan faktorsúly-mátrixot. A faktorsúly az eredeti változó és az adott faktor közötti korrelációt mutatja, amelynek értéke a korrelációs együtthatókhoz hasonlóan -1 és 1 között változhat.\nA faktorkiválasztás során azonban előfordulhat, hogy olyan változók fognak korrelálni egy adott faktorral, amelyeknek semmi közük egymáshoz, ezáltal lehetetlenné téve az értelmezést. Ezen a problémán segít a forgatás, vagy más néven rotáció. A faktor-rotáció azt jelenti, hogy a faktorok tengelyeit elforgatjuk úgy, hogy egyszerűbb és értelmezhetőbb faktormegoldáshoz vezessen.\nA rotáció (forgatás) során nem változnak sem a kommunalitás, sem pedig az összes magyarázott variancia, csak a faktorok sajátértékei/magyarázott varianciái módosulnak.\nA rotáláson belül két típust különböztetünk meg: a derékszögű (ortogonális) (Varimax, Equimax, Quartimax) és a hegyesszögű (nem ortogonális) (Direct Oblimin, Promax) forgatási módszereket.\nA derékszögű esetében a tengelyek merőlegesen állnak egymásra, ezáltal a faktorok nem korrelálnak egymással, míg a hegyesszögű esetében ezek tetszőleges szöget zárnak be egymással, vagyis a faktorok korrelálni fognak egymással."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa-négy-tantárgy-osztályzata",
    "href": "sec_fokomponens_elemzes.html#példa-négy-tantárgy-osztályzata",
    "title": "2  Főkomponens elemzés",
    "section": "2.4 Példa: Négy tantárgy osztályzata",
    "text": "2.4 Példa: Négy tantárgy osztályzata\n\nA példa forrása: Münnich és mtsai. (2006) 2.3.1 fejezettől Probléma\nKapcsolódó jamovi állomány: fokomp_elemzes_tantargyak.omv.\n\n1. Határozzuk meg a korrelációs mátrixot (jamovi-ban: Regression / Correlation matrix)\nAz adatok a fokomp_elemzes_tantargyak.xlsx állományban találhatók.\n\nd <- rio::import(file = \"adat/fokomp_elemzes_tantargyak.xlsx\")\nstr(d)\n#> 'data.frame':    9 obs. of  4 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5\n#>  $ fizika     : num  5 5 3 3 4 2 4 3 5\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5\nd\n#>   matek fizika informatika kemia\n#> 1     5      5           4     5\n#> 2     4      5           4     5\n#> 3     3      3           4     3\n#> 4     2      3           2     3\n#> 5     5      4           5     5\n#> 6     1      2           1     1\n#> 7     5      4           5     5\n#> 8     2      3           2     3\n#> 9     5      5           5     5\n\n\ncor(d)\n#>                 matek    fizika informatika     kemia\n#> matek       1.0000000 0.8712476   0.9492623 0.9499475\n#> fizika      0.8712476 1.0000000   0.7662496 0.9271176\n#> informatika 0.9492623 0.7662496   1.0000000 0.8867155\n#> kemia       0.9499475 0.9271176   0.8867155 1.0000000\n\n\n\n\nKorrelációs mátrix meghatározása\n\n\nA korrelációs mátrix adatai arra utalnak, hogy szoros kapcsolat van a változók között. A korrelációs értékek nullánál nagyobbak, ami azonos irányú tendenciákra utal. E két mátrix is alátámasztja a feltételezésünket, hogy a változók szorosan együtt változnak.\n2. Ellenőrizzük le az adatok alkalmasságát (jamovi-ban: Factor / Principal Component Analysis)\nA változóink eleget tesznek a Bartlett-féle szferikus próbának, a korrelációs mátrix nem egységmátrix \\((p<0,001)\\), az MSA értékek is nagyobban \\(0,5\\)-nél és a KMO érték is megfelelő.\n\n\n\nAlkalmazási feltételek ellenőrzése\n\n\n3. Határozzuk meg a komponensek számát\nElvileg annyi főkomponenst lehet kiszámolni, ahány változónk van, a célunk azonban a komponensek számának minimalizálása.\nTöbb eljárás létezik a főkomponensek számának meghatározására:\n\nHorn-féle párhuzamos analízis (jamovi-ban: Based on parallel analysis): modern eljárás, amely szimuláció segítségével állapítja meg a főkomponensek számát (Horn, 1965).\nA priori meghatározás (jamovi-ban: Fixed number): korábbi ismerete alapján megadjuk a főkomponensek számát.\nSajátértéken alapuló megoldás (jamovi-ban: Based on eigenvalue): tipikusan csak az 1-nél nagyobb sajátértékű faktorokat tartjuk bent a modellben. Az 1-nél kisebb varianciájú faktorok ugyanis nem jobbak mint az eredeti standardizált változók\nSajátértékábrán (scree-plot, kőtörmelék ábra) alapuló meghatározás (jamovi-ban: Scree plot): a sajátérték ábra a sajátértékek ábrázolása a főkomponensek sorrendjében. Az ábra formája alapján lehet következtetni a főkomponensek számára: ahol a görbe meredekségében van egy határozott törés, meredekebb rész után laposabb jön. Ahol tehát a görbe laposodása elkezdődik, az a figyelembe vett főkomponensek megfelelő száma.\nMagyarázott varianciahányadon alapuló meghatározás (jamovi-ban: Component summary): ekkor az előállított főkomponensek számát úgy határozzuk meg, hogy a főkomponensek által magyarázott variancia kumulált százalékos értéke elérjen egy megfelelő szintet. A megfelelő szint (60%-95%-ig) a probléma jellegétől függ.\n\nA Horn-féle párhuzamos elemzés 1 főkomponenst javasol.\n\n\n\nFőkomponensek számának meghatározása\n\n\n4. Válasszunk forgatást (jamovi-ban: Rotation)\nA jamovi alapértelmezés szerint a Varimax forgatást ajánlja, amely derékszögű koordinátatengelyeket eredményez és a legtöbb esetben ez a megfelelő választás. Lehetőségünk van ezen módosítani. Az összes lehetőség:\n\nNone – rotálatlan elemzés\nVarimax\nQartimax\nPromax\nOblimin\nSimplimax\n\nMivel egyetlen főkomponensünk van, így nem változtatunk az alapértelmezett Varimax beállításon.\n5. A főkomponens elemzés eredménye\nKomponens mátrix (jamoviban: Component loadings)\nA főkomponens elemzés eredménye a komponens mátrix (faktormátrix), amelynek soraiban az eredeti változók, oszlopaiban a kinyert főkomponensek vannak. A cellákban a komponens súlyok (faktorsúlyok) szerepelnek, amelyek a főkomponens és a változó közötti korrelációt jelentik. Ezek egyben a főkomponensek azon együtthatói, amelyekkel a standardizált változó a főkomponensekkel kifejezhető.\nA magas abszolút értékű faktorsúly azt jelzi, hogy komponens és a változó szorosan összefügg.\nA változókat tartalmazó sorok rendezhetők a faktorsúlyok csökkenő sorrendjében (jamovi-ban: Sort loading by size)\nAz adott értéknél kisebb faktorsúlyok elrejthetők a táblázatban (jamoviban: Hide loadings below)\nA Uniqueness oszlopban az egyes változók „egyediségét” is láthatjuk. Az egyediség a variancia azon aránya, amely „egyedi” a változóra nézve, és nem magyarázható a komponensekkel. Vegyük figyelembe, hogy minél nagyobb az „egyediség”, annál kisebb a változó relevanciája/hozzájárulása a modellben.\nA kezdő sajátértékek (jamovi-ban: Initial eigenvalues)\nA kezdő sajátértékek táblázat a sajátértékeket adja meg. A komponensek sajátértékei csökkenő nagyságúak, ahogy az 1. komponenstől a 4. komponensig haladunk. A komponens sajátértéke kifejezi a komponens által magyarázott teljes varianciát. A 4 komponens összvarianciája pontosan 4. A további két oszlopban ez alapján számoljuk a százalékos és a kummulált százalékos varianciát.\nA komponensek összegzése (jamovi-ban: Component summary)\nA komponensek összegzése táblázat tartalmazza a megtartott komponenseket, a magyarázott varianciát, illetve utóbbit százalékosan is kifejezve. Vegyük észre, hogy ez a sor teljesen megegyezik a kezdő sajátértékek táblázat első sorával. Az SS Loadings felirat magyarázata, hogy magyarázott variancia a komponenshez tartozó faktorsúlyok négyzetösszege (sum of square).\n\n\n\nKomponensek összegzése\n\n\n6. Főkomponens értékek kiszámítása\nA főkomponens elemzés célja az eredeti változók csökkentése. A főkomponens(ek) az eredeti változók lineáris kombinációjával kifejezhetők. Ez(ek) a főkomponens értékek (jamovi-ban: Component score) az adatbázisban is rögzíthetők, és további elemzések kiindulópontjai lehetnek.\n\n\n\nFőkomponens értékek kiszámítása\n\n\nSikerült tehát az érdemjegyeket egyetlen mérőszámmal kifejezni, a fenti főkomponens érték az, amely a lehető legjobban magában foglalja az egyes tantárgyakból szerzett jegyeket és ezáltal a reál tantárgyak iránti fogékonyság mérőszáma lehet. A legjobban a kilencedik személy teljesít a reál tárgyakból, legrosszabbul pedig a hatodik. Ezek az értékek standardizáltak, vagyis 0 átlagúak és 1 szórásúak.\n\n\n\nFőkomponens értékek leíró statisztikája\n\n\nR-ben több lehetőségünk van a főlomponenselemzés elvégzésére.\n\npca_1 <- prcomp(d, scale. = TRUE)\npca_1\n#> Standard deviations (1, .., p=4):\n#> [1] 1.9177188 0.5017701 0.2045278 0.1695572\n#> \n#> Rotation (n x k) = (4 x 4):\n#>                    PC1        PC2         PC3         PC4\n#> matek       -0.5129614  0.2231620 -0.02972158 -0.82836339\n#> fizika      -0.4843985 -0.7077528  0.50610146  0.09113404\n#> informatika -0.4900124  0.6474152  0.35260295  0.46520167\n#> kemia       -0.5119731 -0.1736040 -0.78654250  0.29848968\n\n\npca_1 <- princomp(d, cor = TRUE)\npca_1\n#> Call:\n#> princomp(x = d, cor = TRUE)\n#> \n#> Standard deviations:\n#>    Comp.1    Comp.2    Comp.3    Comp.4 \n#> 1.9177188 0.5017701 0.2045278 0.1695572 \n#> \n#>  4  variables and  9 observations.\n\n\npsych::pca(d, rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>              PC1   h2    u2 com\n#> matek       0.98 0.97 0.032   1\n#> fizika      0.93 0.86 0.137   1\n#> informatika 0.94 0.88 0.117   1\n#> kemia       0.98 0.96 0.036   1\n#> \n#>                 PC1\n#> SS loadings    3.68\n#> Proportion Var 0.92\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.05 \n#>  with the empirical chi square  0.28  with prob <  0.87 \n#> \n#> Fit based upon off diagonal values = 1\n\n\npca_1 <- FactoMineR::PCA(d, graph = FALSE)\npca_1$eig\n#>        eigenvalue percentage of variance\n#> comp 1 3.67764553             91.9411383\n#> comp 2 0.25177321              6.2943303\n#> comp 3 0.04183160              1.0457901\n#> comp 4 0.02874965              0.7187414\n#>        cumulative percentage of variance\n#> comp 1                          91.94114\n#> comp 2                          98.23547\n#> comp 3                          99.28126\n#> comp 4                         100.00000\npca_1$var\n#> $coord\n#>                 Dim.1      Dim.2        Dim.3       Dim.4\n#> matek       0.9837158 -0.1119760 -0.006078888 -0.14045500\n#> fizika      0.9289402  0.3551292  0.103511795  0.01545243\n#> informatika 0.9397061 -0.3248536  0.072117091  0.07887831\n#> kemia       0.9818205  0.0871093 -0.160869772  0.05061108\n#> \n#> $cor\n#>                 Dim.1      Dim.2        Dim.3       Dim.4\n#> matek       0.9837158 -0.1119760 -0.006078888 -0.14045500\n#> fizika      0.9289402  0.3551292  0.103511795  0.01545243\n#> informatika 0.9397061 -0.3248536  0.072117091  0.07887831\n#> kemia       0.9818205  0.0871093 -0.160869772  0.05061108\n#> \n#> $cos2\n#>                 Dim.1       Dim.2        Dim.3        Dim.4\n#> matek       0.9676968 0.012538628 3.695288e-05 0.0197276074\n#> fizika      0.8629298 0.126116721 1.071469e-02 0.0002387777\n#> informatika 0.8830475 0.105529830 5.200875e-03 0.0062217871\n#> kemia       0.9639714 0.007588031 2.587908e-02 0.0025614817\n#> \n#> $contrib\n#>                Dim.1     Dim.2       Dim.3      Dim.4\n#> matek       26.31294  4.980128  0.08833723 68.6185908\n#> fizika      23.46419 50.091398 25.61386842  0.8305413\n#> informatika 24.01122 41.914638 12.43288421 21.6412590\n#> kemia       26.21165  3.013836 61.86491013  8.9096089\nfactoextra::fviz_eig(pca_1, addlabels = TRUE, ylim = c(0, 110))\nfactoextra::get_eigenvalue(pca_1)\n#>       eigenvalue variance.percent cumulative.variance.percent\n#> Dim.1 3.67764553       91.9411383                    91.94114\n#> Dim.2 0.25177321        6.2943303                    98.23547\n#> Dim.3 0.04183160        1.0457901                    99.28126\n#> Dim.4 0.02874965        0.7187414                   100.00000\nfactoextra::get_pca_ind(pca_1)\n#> Principal Component Analysis Results for individuals\n#>  ===================================================\n#>   Name       Description                       \n#> 1 \"$coord\"   \"Coordinates for the individuals\" \n#> 2 \"$cos2\"    \"Cos2 for the individuals\"        \n#> 3 \"$contrib\" \"contributions of the individuals\"\nfactoextra::get_pca_var(pca_1)\n#> Principal Component Analysis Results for variables\n#>  ===================================================\n#>   Name       Description                                    \n#> 1 \"$coord\"   \"Coordinates for the variables\"                \n#> 2 \"$cor\"     \"Correlations between variables and dimensions\"\n#> 3 \"$cos2\"    \"Cos2 for the variables\"                       \n#> 4 \"$contrib\" \"contributions of the variables\"\nfactoextra::fviz_pca_ind(pca_1)\nfactoextra::fviz_pca_var(pca_1)\nfactoextra::fviz_pca_biplot(pca_1)\ncorrplot::corrplot(pca_1$var$cos2, is.corr = FALSE)"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa-létezik-a-reál-tárgyak-iránti-fogékonyság",
    "href": "sec_fokomponens_elemzes.html#példa-létezik-a-reál-tárgyak-iránti-fogékonyság",
    "title": "2  Főkomponens elemzés",
    "section": "2.5 Példa: Létezik a reál tárgyak iránti fogékonyság?",
    "text": "2.5 Példa: Létezik a reál tárgyak iránti fogékonyság?\n\nA példa forrása: Münnich és mtsai. (2006) 2.5.1 Probléma\nKapcsolódó jamovi állomány: fokomp_real_targyak.omv\n\nKorábban már foglalkoztunk azzal a felvetéssel, hogy néhány tantárgy eredményeit egyetlen mérőszámmal reprezentáljuk. Korábbi példánkban a matematika, fizika, informatika és kémia jegyek közötti összefüggéseket vizsgáltuk egy kisebb adatbázison, most egy sokkal nagyobb adatbázis segítségével mutatjuk be, hogyan végezhetünk főkomponens-analízist. Az adatok a fokomp_real_targyak.xlsx állományban találhatók.\n\nd <- rio::import(file = \"adat/fokomp_real_targyak.xlsx\")\nstr(d)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5 5 ...\n#>  $ fizika     : num  5 5 3 3 4 2 4 3 5 3 ...\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5 4 ...\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5 5 ...\npsych::headTail(d)\n#>     matek fizika informatika kemia\n#> 1       5      5           4     5\n#> 2       4      5           4     5\n#> 3       3      3           4     3\n#> 4       2      3           2     3\n#> ...   ...    ...         ...   ...\n#> 27      5      5           5     5\n#> 28      5      4           5     5\n#> 29      2      3           2     3\n#> 30      5      4           5     5\n\nHozzuk létre a korrelációs mátrixot!\n\ncor(d)\n#>                 matek    fizika informatika     kemia\n#> matek       1.0000000 0.7746503   0.9391649 0.9075545\n#> fizika      0.7746503 1.0000000   0.7038821 0.8344007\n#> informatika 0.9391649 0.7038821   1.0000000 0.8172819\n#> kemia       0.9075545 0.8344007   0.8172819 1.0000000\n\nLátható, hogy a négy tantárgy jegyei viszonylag összhangban vannak egymással abban az értelemben, hogy azok a diákok, akik az egyik tárgyból jól teljesítenek, azok a másik három tárgyból is.\nEzek alapján van egy olyan sejtésünk, hogy egy úgynevezett reál tárgyak iránti fogékonyság mutatóval reprezentálhatjuk a négy tantárgy eredményeit. Vagyis főkomponens-analízis segítségével ellenőrizhetjük, hogy az adatok valóban jól sűríthetőek-e egyetlen dimenzióba vagy mérőszámba, és ha igen, akkor ezt a dimenziót elnevezhetjük reál tárgyak iránti fogékonyságnak.\n\npsych::pca(d, rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>              PC1   h2    u2 com\n#> matek       0.97 0.94 0.057   1\n#> fizika      0.88 0.78 0.220   1\n#> informatika 0.93 0.86 0.139   1\n#> kemia       0.95 0.91 0.091   1\n#> \n#>                 PC1\n#> SS loadings    3.49\n#> Proportion Var 0.87\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.07 \n#>  with the empirical chi square  1.59  with prob <  0.45 \n#> \n#> Fit based upon off diagonal values = 0.99\n\n\n\n\nFőkomponens elemzés - Reál tantárgyak iránti fogékonyság\n\n\nÖsszességében az adatok jól sűríthetők egyetlen mérőszámba, minimális információveszteséggel, ezt a mutatót pedig hívhatjuk a reál tárgyak iránti fogékonyság mutatójának."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa-egy-kérdőív-szerkesztésének-problémái",
    "href": "sec_fokomponens_elemzes.html#példa-egy-kérdőív-szerkesztésének-problémái",
    "title": "2  Főkomponens elemzés",
    "section": "2.6 Példa: Egy kérdőív szerkesztésének problémái",
    "text": "2.6 Példa: Egy kérdőív szerkesztésének problémái\n\nA példa forrása: Münnich és mtsai. (2006) 2.5.2 Probléma\nKapcsolódó jamovi állomány: fokomp_kerdoivtervezet.omv\n\nKérdőívek kialakításkor gyakran előfordul az a probléma, hogy egy dimenzió mérésére nem áll rendelkezésünkre valamilyen bevált mérőeszköz, hanem magunknak kell egyet kialakítani. Egy jó kérdőív kialakítása hosszas és nagyon alapos munkát igényel. Ez a folyamat nagyvonalakban úgy néz ki, hogy az összeállított itemeket először egy kisebb mintán teszteljük (elővizsgálat), majd megnézzük, hogy az itemek valóban úgy „működnek-e”, ahogyan azt mi feltételeztük. Ez jelenti egyrészt a teszt megbízhatóságának, másrészt érvényességének vizsgálatát.\nA megbízhatóság vizsgálatának egyik módszere, hogy megnézzük, az itemek valóban egy dimenzióra illeszkednek-e. A nem odaillő itemeket pedig kivesszük a kérdőívből (itemszelekció). Ennek módszerei lehetnek a\n\nfőkomponens-analízis\nCronbach-alfán lapuló\n\nAz adatok a fokomp_kerdoivtervezet.xlsx állományban találhatók.\n\nd <- rio::import(file = \"adat/fokomp_kerdoivtervezet.xlsx\")\nstr(d)\n#> 'data.frame':    125 obs. of  10 variables:\n#>  $ K_1 : num  7 5 4 2 3 3 7 4 7 2 ...\n#>  $ K_2 : num  7 5 4 2 2 3 7 3 7 2 ...\n#>  $ K_3 : num  6 5 2 2 4 3 7 3 7 3 ...\n#>  $ K_4 : num  7 5 5 4 2 3 7 3 7 3 ...\n#>  $ K_5 : num  7 5 4 4 3 3 7 3 7 3 ...\n#>  $ K_6 : num  5 3 4 2 1 3 5 3 4 1 ...\n#>  $ K_7 : num  5 3 2 6 6 6 5 3 4 1 ...\n#>  $ K_8 : num  7 5 4 2 3 3 7 3 7 3 ...\n#>  $ K_9 : num  5 3 4 2 3 6 5 3 4 4 ...\n#>  $ K_10: num  5 3 4 3 2 2 7 3 7 3 ...\npsych::headTail(d)\n#>     K_1 K_2 K_3 K_4 K_5 K_6 K_7 K_8 K_9 K_10\n#> 1     7   7   6   7   7   5   5   7   5    5\n#> 2     5   5   5   5   5   3   3   5   3    3\n#> 3     4   4   2   5   4   4   2   4   4    4\n#> 4     2   2   2   4   4   2   6   2   2    3\n#> ... ... ... ... ... ... ... ... ... ...  ...\n#> 122   4   4   4   4   4   2   2   4   2    2\n#> 123   2   2   2   2   2   4   1   4   3    3\n#> 124   1   1   1   1   1   7   7   1   7    7\n#> 125   3   3   3   3   3   3   3   3   3    3\n\nElőször végezzünk főkomponens elemzést a változókra, hogy képet kaphassunk az adatok egymáshoz való viszonyáról. Kezdjük a korrelációs mátrixszal.\n\nprint(cor(d), digits = 2)\n#>        K_1    K_2    K_3    K_4    K_5   K_6   K_7      K_8  ...\n#> K_1   1.00  0.935  0.824  0.819  0.889 -0.16 -0.30  0.74648 -...\n#> K_2   0.93  1.000  0.824  0.807  0.884 -0.14 -0.26  0.75350 -...\n#> K_3   0.82  0.824  1.000  0.774  0.822 -0.20 -0.26  0.70244 -...\n#> K_4   0.82  0.807  0.774  1.000  0.826 -0.12 -0.26  0.69481 -...\n#> K_5   0.89  0.884  0.822  0.826  1.000 -0.23 -0.31  0.78636 -...\n#> K_6  -0.16 -0.140 -0.203 -0.117 -0.233  1.00  0.63 -0.18707  ...\n#> K_7  -0.30 -0.264 -0.257 -0.256 -0.315  0.63  1.00 -0.31395  ...\n#> K_8   0.75  0.753  0.702  0.695  0.786 -0.19 -0.31  1.00000 -...\n#> K_9  -0.12 -0.099 -0.164 -0.109 -0.144  0.69  0.53 -0.26564  ...\n#> K_10  0.10  0.106  0.095 -0.031  0.076  0.42  0.25 -0.00063  ...\n#>          K_10\n#> K_1   0.10038\n#> K_2   0.10637\n#> K_3   0.09462\n#> K_4  -0.03121\n#> K_5   0.07551\n#> K_6   0.41988\n#> K_7   0.24515\n#> K_8  -0.00063\n#> K_9   0.46786\n#> K_10  1.00000\n\n\npsych::pca(d, rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>        PC1      h2   u2 com\n#> K_1   0.93 0.87216 0.13   1\n#> K_2   0.93 0.85839 0.14   1\n#> K_3   0.89 0.78819 0.21   1\n#> K_4   0.87 0.76526 0.23   1\n#> K_5   0.94 0.88251 0.12   1\n#> K_6  -0.34 0.11231 0.89   1\n#> K_7  -0.45 0.19850 0.80   1\n#> K_8   0.85 0.72287 0.28   1\n#> K_9  -0.30 0.08965 0.91   1\n#> K_10 -0.02 0.00027 1.00   1\n#> \n#>                 PC1\n#> SS loadings    5.29\n#> Proportion Var 0.53\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.19 \n#>  with the empirical chi square  386.88  with prob <  6.7e-61 \n#> \n#> Fit based upon off diagonal values = 0.87\n\nLátható, hogy a 6, 7,9 és 10 -es itemek nem nagy súllyal vesznek részt az első főkomponensben, az egyediségük (nem magyarázott varianciájuk) nekik a legnagyobb. Az 1. főkomponens az összes variancia 53%-át magyarázza.\nHa elhagyjuk ezeket az itemeket, jelentősen javul a főkomponens elemzés eredménye:\n\npsych::pca(d[-c(6, 7, 9, 10)], rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>      PC1   h2    u2 com\n#> K_1 0.95 0.90 0.096   1\n#> K_2 0.95 0.90 0.099   1\n#> K_3 0.90 0.81 0.190   1\n#> K_4 0.90 0.80 0.198   1\n#> K_5 0.95 0.90 0.100   1\n#> K_8 0.85 0.72 0.280   1\n#> \n#>                 PC1\n#> SS loadings    5.04\n#> Proportion Var 0.84\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.04 \n#>  with the empirical chi square  5.89  with prob <  0.75 \n#> \n#> Fit based upon off diagonal values = 1\n\nA magyarázott variancia felmegy 84%-ra, és mindegyik változónak szoros a kapcsolata az 1. főkomponenssel. Az itemek igen jól illeszkednek egyetlen dimenzióra.\nA fenti vizsgálatot a Cronbach-alfa alapján is elvégezhetjük.\n\npsych::alpha(d)\n#> Some items ( K_6 K_7 K_9 K_10 ) were negatively correlated wi...\n#> probably should be reversed.  \n#> To do this, run the function again with the 'check.keys=TRUE'...\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = d)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.77      0.78    0.91      0.26 3.5 0.032  3.5 1.1    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.71  0.77  0.83\n#> Duhachek  0.71  0.77  0.84\n#> \n#>  Reliability if an item is dropped:\n#>      raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r\n#> K_1       0.71      0.72    0.88      0.22 2.6    0.042  0.19\n#> K_2       0.71      0.72    0.88      0.22 2.6    0.042  0.20\n#> K_3       0.72      0.73    0.89      0.23 2.7    0.041  0.20\n#> K_4       0.72      0.73    0.88      0.23 2.7    0.041  0.20\n#> K_5       0.72      0.73    0.88      0.23 2.6    0.041  0.19\n#> K_6       0.79      0.80    0.90      0.31 4.0    0.028  0.22\n#> K_7       0.82      0.82    0.92      0.33 4.5    0.025  0.20\n#> K_8       0.74      0.75    0.89      0.25 2.9    0.038  0.21\n#> K_9       0.79      0.80    0.91      0.31 3.9    0.029  0.22\n#> K_10      0.77      0.78    0.91      0.29 3.6    0.032  0.25\n#>      med.r\n#> K_1  0.085\n#> K_2  0.085\n#> K_3  0.088\n#> K_4  0.097\n#> K_5  0.097\n#> K_6  0.176\n#> K_7  0.263\n#> K_8  0.097\n#> K_9  0.176\n#> K_10 0.217\n#> \n#>  Item statistics \n#>        n raw.r std.r r.cor r.drop mean  sd\n#> K_1  125  0.81  0.82 0.839  0.729  3.2 1.9\n#> K_2  125  0.82  0.83 0.853  0.748  3.2 1.9\n#> K_3  125  0.76  0.76 0.756  0.660  3.3 1.9\n#> K_4  125  0.75  0.76 0.756  0.659  3.4 1.8\n#> K_5  125  0.78  0.79 0.809  0.701  3.2 1.7\n#> K_6  125  0.31  0.29 0.241  0.140  3.7 1.8\n#> K_7  125  0.15  0.12 0.031 -0.049  4.1 2.1\n#> K_8  125  0.66  0.68 0.652  0.558  3.4 1.6\n#> K_9  125  0.32  0.31 0.247  0.160  3.7 1.8\n#> K_10 125  0.44  0.43 0.330  0.278  3.6 1.9\n#> \n#> Non missing response frequency for each item\n#>         1    2    3    4    5    6    7 miss\n#> K_1  0.21 0.26 0.14 0.18 0.05 0.10 0.07    0\n#> K_2  0.19 0.29 0.11 0.18 0.07 0.08 0.08    0\n#> K_3  0.18 0.23 0.17 0.16 0.06 0.11 0.08    0\n#> K_4  0.17 0.22 0.18 0.17 0.09 0.10 0.08    0\n#> K_5  0.18 0.24 0.21 0.15 0.10 0.04 0.07    0\n#> K_6  0.11 0.23 0.16 0.14 0.11 0.18 0.06    0\n#> K_7  0.14 0.14 0.15 0.12 0.07 0.24 0.14    0\n#> K_8  0.14 0.18 0.19 0.28 0.10 0.06 0.06    0\n#> K_9  0.08 0.24 0.18 0.16 0.10 0.17 0.06    0\n#> K_10 0.10 0.27 0.20 0.12 0.07 0.14 0.09    0\n\nLátható, hogy a Cronbach-alfa értéke 0,77, de javítható a 7. item eldobásával.\n\npsych::alpha(d[c(-7)])\n#> Some items ( K_6 K_9 ) were negatively correlated with the to...\n#> probably should be reversed.  \n#> To do this, run the function again with the 'check.keys=TRUE'...\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = d[c(-7)])\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.82      0.82    0.92      0.33 4.5 0.025  3.4 1.2    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.77  0.82  0.86\n#> Duhachek  0.77  0.82  0.87\n#> \n#>  Reliability if an item is dropped:\n#>      raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r\n#> K_1       0.76      0.76    0.89      0.29 3.2    0.034  0.19\n#> K_2       0.76      0.76    0.89      0.29 3.2    0.034  0.19\n#> K_3       0.77      0.77    0.90      0.30 3.4    0.032  0.20\n#> K_4       0.77      0.77    0.90      0.30 3.4    0.032  0.20\n#> K_5       0.77      0.77    0.89      0.29 3.3    0.033  0.19\n#> K_6       0.86      0.86    0.92      0.43 6.0    0.019  0.19\n#> K_8       0.79      0.79    0.90      0.32 3.7    0.030  0.20\n#> K_9       0.85      0.85    0.92      0.42 5.8    0.019  0.19\n#> K_10      0.84      0.83    0.93      0.39 5.0    0.022  0.24\n#>      med.r\n#> K_1  0.100\n#> K_2  0.097\n#> K_3  0.103\n#> K_4  0.103\n#> K_5  0.103\n#> K_6  0.699\n#> K_8  0.103\n#> K_9  0.699\n#> K_10 0.699\n#> \n#>  Item statistics \n#>        n raw.r std.r r.cor r.drop mean  sd\n#> K_1  125  0.87  0.87  0.89  0.818  3.2 1.9\n#> K_2  125  0.88  0.88  0.90  0.829  3.2 1.9\n#> K_3  125  0.81  0.81  0.80  0.735  3.3 1.9\n#> K_4  125  0.81  0.81  0.80  0.733  3.4 1.8\n#> K_5  125  0.85  0.85  0.87  0.792  3.2 1.7\n#> K_6  125  0.19  0.18  0.11  0.012  3.7 1.8\n#> K_8  125  0.73  0.74  0.71  0.640  3.4 1.6\n#> K_9  125  0.22  0.22  0.15  0.051  3.7 1.8\n#> K_10 125  0.39  0.39  0.29  0.227  3.6 1.9\n#> \n#> Non missing response frequency for each item\n#>         1    2    3    4    5    6    7 miss\n#> K_1  0.21 0.26 0.14 0.18 0.05 0.10 0.07    0\n#> K_2  0.19 0.29 0.11 0.18 0.07 0.08 0.08    0\n#> K_3  0.18 0.23 0.17 0.16 0.06 0.11 0.08    0\n#> K_4  0.17 0.22 0.18 0.17 0.09 0.10 0.08    0\n#> K_5  0.18 0.24 0.21 0.15 0.10 0.04 0.07    0\n#> K_6  0.11 0.23 0.16 0.14 0.11 0.18 0.06    0\n#> K_8  0.14 0.18 0.19 0.28 0.10 0.06 0.06    0\n#> K_9  0.08 0.24 0.18 0.16 0.10 0.17 0.06    0\n#> K_10 0.10 0.27 0.20 0.12 0.07 0.14 0.09    0\n\nLátható, hogy a Cronbach-alfa értéke 0,82, de javítható a 6. item eldobásával.\n\npsych::alpha(d[c(-7, -6)])\n#> Some items ( K_9 ) were negatively correlated with the total ...\n#> probably should be reversed.  \n#> To do this, run the function again with the 'check.keys=TRUE'...\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = d[c(-7, -6)])\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.86      0.86    0.92      0.43   6 0.019  3.4 1.3    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.82  0.86  0.89\n#> Duhachek  0.82  0.86  0.89\n#> \n#>  Reliability if an item is dropped:\n#>      raw_alpha std.alpha G6(smc) average_r  S/N alpha se var.r\n#> K_1       0.80      0.81    0.89      0.37  4.1    0.026  0.19\n#> K_2       0.80      0.80    0.89      0.37  4.1    0.027  0.19\n#> K_3       0.81      0.82    0.90      0.39  4.4    0.025  0.20\n#> K_4       0.82      0.82    0.90      0.39  4.5    0.025  0.20\n#> K_5       0.81      0.81    0.89      0.37  4.2    0.026  0.18\n#> K_8       0.83      0.83    0.91      0.41  4.8    0.023  0.20\n#> K_9       0.91      0.91    0.93      0.59 10.2    0.012  0.12\n#> K_10      0.89      0.89    0.93      0.53  8.0    0.013  0.20\n#>      med.r\n#> K_1   0.47\n#> K_2   0.47\n#> K_3   0.47\n#> K_4   0.47\n#> K_5   0.47\n#> K_8   0.47\n#> K_9   0.77\n#> K_10  0.77\n#> \n#>  Item statistics \n#>        n raw.r std.r r.cor r.drop mean  sd\n#> K_1  125  0.92  0.92  0.94  0.880  3.2 1.9\n#> K_2  125  0.92  0.92  0.94  0.886  3.2 1.9\n#> K_3  125  0.86  0.86  0.85  0.803  3.3 1.9\n#> K_4  125  0.84  0.85  0.84  0.779  3.4 1.8\n#> K_5  125  0.91  0.91  0.92  0.868  3.2 1.7\n#> K_8  125  0.77  0.78  0.75  0.697  3.4 1.6\n#> K_9  125  0.10  0.10 -0.02 -0.072  3.7 1.8\n#> K_10 125  0.33  0.32  0.21  0.150  3.6 1.9\n#> \n#> Non missing response frequency for each item\n#>         1    2    3    4    5    6    7 miss\n#> K_1  0.21 0.26 0.14 0.18 0.05 0.10 0.07    0\n#> K_2  0.19 0.29 0.11 0.18 0.07 0.08 0.08    0\n#> K_3  0.18 0.23 0.17 0.16 0.06 0.11 0.08    0\n#> K_4  0.17 0.22 0.18 0.17 0.09 0.10 0.08    0\n#> K_5  0.18 0.24 0.21 0.15 0.10 0.04 0.07    0\n#> K_8  0.14 0.18 0.19 0.28 0.10 0.06 0.06    0\n#> K_9  0.08 0.24 0.18 0.16 0.10 0.17 0.06    0\n#> K_10 0.10 0.27 0.20 0.12 0.07 0.14 0.09    0\n\nLátható, hogy a Cronbach-alfa értéke 0,86, de javítható a 9. item eldobásával.\n\npsych::alpha(d[-c(7, 6, 9)])\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = d[-c(7, 6, 9)])\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.91      0.91    0.93      0.59  10 0.012  3.3 1.5    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.88  0.91  0.93\n#> Duhachek  0.89  0.91  0.93\n#> \n#>  Reliability if an item is dropped:\n#>      raw_alpha std.alpha G6(smc) average_r  S/N alpha se  var.r\n#> K_1       0.87      0.88    0.90      0.54  7.1   0.0173 0.1331\n#> K_2       0.87      0.88    0.90      0.54  7.1   0.0173 0.1340\n#> K_3       0.88      0.88    0.92      0.56  7.6   0.0163 0.1436\n#> K_4       0.89      0.89    0.91      0.57  7.9   0.0157 0.1348\n#> K_5       0.88      0.88    0.91      0.54  7.1   0.0168 0.1327\n#> K_8       0.89      0.89    0.92      0.58  8.4   0.0149 0.1440\n#> K_10      0.96      0.96    0.96      0.81 24.9   0.0053 0.0044\n#>      med.r\n#> K_1   0.75\n#> K_2   0.75\n#> K_3   0.75\n#> K_4   0.75\n#> K_5   0.75\n#> K_8   0.82\n#> K_10  0.82\n#> \n#>  Item statistics \n#>        n raw.r std.r r.cor r.drop mean  sd\n#> K_1  125  0.94  0.94 0.956  0.914  3.2 1.9\n#> K_2  125  0.94  0.94 0.955  0.914  3.2 1.9\n#> K_3  125  0.89  0.89 0.877  0.846  3.3 1.9\n#> K_4  125  0.87  0.87 0.850  0.808  3.4 1.8\n#> K_5  125  0.93  0.94 0.943  0.906  3.2 1.7\n#> K_8  125  0.82  0.83 0.794  0.759  3.4 1.6\n#> K_10 125  0.24  0.24 0.077  0.064  3.6 1.9\n#> \n#> Non missing response frequency for each item\n#>         1    2    3    4    5    6    7 miss\n#> K_1  0.21 0.26 0.14 0.18 0.05 0.10 0.07    0\n#> K_2  0.19 0.29 0.11 0.18 0.07 0.08 0.08    0\n#> K_3  0.18 0.23 0.17 0.16 0.06 0.11 0.08    0\n#> K_4  0.17 0.22 0.18 0.17 0.09 0.10 0.08    0\n#> K_5  0.18 0.24 0.21 0.15 0.10 0.04 0.07    0\n#> K_8  0.14 0.18 0.19 0.28 0.10 0.06 0.06    0\n#> K_10 0.10 0.27 0.20 0.12 0.07 0.14 0.09    0\n\nLátható, hogy a Cronbach-alfa értéke 0,91, de javítható a 10. item eldobásával.\n\npsych::alpha(d[-c(7, 6, 9, 10)])\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = d[-c(7, 6, 9, 10)])\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd\n#>       0.96      0.96    0.96      0.81  25 0.0053  3.3 1.7\n#>  median_r\n#>      0.82\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.95  0.96  0.97\n#> Duhachek  0.95  0.96  0.97\n#> \n#>  Reliability if an item is dropped:\n#>     raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r\n#> K_1      0.95      0.95    0.94      0.79  19   0.0072 0.0034\n#> K_2      0.95      0.95    0.94      0.79  19   0.0072 0.0037\n#> K_3      0.96      0.96    0.95      0.81  22   0.0061 0.0054\n#> K_4      0.96      0.96    0.95      0.82  22   0.0060 0.0052\n#> K_5      0.95      0.95    0.94      0.79  19   0.0071 0.0050\n#> K_8      0.96      0.96    0.96      0.84  26   0.0053 0.0022\n#>     med.r\n#> K_1  0.80\n#> K_2  0.80\n#> K_3  0.81\n#> K_4  0.82\n#> K_5  0.79\n#> K_8  0.82\n#> \n#>  Item statistics \n#>       n raw.r std.r r.cor r.drop mean  sd\n#> K_1 125  0.95  0.95  0.95   0.93  3.2 1.9\n#> K_2 125  0.95  0.95  0.95   0.92  3.2 1.9\n#> K_3 125  0.90  0.90  0.87   0.86  3.3 1.9\n#> K_4 125  0.90  0.90  0.86   0.85  3.4 1.8\n#> K_5 125  0.95  0.95  0.94   0.92  3.2 1.7\n#> K_8 125  0.85  0.85  0.80   0.79  3.4 1.6\n#> \n#> Non missing response frequency for each item\n#>        1    2    3    4    5    6    7 miss\n#> K_1 0.21 0.26 0.14 0.18 0.05 0.10 0.07    0\n#> K_2 0.19 0.29 0.11 0.18 0.07 0.08 0.08    0\n#> K_3 0.18 0.23 0.17 0.16 0.06 0.11 0.08    0\n#> K_4 0.17 0.22 0.18 0.17 0.09 0.10 0.08    0\n#> K_5 0.18 0.24 0.21 0.15 0.10 0.04 0.07    0\n#> K_8 0.14 0.18 0.19 0.28 0.10 0.06 0.06    0\n\nLátható, hogy a Cronbach-alfa értéke 0,96.\nA kapott eredmények alapján az itemszelekciót ennél a lépésnél befejezhetjük. Az így kapott hat itemünk a statisztikai eredmények alapján egészen jól lefednek egy dimenziót, ezáltal használhatóak egy jelenség kérdőíves vizsgálatára.\n\n\n\nEgy kérdőív szerkesztésének problémái: főkomponens elemzés"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa-mi-is-az-a-munkahelyi-tolerancia",
    "href": "sec_fokomponens_elemzes.html#példa-mi-is-az-a-munkahelyi-tolerancia",
    "title": "2  Főkomponens elemzés",
    "section": "2.7 Példa: Mi is az a munkahelyi tolerancia?",
    "text": "2.7 Példa: Mi is az a munkahelyi tolerancia?\n\nA példa forrása: Münnich és mtsai. (2006) 2.5.3 Probléma\nKapcsolódó jamovi állomány: fokomp_kerdoivtervezet.omv\n\nEbben a példában azt vizsgáljuk meg, hogy ha a toleranciát munkahelyen vizsgáljuk, akkor mely jelenségeket, viselkedéseket kell figyelembe vennünk. Az adatok a fokomp_munkahelyi_tolarencia.xlsx állományban találhatók.\n\nd <- rio::import(\"adat/fokomp_munkahelyi_tolarencia.xlsx\")\nstr(d)\n#> 'data.frame':    155 obs. of  18 variables:\n#>  $ alkohol    : num  1 1 1 1 1 2 1 1 1 1 ...\n#>  $ kabitoszer : num  1 1 1 1 1 1 1 1 1 1 ...\n#>  $ hianyzik   : num  3 1 1 2 1 1 5 1 1 3 ...\n#>  $ dohanyzas  : num  4 5 1 3 1 4 5 1 5 5 ...\n#>  $ udvariatlan: num  3 1 5 2 2 1 1 1 1 1 ...\n#>  $ rendetlen  : num  3 1 5 2 2 1 1 1 1 3 ...\n#>  $ pontatlan  : num  3 1 5 3 2 1 1 1 1 3 ...\n#>  $ pletykas   : num  1 1 5 2 1 2 1 1 1 3 ...\n#>  $ harsany    : num  4 3 5 2 2 4 1 1 2 3 ...\n#>  $ tudalekos  : num  3 2 4 3 2 2 1 1 2 1 ...\n#>  $ csamcsog   : num  3 1 5 3 3 1 1 1 1 3 ...\n#>  $ lusta      : num  3 1 5 2 3 4 1 1 1 5 ...\n#>  $ szemtelen  : num  3 1 5 2 2 1 1 1 1 1 ...\n#>  $ bufog      : num  3 1 5 2 2 5 5 1 1 1 ...\n#>  $ felelotlen : num  3 1 5 2 2 1 1 1 1 1 ...\n#>  $ bosszuallo : num  2 2 3 2 1 1 1 1 1 1 ...\n#>  $ durva      : num  2 1 5 2 2 1 1 1 1 1 ...\n#>  $ agressziv  : num  2 1 5 1 2 1 1 1 1 1 ...\npsych::headTail(d)\n#>     alkohol kabitoszer hianyzik dohanyzas udvariatlan rendetlen\n#> 1         1          1        3         4           3         3\n#> 2         1          1        1         5           1         1\n#> 3         1          1        1         1           5         5\n#> 4         1          1        2         3           2         2\n#> ...     ...        ...      ...       ...         ...       ...\n#> 152       3          1        2         5           3         4\n#> 153       3          1        2         2           2         1\n#> 154       4          4        2         5           3         4\n#> 155       3          3        4         5           3         4\n#>     pontatlan pletykas harsany tudalekos csamcsog lusta szemt...\n#> 1           3        1       4         3        3     3      ...\n#> 2           1        1       3         2        1     1      ...\n#> 3           5        5       5         4        5     5      ...\n#> 4           3        2       2         3        3     2      ...\n#> ...       ...      ...     ...       ...      ...   ...      ...\n#> 152         2        2       5         3        4     5      ...\n#> 153         1        1       1         2        1     1      ...\n#> 154         5        5       3         2        2     3      ...\n#> 155         4        2       2         1        1     3      ...\n#>     bufog felelotlen bosszuallo durva agressziv\n#> 1       3          3          2     2         2\n#> 2       1          1          2     1         1\n#> 3       5          5          3     5         5\n#> 4       2          2          2     2         1\n#> ...   ...        ...        ...   ...       ...\n#> 152     4          2          1     3         1\n#> 153     1          1          1     1         1\n#> 154     4          5          5     5         5\n#> 155     1          2          1     2         2\n\nA fenti outputban látható, hogy adatokat találunk arról, hogy egyes viselkedéseket (pl. agresszivitás, dohányzás, durva beszéd stb.) mennyire tartanak zavarónak az emberek. Az adatokból a főkomponens analízis és a Cronbach-alfa segítségével pedig megnézhetjük, hogy az adatok összegezhetőek-e egy általános munkahelyi tolerancia főkomponensbe.\n\npsych::pca(d, rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>              PC1    h2   u2 com\n#> alkohol     0.54 0.295 0.71   1\n#> kabitoszer  0.62 0.386 0.61   1\n#> hianyzik    0.62 0.384 0.62   1\n#> dohanyzas   0.18 0.033 0.97   1\n#> udvariatlan 0.78 0.607 0.39   1\n#> rendetlen   0.80 0.633 0.37   1\n#> pontatlan   0.74 0.548 0.45   1\n#> pletykas    0.47 0.224 0.78   1\n#> harsany     0.41 0.170 0.83   1\n#> tudalekos   0.53 0.283 0.72   1\n#> csamcsog    0.70 0.492 0.51   1\n#> lusta       0.73 0.538 0.46   1\n#> szemtelen   0.83 0.692 0.31   1\n#> bufog       0.62 0.386 0.61   1\n#> felelotlen  0.77 0.587 0.41   1\n#> bosszuallo  0.73 0.532 0.47   1\n#> durva       0.73 0.535 0.46   1\n#> agressziv   0.75 0.559 0.44   1\n#> \n#>                 PC1\n#> SS loadings    7.88\n#> Proportion Var 0.44\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.11 \n#>  with the empirical chi square  578.76  with prob <  3e-56 \n#> \n#> Fit based upon off diagonal values = 0.93\n\nAz első főkomponens csupán az összvariancia 43%-át magyarázza. A fentiek alapján főleg a “dohányzás”, a “harsány” és a “pletykás” változó az, amely valamennyire „kilóg” a modellből, hiszen a hozzájuk tartozó súlyok a legkisebbek a fenti outputban.\n\nlibrary(tidyverse)\npsych::pca(d %>%\n    select(-dohanyzas, -harsany, -pletykas), rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>              PC1   h2   u2 com\n#> alkohol     0.56 0.31 0.69   1\n#> kabitoszer  0.64 0.41 0.59   1\n#> hianyzik    0.63 0.40 0.60   1\n#> udvariatlan 0.77 0.60 0.40   1\n#> rendetlen   0.78 0.61 0.39   1\n#> pontatlan   0.73 0.54 0.46   1\n#> tudalekos   0.50 0.25 0.75   1\n#> csamcsog    0.69 0.48 0.52   1\n#> lusta       0.72 0.52 0.48   1\n#> szemtelen   0.84 0.71 0.29   1\n#> bufog       0.62 0.38 0.62   1\n#> felelotlen  0.78 0.61 0.39   1\n#> bosszuallo  0.75 0.56 0.44   1\n#> durva       0.75 0.56 0.44   1\n#> agressziv   0.77 0.59 0.41   1\n#> \n#>                 PC1\n#> SS loadings    7.53\n#> Proportion Var 0.50\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.1 \n#>  with the empirical chi square  335.97  with prob <  4.6e-30 \n#> \n#> Fit based upon off diagonal values = 0.95\n\nÍgy az első főkomponens által magyarázott összvariancia már elérte az 50%-ot.\nVizsgáljuk meg a Cronbach-alfa értékét is.\n\nRcmdrMisc::reliability(cov(d))\n#> Alpha reliability =  0.9155 \n#> Standardized alpha =  0.9175 \n#> \n#> Reliability deleting each item in turn:\n#>              Alpha Std.Alpha r(item, total)\n#> alkohol     0.9130    0.9154         0.5086\n#> kabitoszer  0.9115    0.9138         0.5657\n#> hianyzik    0.9114    0.9136         0.5711\n#> dohanyzas   0.9233    0.9236         0.1696\n#> udvariatlan 0.9075    0.9093         0.7314\n#> rendetlen   0.9066    0.9087         0.7537\n#> pontatlan   0.9085    0.9106         0.6837\n#> pletykas    0.9149    0.9170         0.4295\n#> harsany     0.9160    0.9183         0.3788\n#> tudalekos   0.9136    0.9158         0.4791\n#> csamcsog    0.9090    0.9113         0.6587\n#> lusta       0.9086    0.9105         0.6862\n#> szemtelen   0.9065    0.9083         0.7730\n#> bufog       0.9115    0.9136         0.5714\n#> felelotlen  0.9084    0.9105         0.6847\n#> bosszuallo  0.9090    0.9113         0.6599\n#> durva       0.9087    0.9111         0.6699\n#> agressziv   0.9084    0.9109         0.6764\n\nA fenti output alapján már viszonylag magas a Cronbach-alfa értéke (0,915), de látható, hogy a “dohányzás” eltávolításával tovább növelhető.\n\nRcmdrMisc::reliability(cov(d %>%\n    select(-dohanyzas)))\n#> Alpha reliability =  0.9233 \n#> Standardized alpha =  0.9236 \n#> \n#> Reliability deleting each item in turn:\n#>              Alpha Std.Alpha r(item, total)\n#> alkohol     0.9222    0.9226         0.4892\n#> kabitoszer  0.9202    0.9206         0.5673\n#> hianyzik    0.9205    0.9208         0.5573\n#> udvariatlan 0.9161    0.9161         0.7331\n#> rendetlen   0.9155    0.9156         0.7493\n#> pontatlan   0.9170    0.9172         0.6900\n#> pletykas    0.9234    0.9238         0.4320\n#> harsany     0.9249    0.9253         0.3684\n#> tudalekos   0.9220    0.9224         0.4883\n#> csamcsog    0.9177    0.9180         0.6629\n#> lusta       0.9173    0.9174         0.6856\n#> szemtelen   0.9149    0.9148         0.7856\n#> bufog       0.9205    0.9205         0.5674\n#> felelotlen  0.9164    0.9168         0.7100\n#> bosszuallo  0.9173    0.9178         0.6777\n#> durva       0.9175    0.9179         0.6699\n#> agressziv   0.9169    0.9174         0.6909\n\nA fenti output alapján a Cronbach-alfa értéke (0,923), de látható, hogy a “harsany” eltávolításával tovább növelhető.\n\nRcmdrMisc::reliability(cov(d %>%\n    select(-dohanyzas, -harsany)))\n#> Alpha reliability =  0.9249 \n#> Standardized alpha =  0.9253 \n#> \n#> Reliability deleting each item in turn:\n#>              Alpha Std.Alpha r(item, total)\n#> alkohol     0.9238    0.9245         0.5019\n#> kabitoszer  0.9215    0.9220         0.5903\n#> hianyzik    0.9221    0.9225         0.5694\n#> udvariatlan 0.9178    0.9180         0.7306\n#> rendetlen   0.9173    0.9176         0.7419\n#> pontatlan   0.9188    0.9192         0.6890\n#> pletykas    0.9262    0.9269         0.4018\n#> tudalekos   0.9246    0.9254         0.4601\n#> csamcsog    0.9199    0.9204         0.6470\n#> lusta       0.9195    0.9198         0.6660\n#> szemtelen   0.9164    0.9165         0.7874\n#> bufog       0.9226    0.9228         0.5616\n#> felelotlen  0.9177    0.9182         0.7236\n#> bosszuallo  0.9184    0.9191         0.6989\n#> durva       0.9188    0.9195         0.6832\n#> agressziv   0.9182    0.9188         0.7053\n\nA fenti output alapján a Cronbach-alfa értéke (0,925), de látható, hogy a “pletykas” eltávolításával tovább növelhető.\n\nRcmdrMisc::reliability(cov(d %>%\n    select(-dohanyzas, -harsany, -pletykas)))\n#> Alpha reliability =  0.9262 \n#> Standardized alpha =  0.9269 \n#> \n#> Reliability deleting each item in turn:\n#>              Alpha Std.Alpha r(item, total)\n#> alkohol     0.9254    0.9262         0.5101\n#> kabitoszer  0.9231    0.9238         0.5931\n#> hianyzik    0.9236    0.9242         0.5752\n#> udvariatlan 0.9193    0.9198         0.7250\n#> rendetlen   0.9189    0.9195         0.7319\n#> pontatlan   0.9206    0.9212         0.6769\n#> tudalekos   0.9269    0.9280         0.4410\n#> csamcsog    0.9215    0.9222         0.6453\n#> lusta       0.9211    0.9217         0.6617\n#> szemtelen   0.9174    0.9177         0.7958\n#> bufog       0.9243    0.9246         0.5652\n#> felelotlen  0.9190    0.9197         0.7274\n#> bosszuallo  0.9198    0.9207         0.7007\n#> durva       0.9200    0.9208         0.6947\n#> agressziv   0.9194    0.9202         0.7133\n\nAz eredmények alapján az adatredukciót ezzel a lépéssel be is fejezhetjük. A modellben maradt változókat tekinthetjük az általános munkahelyi toleranciát lefedő viselkedéseknek.\n\n\n\nMi is az a munkahelyi tolerancia: főkomponens elemzés"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa-egy-elégedettségvizsgálat-tanulságai",
    "href": "sec_fokomponens_elemzes.html#példa-egy-elégedettségvizsgálat-tanulságai",
    "title": "2  Főkomponens elemzés",
    "section": "2.8 Példa: Egy elégedettségvizsgálat tanulságai",
    "text": "2.8 Példa: Egy elégedettségvizsgálat tanulságai\n\nA példa forrása: Münnich és mtsai. (2006) 2.5.4 Probléma\nKapcsolódó jamovi állomány: fokomp_munkahelyi_elegedettseg.omv\n\nEbben a példánkban azt a kérdést járjuk körbe, hogy mely tényezők befolyásolják azt, hogy elégedett-e valaki az egyetemi oktatással, mely tényezők kerülhetnének be egy tolerancia kérdőív itemei közé.\nA fokomp_munkahelyi_elegedettseg.xlsx adatbázis a következő kérdésekre adott válaszokat tartalmazza:\nMennyire vagy elégedett…\n\naz egyetemen szerzett ismeretek felhasználhatóságával? (DK210)\naz egyetem ösztönző, fejlesztő tevékenységével? (DK212)\naz egyetemen az információ áramlással? (DK214)\na szakodon tanított tárgyakkal? (DK215)\na tanárok előadókészségével? (DK219)\na tanárok szakmai felkészültségével? (DK220)\naz oktatóid tanítási módszereivel? (DK221)\na kutatási lehetőségekkel? (DK217)\n\na szakod által adott elhelyezkedési lehetőségekkel? (DK218)\n\n\nd <- rio::import(file = \"adat/fokomp_munkahelyi_elegedettseg.xlsx\")\nstr(d)\n#> 'data.frame':    622 obs. of  9 variables:\n#>  $ DK210: num  6 3 20 13 5 5 10 16 14 5 ...\n#>  $ DK212: num  6 7 12 10 7 5 10 13 15 10 ...\n#>  $ DK214: num  11 1 16 14 10 7 10 17 14 13 ...\n#>  $ DK215: num  13 16 18 14 12 8 10 18 11 14 ...\n#>  $ DK217: num  4 10 19 10 5 15 10 15 9 18 ...\n#>  $ DK218: num  11 15 17 10 3 15 10 18 10 16 ...\n#>  $ DK219: num  10 8 17 11 9 2 10 18 13 19 ...\n#>  $ DK220: num  10 18 16 12 13 11 15 20 15 19 ...\n#>  $ DK221: num  10 10 17 13 7 5 10 15 15 17 ...\npsych::headTail(d)\n#>     DK210 DK212 DK214 DK215 DK217 DK218 DK219 DK220 DK221\n#> 1       6     6    11    13     4    11    10    10    10\n#> 2       3     7     1    16    10    15     8    18    10\n#> 3      20    12    16    18    19    17    17    16    17\n#> 4      13    10    14    14    10    10    11    12    13\n#> ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n#> 619     2    13    20     5    10     5    14    16    17\n#> 620    16    17    11    18    20    18    15    16    19\n#> 621    19    17     8     9    11    15    16    17    16\n#> 622    13    14     7    11    11     4     9    15    10\n\n\npsych::pca(d, rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>        PC1   h2   u2 com\n#> DK210 0.71 0.50 0.50   1\n#> DK212 0.77 0.59 0.41   1\n#> DK214 0.55 0.30 0.70   1\n#> DK215 0.74 0.54 0.46   1\n#> DK217 0.59 0.35 0.65   1\n#> DK218 0.40 0.16 0.84   1\n#> DK219 0.79 0.62 0.38   1\n#> DK220 0.70 0.49 0.51   1\n#> DK221 0.78 0.61 0.39   1\n#> \n#>                 PC1\n#> SS loadings    4.17\n#> Proportion Var 0.46\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.09 \n#>  with the empirical chi square  342.93  with prob <  1.8e-56 \n#> \n#> Fit based upon off diagonal values = 0.95\n\nAz első főkomponens által magyarázott variancia az összvariancia 46%-át teszi ki. Vizsgáljuk meg mely változók járulnak kevésbé hozzá az első főkomponens kialakításához. A DK214, DK217 és a DK218-as kérdés „lóg ki” a sorból, hiszen a hozzájuk tartozó főkomponenssúlyok rendre alacsonyak.\n\npsych::pca(d %>%\n    select(-DK214, -DK217, -DK218), rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>        PC1   h2   u2 com\n#> DK210 0.71 0.51 0.49   1\n#> DK212 0.74 0.55 0.45   1\n#> DK215 0.74 0.55 0.45   1\n#> DK219 0.83 0.68 0.32   1\n#> DK220 0.74 0.54 0.46   1\n#> DK221 0.82 0.67 0.33   1\n#> \n#>                 PC1\n#> SS loadings    3.51\n#> Proportion Var 0.59\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.11 \n#>  with the empirical chi square  208.36  with prob <  5.8e-40 \n#> \n#> Fit based upon off diagonal values = 0.96\n\naz első főkomponens által magyarázott variancia immár elérte az 50%-ot (pontosan 59%), vagyis magyarázóértéke ezen mutató alapján elégséges. A komponens mátrixban szereplő korrelációs értékek megfelelőek.\nVizsgáljuk meg a Cronbach-alfa értékét is.\n\nRcmdrMisc::reliability(cov(d))\n#> Alpha reliability =  0.8405 \n#> Standardized alpha =  0.8478 \n#> \n#> Reliability deleting each item in turn:\n#>        Alpha Std.Alpha r(item, total)\n#> DK210 0.8188    0.8280         0.6014\n#> DK212 0.8087    0.8194         0.6872\n#> DK214 0.8374    0.8444         0.4424\n#> DK215 0.8164    0.8247         0.6302\n#> DK217 0.8315    0.8396         0.4911\n#> DK218 0.8512    0.8565         0.3223\n#> DK219 0.8126    0.8202         0.6595\n#> DK220 0.8232    0.8301         0.5743\n#> DK221 0.8138    0.8208         0.6582\n\nA fenti output alapján a Cronbach-alfa értéke (0,841), de látható, hogy a “DK218” eltávolításával tovább növelhető.\n\nRcmdrMisc::reliability(cov(d %>%\n    select(-DK218)))\n#> Alpha reliability =  0.8512 \n#> Standardized alpha =  0.8565 \n#> \n#> Reliability deleting each item in turn:\n#>        Alpha Std.Alpha r(item, total)\n#> DK210 0.8336    0.8404         0.5886\n#> DK212 0.8220    0.8302         0.6807\n#> DK214 0.8533    0.8570         0.4454\n#> DK215 0.8282    0.8345         0.6380\n#> DK217 0.8481    0.8528         0.4828\n#> DK219 0.8231    0.8285         0.6758\n#> DK220 0.8346    0.8395         0.5905\n#> DK221 0.8236    0.8286         0.6797\n\nA fenti output alapján a Cronbach-alfa értéke (0,851), de látható, hogy a “DK214” eltávolításával tovább növelhető.\n\nRcmdrMisc::reliability(cov(d %>%\n    select(-DK218, -DK214)))\n#> Alpha reliability =  0.8533 \n#> Standardized alpha =  0.857 \n#> \n#> Reliability deleting each item in turn:\n#>        Alpha Std.Alpha r(item, total)\n#> DK210 0.8359    0.8410         0.5953\n#> DK212 0.8274    0.8332         0.6520\n#> DK215 0.8303    0.8350         0.6350\n#> DK217 0.8564    0.8576         0.4763\n#> DK219 0.8206    0.8244         0.6975\n#> DK220 0.8367    0.8402         0.5945\n#> DK221 0.8221    0.8256         0.6943\n\nA fenti output alapján a Cronbach-alfa értéke (0,853), de látható, hogy a “DK217” eltávolításával tovább növelhető.\n\nRcmdrMisc::reliability(cov(d %>%\n    select(-DK218, -DK214, -DK217)))\n#> Alpha reliability =  0.8564 \n#> Standardized alpha =  0.8576 \n#> \n#> Reliability deleting each item in turn:\n#>        Alpha Std.Alpha r(item, total)\n#> DK210 0.8419    0.8440         0.5954\n#> DK212 0.8363    0.8377         0.6286\n#> DK215 0.8354    0.8374         0.6280\n#> DK219 0.8194    0.8202         0.7121\n#> DK220 0.8398    0.8406         0.6064\n#> DK221 0.8208    0.8217         0.7090\n\nA Cronbach-alfa értékét már nem tudjuk tovább növelni a változók eltávolításával.\nÖsszegezve, az eredmények alapján csupán a szak által adott elhelyezkedési lehetőségek, az információáramlás és a kutatási lehetőségek nem kerülnek be az egyetemi oktatással való elégedettség mérőszámába, míg a többi változó eredményei igen.\n\n\n\nEgy elégedettségvizsgálat tanulságai: főkomponens elemzés\n\n\n\n\n\n\nHorn, J. L. (1965). A rationale and test for the number of factors in factor analysis. Psychometrika, 30, 179–185. https://doi.org/10.1007/BF02289447\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika"
  },
  {
    "objectID": "sec_megbizhatosag_elemzes.html#cronbach-alfa-belső-konzisztencia-mérése",
    "href": "sec_megbizhatosag_elemzes.html#cronbach-alfa-belső-konzisztencia-mérése",
    "title": "3  Megbízhatóság elemzés",
    "section": "3.1 Cronbach-alfa – belső konzisztencia mérése",
    "text": "3.1 Cronbach-alfa – belső konzisztencia mérése\nFőkomponens elemzés segítségével könnyen tudunk több változót - viszonylag csekély veszteséggel - egyetlen változóba tömöríteni, ezért gyakran használják kérdőívek itemeinek szelekciójára, valamint megbízhatóság (reliabilitás) vizsgálatra. A klasszikus tesztelmélet keretein belül azonban a tesztek megbízhatóságának (reliabilitásának) több lehetséges mutatója is létezik.\nCronbach 1951-es munkájában publikálta azon nézetét, hogy a korábbi egyszerű tesztfelezéses eljárás helyett egy annál tökéletesebb mutatót kellene használni a tesztek megbízhatóságának indikátoraként. Ha az itemek száma alacsony vagy az itemek közötti átlagos korreláció alacsony, akkor csökkenni fog a Cronbach-féle alfa értéke is. Az is egyértelmű, hogy az itemek közötti alacsony korreláció arra enged következtetni, hogy a teszt itemjei nem egy és ugyanazon dolog vizsgálatára szolgálnak, a belőlük képzendő tesztérték nem alkalmas sem elméleti, sem pedig gyakorlati felhasználásra.\nAz ómega (McDonald \\(\\omega\\)) korrigálja a Cronbach-alfa torzítását, érdemes elvégezni az elemzést ezzel a mutatóval is (Kárász és mtsai., 2022; Malkewitz és mtsai., 2023)."
  },
  {
    "objectID": "sec_megbizhatosag_elemzes.html#példa-real-tárgyak-iránti-fogékonyság",
    "href": "sec_megbizhatosag_elemzes.html#példa-real-tárgyak-iránti-fogékonyság",
    "title": "3  Megbízhatóság elemzés",
    "section": "3.2 Példa: Real tárgyak iránti fogékonyság",
    "text": "3.2 Példa: Real tárgyak iránti fogékonyság\nEgy fiktív adatbázis 9 tanuló iskolai jegyeit tartalmazza reál tantárgyakból (matematika, fizika, kémia, informatika) (megbizhatosag_tantargyak.xlsx). Vizsgáljuk meg, ha a reál tantárgyak iránti fogékonyságot ezzel a 4 érdemjeggyel mérnénk, akkor ez megbízhatóság szempontjából alkalmas mérőeszköz lenne.\n\nreal <- rio::import(file = \"adat/megbizhatosag_tantargyak.xlsx\")\nstr(real)\n#> 'data.frame':    9 obs. of  4 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5\n#>  $ fizika     : num  5 5 3 3 4 2 4 3 5\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5\n\nA Cronbach alfa meghatározását végezhetjük a {psych} csomag alpha() függvényével.\n\npsych::alpha(real)  # Cronbach-alfa\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = real)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.97      0.97    0.98      0.89  33 0.017  3.7 1.4    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.91  0.97  0.99\n#> Duhachek  0.93  0.97  1.00\n#> \n#>  Reliability if an item is dropped:\n#>             raw_alpha std.alpha G6(smc) average_r S/N alpha se\n#> matek            0.94      0.95    0.95      0.86  18    0.032\n#> fizika           0.97      0.98    0.97      0.93  39    0.015\n#> informatika      0.96      0.97    0.97      0.92  33    0.019\n#> kemia            0.94      0.95    0.96      0.86  19    0.029\n#>              var.r med.r\n#> matek       0.0070  0.89\n#> fizika      0.0013  0.95\n#> informatika 0.0016  0.93\n#> kemia       0.0084  0.87\n#> \n#>  Item statistics \n#>             n raw.r std.r r.cor r.drop mean  sd\n#> matek       9  0.99  0.98  0.98   0.97  3.6 1.6\n#> fizika      9  0.92  0.93  0.91   0.88  3.8 1.1\n#> informatika 9  0.95  0.94  0.93   0.90  3.6 1.5\n#> kemia       9  0.98  0.98  0.98   0.96  3.9 1.5\n#> \n#> Non missing response frequency for each item\n#>                1    2    3    4    5 miss\n#> matek       0.11 0.22 0.11 0.11 0.44    0\n#> fizika      0.00 0.11 0.33 0.22 0.33    0\n#> informatika 0.11 0.22 0.00 0.33 0.33    0\n#> kemia       0.11 0.00 0.33 0.00 0.56    0\n\nA McDonald \\(\\omega\\) értékét kiszámolhatjuk a {psych} csomag omega() függvényével.\n\npsych::omega(real, plot = F)  # McDonald-ómega\n#> Omega \n#> Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, ...\n#>     digits = digits, title = title, sl = sl, labels = labels, \n#>     plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, o...\n#>     covar = covar)\n#> Alpha:                 0.97 \n#> G.6:                   0.98 \n#> Omega Hierarchical:    0.95 \n#> Omega H asymptotic:    0.96 \n#> Omega Total            0.99 \n#> \n#> Schmid Leiman Factor loadings greater than  0.2 \n#>                g   F1*   F2*   F3*   h2   u2   p2\n#> matek       0.97        0.28       0.99 0.01 0.94\n#> fizika      0.89  0.29             0.92 0.08 0.86\n#> informatika 0.91        0.28       0.95 0.05 0.87\n#> kemia       0.96  0.29             0.99 0.01 0.94\n#> \n#> With Sums of squares  of:\n#>    g  F1*  F2*  F3* \n#> 3.48 0.17 0.16 0.04 \n#> \n#> general/max  21.07   max/min =   4.03\n#> mean percent general =  0.9    with sd =  0.04 and cv of  0.05 \n#> Explained Common Variance of the general factor =  0.91 \n#> \n#> The degrees of freedom are -3  and the fit is  0 \n#> The number of observations was  9  with Chi Square =  0  with...\n#> The root mean square of the residuals is  0 \n#> The df corrected root mean square of the residuals is  NA\n#> \n#> Compare this with the adequacy of just a general factor and n...\n#> The degrees of freedom for just the general factor are 2  and...\n#> The number of observations was  9  with Chi Square =  5.14  w...\n#> The root mean square of the residuals is  0.05 \n#> The df corrected root mean square of the residuals is  0.08 \n#> \n#> RMSEA index =  0.401  and the 10 % confidence intervals are  ...\n#> BIC =  0.75 \n#> \n#> Measures of factor score adequacy             \n#>                                                  g  F1*  F2* ...\n#> Correlation of scores with factors            0.98 0.89 0.86 ...\n#> Multiple R square of scores with factors      0.95 0.78 0.74 ...\n#> Minimum correlation of factor score estimates 0.90 0.57 0.48 ...\n#> \n#>  Total, General and Subset omega for each subset\n#>                                                  g  F1*  F2* F3*\n#> Omega total for total scores and subscales    0.99 0.98 0.99  NA\n#> Omega general for total scores and subscales  0.95 0.89 0.91  NA\n#> Omega group for total scores and subscales    0.04 0.09 0.08  NA\n\nA fenti elemzéseket jamovi-ban a Factor / Reliability Analysis menüpont segítségével végezhetjük el.\n\n\n\nMegbízhatóság elemzés jamovi-ban\n\n\nA fenti megbízhatósági elemzések azt mutatják, hogy a négy tantárgy alfa értéke 0,966, ami egy igen jó érték, hiszen közel van 1-hez (jamovi-ban: Scale Reliability Statistics). Az Item Reliability Statistics táblázat oszlopában szereplő értékek azt mutatják, mi történik, ha egy változót kiveszünk a modellből. Láthatjuk, hogy egyedül a fizika változó értéke növelné az alfát, de a növekedés mértéke elenyésző lenne, tehát nem éri meg eltávolítani a változót, hiszen minél több információnk van egy személyről, annál jobb.\n\n\n\n\nCarver, C. S. és Scheier, M. F. (2006). Személyiségpszichológia. Osiris Kiadó.\n\n\nKárász, J. T., Nagy, O. N., Széll, K. és Takács, S. (2022). Cronbach-alfa: vele vagy nélküle? Magyar Pszichológiai Szemle, 77, 81–98. https://doi.org/10.1556/0016.2022.00004\n\n\nMalkewitz, C. P., Schwall, P., Meesters, C. és Hardt, J. (2023). Estimating reliability: A comparison of Cronbach’s α, McDonald’s ωt and the greatest lower bound. Social Sciences & Humanities Open, 7, 100368. https://doi.org/10.1016/j.ssaho.2022.100368\n\n\nNagy, O. N. (2006). A pszichológiai tesztek reliabilitása. In S. Rózsa, O. N. Nagy, és A. Oláh (Szerk.), A pszichológiai mérés alapjai. Elmélet, módszer és gyakorlati alkalmazás. Bölcsész Konzorcium. https://mek.oszk.hu/05500/05536/05536.pdf"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#a-főkomponens-elemzés-és-a-faktorelemzés-összehasonlítása",
    "href": "sec_feltaro_faktorelemzes.html#a-főkomponens-elemzés-és-a-faktorelemzés-összehasonlítása",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.1 A főkomponens elemzés és a faktorelemzés összehasonlítása",
    "text": "4.1 A főkomponens elemzés és a faktorelemzés összehasonlítása\n\nA főkomponens elemzés során az adatok teljes varianciáját vesszük figyelembe, míg faktorelemzés során a faktorokat csak a közös variancia alapján becsüljük. A két eljárás egyébként nagyon hasonló elvekre épül.\n\nFőkomponens elemzés során a korrelációs mátrix átlójában lévő 1-esek összege adja teljes varianciát, ami teljes egészében bekerül a faktormodellbe. Ezért ez az eljárás akkor javasolt, ha a fő cél, hogy meghatározzuk azon főkomponensek (faktorok) legkisebb számát, amelyek a legtöbb varianciát magyarázzák. Ezek a faktorok később jól alkalmazhatók többváltozós elemzésekben. Összegezve: a főkomponens elemzésnél részinformációkat próbálunk összegezni a lehető legkisebb információveszteséggel (vagyis a variancia maximalizálásával).\nAz ún. közös faktorelemzésnél a faktorokat csak a közös variancia alapján becsüljük, vagyis a kommunalitások kerülnek a korrelációs mátrix átlójába (ezek 1-nél kisebb számok). Összegezve a faktorelemzés általános célja egy látens, lineáris struktúra feltárása manifeszt változók segítségével."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#fogalmak",
    "href": "sec_feltaro_faktorelemzes.html#fogalmak",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.2 Fogalmak",
    "text": "4.2 Fogalmak\nA főkomponens- és fakorelemzésben a következő fogalmak fordulnak elő (a komponens és a faktor szavak felcserélhetők, attól függően, hogy főkomponens- vagy fakorelemzésről van szó).\n\nKommuninalitás: a variancia azon hányada, amelyen egy változó osztozik a többi elemzésbe vont változóval. Ez egyben a közös faktorok által magyarázott variancia aránya.\nSajátérték: Az egyes faktorok által magyarázott teljes varianciát fejezi ki.\nFaktorsúly: A változók és a faktorok közötti közönséges korreláció.\nFaktormátrix: Valamennyi változónak az összes előállított faktorra vonatkozó faktorsúlyát tartalmazza.\nFaktorértékek: Az előállított faktoroknak az egyes megkérdezettekre vonatkozóan becsült értékei.\nSajátértékábra (scree-plot, kőtörmelék ábra): A sajátértékek ábrázolása az előállított faktorok sorszámának függvényében.\nVarianciahányad: A teljes variancia egy adott faktornak tulajdonított része százalékban kifejezve."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#a-faktormodell",
    "href": "sec_feltaro_faktorelemzes.html#a-faktormodell",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.3 A faktormodell",
    "text": "4.3 A faktormodell\nA főkomponens és faktorelemzés annyiban hasonlít a többszörös regressziószámításhoz, hogy minden változót kifejezhető a háttérben meghúzódó faktorok lineáris kombinációjaként. Minden egyes változó kifejezhető kisszámú közös faktor és egy egyedi faktor segítségével. Ezek a faktorok nem figyelhetők meg közvetlenül. Standardizált kiinduló változók esetén a faktormodell így írható fel:\n\n\\(X_i=A_{i1} F_1+A_{i2} F_2+\\dots+ A_{im} F_m+V_i U_i\\), ahol\n\n\\(X_i\\) az \\(i.\\) standardizált változó\n\\(A_{i1}\\) az \\(i.\\) változó \\(j.\\) közös faktorra vonatkozó többszörös standardizált parciális regressziós együtthatója\n\\(F_j\\) a \\(j.\\) közös faktor\n\\(V_i\\) az \\(i.\\) változó \\(j.\\) egyedi faktorra vonatkozó többszörös standardizált parciális regressziós együtthatója\n\\(U_i\\) az \\(i.\\) változó egyedi faktora\n\\(m\\) a közös faktorok száma.\n\n\nAz egyedi faktorok egymással és a közös faktorokkal is korrelálatlanok. A közös faktorok kifejezhetők a megfigyelt változók lineáris kombinációiként:\n\n\\(F_i=W_{i1} X_1+W_i2 X_2+\\dots+ W_im X_m+\\dots+ W_ik X_k\\), ahol\n\n\\(F_i\\) az \\(i.\\) faktor becslése\n\\(W_i\\) súly vagy a faktorérték együtthatója\n\\(k\\) a változók száma\n\n\nA súlyokat vagy faktorérték együtthatókat úgy is meg lehet választani, hogy az első faktor magyarázza a teljes variancia legnagyobb részét, a második faktor a második legnagyobb részét és így tovább, valamint, hogy a faktorok korrelálatlanok legyenek egymással. Ez történik főkomponens elemzés esetén."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#a-faktorelmzés-menete",
    "href": "sec_feltaro_faktorelemzes.html#a-faktorelmzés-menete",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.4 A faktorelmzés menete",
    "text": "4.4 A faktorelmzés menete\n1. A probléma megfogalmazása\nA kutató arra volt kíváncsi, milyen előnyöket keresnek a fogyasztók a fogrémvásárlásnál. Egy 30 fős mintán a válaszadókat arra kérték, hogy jelezzék, mennyire értenek egyet a következő állításokkal (1 = egyáltalán nem ért egyet; 7 = teljes mértékben egyetért)\n\nv1: Fontos, hogy olyan fogkrémet vásároljak, amellyel megelőzhető a fogszuvasodás.\nv2: Az olyan fogkrémeket szeretem, amely fényessé teszi a fogaimat.\nv3: Egy fogkrémnek erősítenie kell a fogínyt.\nv4: Az olyan fogkrémeket szeretem, amely friss leheletet biztosít.\nv5: A fog romlásának megelőzése számomra nem fontos elvárás.\nv6: A legfontosabb szempont a fogkrém vásárlásánál a szép fog.\n\n2. A korrelációs mátrix előállítása\nA korrelációs mátrix előállítása során arra számítunk, hogy azok a változók, amelyek között magas a korreláció, ugyanazzal a faktorral fognak korrelálni.\n\n\n\nKorrelációs mátrix\n\n\nA fogkrémvásárlás során keresett előnyök korrelációs mátrix tanulmányozásával látható:\n\nviszonylag magas a korreláció a v1 (fogszuvasodás megelőzése), v3 (erős fogíny) és v5 (a fog romlásának megelőzése) között. Arra számítunk, hogy ezek a változók ugyanazokkal a faktorokkal fognak korrelálni.\nviszonylag magas a korreláció a v2 (fényes fogak), v4 (friss lehelet) és v6 (szép fogak) változók között, ezek is feltehetőleg ugyanazokkal a faktorokkal fognak korrelálni.\n\n3. Az alkalmazási feltételek ellenőrzése\nAhhoz, hogy a faktorelemzés alkalmazható legyen, a változóknak korrelálniuk kell egymással. Erről meggyőződhetünk kétféle objektív módszerrel is:\n\nBartlett-féle szferikus próba: nullhipotézise szerint a korrelációs mátrix egységmátrix (a változók korrelálatlanok), azaz az átlón kívül minden elem nulla. Amennyiben a nullhipotézis nem vethető el, a faktorelemzés alkalmazhatósága megkérdőjelezhető.\nKaiser-Meyer-Olkin-féle megfelelőségi mutató: a megfigyelt korrelációs együtthatók nagyságát viszonyítja a parciális korrelációs együtthatók nagyságához. Az alacsony KMO-mutató azt jelzi, hogy a változópárok közötti korreláció nem magyarázható más változókkal, így a faktorelemzés nem megfelelő módszer. Általában 0,5 fölött érték kívánatos.\n\nJamovi-ban a Factor / Exploratory Factor Analysis menüpontban tudjuk a fenti vizsgálatokat elvégezni.\n A Bartlett-féle szferikus próba szerint a pupulációban a korrelációs mátrix nem egységmátrix (ez számunkra kedvező), valamint a KMO-érték 0,66, ameéy elég magas (>0,5), így megállapíthatjuk, hogy a faktorelemzés alkalmas módszer a korrelációs mátrix elemzésére.\n4. A faktorelemzés módszerének meghatározása\nA faktorelemzés egyes módszerei abban különböznek egymástól, hogy milyen módon határozzák meg a súlyokat vagy faktorérték együtthatókat.\nA jamovi 3 módszert ismer a közös faktorok becslésére:\n\nPrincipal axis – főtengelyelemzés\nMinimum residuals\nMaximum likelihood\n\n5. A faktorok számának meghatározása\nA faktorelemzés akkor ér célt, ha a változók számánál kevesebb számú közös faktort hozunk létre. De mi legyen ez a szám. Több eljárás létezik. Ezeket részletesen a főkomponens elemzés során bemutattuk. Itt csak felsoroljuk őket:\n\nHorn-féle párhuzamos analízis (jamovi-ban: Based on parallel analysis)\nA priori meghatározás (jamovi-ban: Fixed number)\nSajátértéken alapuló megoldás (jamovi-ban: Based on eigenvalue)\nSajátértékábrán (scree-plot, kőtörmelék ábra) alapuló meghatározás (jamovi-ban: Scree plot)\nMagyarázott varianciahányadon alapuló meghatározás (jamovi-ban: Component summary)\n\n6. A faktorok forgatása\nA faktorelemzés fontos eredménye a faktormátrix (jamovi-ban: Factor Loadings).\n\n\n\nA faktormátrix\n\n\nA faktormátrix tartalmazza azokat az együtthatókat, amelyekkel a standardizált változókat ki lehet fejezni a faktorokkal. Ezeket az együtthatókat faktorsúlyoknak nevezzük, a faktorok és a faktorsúlyok közötti korrelációt mutatják. A magas abszolút értékű együttható azt jelzi, hogy a faktor és a változó szorosan összefügg. A faktormátrix együttható alapján lehet a faktorokat értelmezni.\nA kiinduló vagy rotálatlan faktormátrix jelzi ugyan az egyes változók és a faktorok kapcsolatát, de ritkán eredményez könnyen értelmezhető faktorokat. Ennek főképp az az oka, hogy a faktorok túl sok változóval korrelálnak. (A rotálatlan faktormátrix beállításához jamovi-ban a Rotation: None beállítást használjuk.)\nA faktorok forgatásával a faktormátrix egyszerűbbé, könnyebben értelmezhetővé válik. A faktorok forgatásával szeretnénk elérni:\n\nminden faktor csak néhány vátozóra rendelkezzen szignifikánsan nem nulla súllyal\nminden változónak lehetőleg egy faktorral legyen nem nulla, azaz szignifikáns faktorsúlya.\n\nA forgatás nem érinti a kommunalitásokat és a magyarázott varianciahányadot, azonban az egy faktor által magyarázott varianciahányad változik (és természetesen a faktorsúlyok is).\nA forgatási módszereket érdemes jól megválasztani, mert más-más faktorok azonosításához vezetnek.\nAz ortogonális (derékszögű) forgatási eljárások egymással nem korreláló faktorokat eredményeznek.\n\nEzek közül az egyik legnépszerűbb a Varimax eljárás, amely minimalizálja a nagy faktorsúllyal rendelkező változók számát, így segíti a faktorok értelmezését. A magyarázott variancia egyenletesen próbálja elosztani a faktorok között.\nA Quartimax eljárás első faktorként egy általános faktort faktort hoz létre, amellyel szinte mindegyik változó magasan korrelál.\n\nA ferdeszögű forgatási eljárások során a tengelyek hegyeszöget zárnak be egymással, és a kapott faktorok korrelálni fognak egymással. Ferdeszögű forgatást akkor kell használni, ha feltételezhető, hogy a sokaságban a faktorok erősen összefüggenek.\n\nA Promax eljárás gyorsan lefuttatható, amely főképp nagy adatbázisoknál jelent előnyt.\nA Simplimax a Promax egy módosított formája.\nAz Oblimin eljárás a tengelyek egymással bezárt szögét fokozatosan változtatja, ami egyben a faktorok korreláltságát is meghatározza.\n\n7. A faktorok értelmezése\nAz értelmezést megkönnyíti, ha meghatározzuk azokat a változókat, amelyeknek ugyanazon a faktorra nagy a súlyuk. A faktort a magas faktorsúlyú változók alapján lehet értelmezni.\nAz 1. faktornak magasabb az együtthatói a v1 (fugszuvasodás megelőzése), v3 (erős fogíny) változókkal, negatív az együttható a v5 (a fog romlásának megeleőzése nem fontos) változó esetében. Ezt a faktort az “egészséggel kapcsolatos előnyöknek” nevezhetjük. A 2. faktor a v2 (fényes fogak), a v4 (friss lehelet), v6 (szép fogak) változókkal függ össze. Ezt a 2. faktort “társadalmi előnyök”-nek nevezhetjük.\nÖsszegezve, a fogyasztók feltehetőleg két fő előnyt keresnek a fogkrémvásárlás során: egészséggel kapcsolatos és társadalmi előnyöket.\n8. A faktorértékek kiszámítása\nA faktorelemzésnek önmagában is van értelme, hiszen látens változók azonosításához vezet, azonban hasznos lehet a későbbi elemzések számára a faktorértékek kiszámítása minden egyes megkérdezettre. A faktor az eredeti változók lineáris kombinációja. A standardizált változó értékeinek és a megfelelő faktorérték-együtthatónak a szorzata adja a faktorétéket, amely jelen példában minden válaszadóra két faktorértéket jelent. A faktorérték csak főkomponens elemzés esetében lehet pontosan kiszámítani, egyébként csak közelítő értékeket kapunk.\n\n\n\nFaktorértékek kiszámítása"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#illeszkedési-mutatók",
    "href": "sec_feltaro_faktorelemzes.html#illeszkedési-mutatók",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.5 Illeszkedési mutatók",
    "text": "4.5 Illeszkedési mutatók\n\nCFI - összehasonlító illeszkedési mutató (Comparative Fit Index) - A CFI azt méri fel, hogy egy feltételezett hipotetikus modell milyen mértékben reprodukálja a valós adatokon nyugvó kovarianciamátrixot egy független modellhez képest.\nTLI - Tucker–Lewis-féle Illeszkedési mutató - A TLI a CFI-hez hasonló módon méri az illeszkedést, annyi különbséggel, hogy ez a mutató a modellben használt szabadságfokot is figyelembe veszi, így kiküszöböli a vizsgálati minta méretének befolyásoló szerepét\n\nA CFI és TLI mutatók értéke 0 és 1 közötti tartományba eshet, ahol az 1-hez közeli érték jelzi a szoros illeszkedést. Kezdetben a mutatók elfogadhatósági kritériumának 0,90-et adtak meg, de az utóbbi időkben inkább a 0,95-ot tekintik az elfogadhatóság alsó határának.\n\nRMSEA - a becslési hiba négyzetes átlagának gyöke (Root-Mean-Square Error of Approximation) - A Steiger-féle RMSEA mutatót a modell populációs kovariancia mátrixhoz viszonyított illeszkedésének becsléséhez használjuk. Az RMSEA az elemszámtól függetlenül hasonlítja össze, hogy a valós és az optimális paraméterekkel rendelkező hipotetikus modell kovarianciamátrixa milyen mértékben illeszkedik. Az RMSEA a modell takarékosságának megbízható jelzője, a komplex modellek hibás specifikálásának hatékony mutatója. Az RMSEA értéke is 0 és 1 közé eshet, itt azonban a kisebb, 0-hoz közel eső érték jelzi a jobb illeszkedést. Az RMSEA értékei 0,05-ig szoros illeszkedést jeleznek; 0,08-os értékig pedig megfelelő illeszkedést.\n\nModel Test\nAz adatok és a teoretikus modell egybeesésének vizsgálata. Az egyik leggyakrabban használt illeszkedési mutató a \\(\\chi^2\\)-próba mértéke, amelyet általában akkor tekinthetünk elfogadhatónak, ha a szabadságfokhoz viszonyított értéke alacsony (pl. kisebb, mint a szabadságfok kétszerese) és nem szignifikáns (p > 0,05). Ennek a mutatónak azonban több korlátja létezik. A legjellemzőbbek a többváltozós normalitás sérülésére és a mintanagyságra való érzékenység. Számos empirikus eredmény és szimulációs vizsgálat támasztja alá, hogy a normalitás sérülésekor vagy nagy elemszámú minta esetében a \\(\\chi^2\\)-próba kevésbé informatív, és a legtöbb esetben a modell elvetését jelzi. A mintanagyságból fakadó korlátot gyakran a \\(\\chi^2\\)-próba szabadságfokhoz mért arányával próbálják kompenzálni (\\(\\chi^2\\)/szabadságfok), amelynek ugyan nincs pontos kritériuma, de az ajánlások általában 2-től 5-ig terjednek, és a határérték alatti érték jelez megfelelő illeszkedést.\n\n\n\nIlleszkedési mutatók"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-vonás--és-állapot-szorongás",
    "href": "sec_feltaro_faktorelemzes.html#példa-vonás--és-állapot-szorongás",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.6 Példa: Vonás- és állapot-szorongás",
    "text": "4.6 Példa: Vonás- és állapot-szorongás\n\nA példa forrása: Münnich és mtsai. (2006) 3.2 fejezet\nKapcsolódó jamovi állomány: faktor_szorongas.omv\n\nAz adatbázisunkban ún. állapot- és vonás-szorongásra vonatkozó (hipotetikus) adatokat találunk. Az első 3 item az állapot-szorongásra, míg a többi 3 item a vonás-szorongásra irányul. A következő kérdésekre vártunk választ a felmérésben:\n\nv1: Nyugtalan vagyok.\nv2: Aggódom.\nv3: Félek, hogy valami baj fog történni.\nv4: Hajlamos vagyok mindent a szívemre venni.\nv5: Szerintem csupa nehézségből áll az életem.\nv6: Ennél könnyebb életem nem is lehetne.\nv1-v3: állapot-szorongás\nv4-v6: vonás-szorongás\n\nAz adatok a faktor_szorongas.xlsx állományban találhatók.\n\nd <- rio::import(\"adat/faktor_szorongas.xlsx\")\nstr(d)\n#> 'data.frame':    10 obs. of  6 variables:\n#>  $ v1: num  2 5 4 7 3 5 4 7 2 3\n#>  $ v2: num  3 5 4 7 4 5 6 4 2 3\n#>  $ v3: num  2 4 3 7 4 5 6 4 2 3\n#>  $ v4: num  5 2 4 7 2 3 5 7 4 1\n#>  $ v5: num  4 1 4 7 2 3 5 6 4 1\n#>  $ v6: num  4 7 4 1 7 5 3 1 4 7\nd\n#>    v1 v2 v3 v4 v5 v6\n#> 1   2  3  2  5  4  4\n#> 2   5  5  4  2  1  7\n#> 3   4  4  3  4  4  4\n#> 4   7  7  7  7  7  1\n#> 5   3  4  4  2  2  7\n#> 6   5  5  5  3  3  5\n#> 7   4  6  6  5  5  3\n#> 8   7  4  4  7  6  1\n#> 9   2  2  2  4  4  4\n#> 10  3  3  3  1  1  7\n\nMivel a faktoranalízis is a korrelációs mátrixból indul ki - a főkomponens-analízishez hasonlóan -, így elsőként az adatok korrelációs mátrixát érdemes megvizsgálni\n\nprint(cor(d), digits = 2)\n#>       v1    v2    v3    v4    v5    v6\n#> v1  1.00  0.71  0.71  0.54  0.51 -0.56\n#> v2  0.71  1.00  0.96  0.36  0.40 -0.36\n#> v3  0.71  0.96  1.00  0.36  0.44 -0.39\n#> v4  0.54  0.36  0.36  1.00  0.97 -0.98\n#> v5  0.51  0.40  0.44  0.97  1.00 -0.98\n#> v6 -0.56 -0.36 -0.39 -0.98 -0.98  1.00\n\nA korrelációs mátrix értékei azt sugallják, hogy két faktort azonosíthatunk.\nElőször a forgatás előtti faktorokat vizsgáljuk meg.\n\nfa_1 <- factanal(d, factors = 2, rotation = \"none\")\nfa_1\n#> \n#> Call:\n#> factanal(x = d, factors = 2, rotation = \"none\")\n#> \n#> Uniquenesses:\n#>    v1    v2    v3    v4    v5    v6 \n#> 0.408 0.081 0.005 0.030 0.022 0.009 \n#> \n#> Loadings:\n#>    Factor1 Factor2\n#> v1  0.763   0.102 \n#> v2  0.830   0.479 \n#> v3  0.871   0.486 \n#> v4  0.765  -0.620 \n#> v5  0.817  -0.558 \n#> v6 -0.788   0.609 \n#> \n#>                Factor1 Factor2\n#> SS loadings      3.904   1.541\n#> Proportion Var   0.651   0.257\n#> Cumulative Var   0.651   0.908\n#> \n#> Test of the hypothesis that 2 factors are sufficient.\n#> The chi square statistic is 5.27 on 4 degrees of freedom.\n#> The p-value is 0.261\n\nA fenti outputban láthatjuk a forgatás előtti faktorok adatait. Elsőként az egyes változók egyedi hatását, az egyedi fakorokat láthatjuk a „uniquenesses” címszó alatt. A „loadings” címszóval a faktorsúlyokat jelölik. A forgatás nélküli faktorok esetében több olyan változó van, amely mindkét faktorral erős kapcsolatban van. Ilyen például a v6 változó, amely faktorsúlya az első faktornál -0,788, a második faktornál pedig 0,609. Ezáltal a vizsgált látens struktúra kevésbé áttekinthető.\nA faktoranalízis modelljének végtelen számú alternatív megoldása van, és ez vezet a faktoranalízis második lépéséhez, amelyet faktor-rotációnak, vagy faktorforgatásnak hívnak.\nA lenti kódban kétfaktoros megoldást kértünk, a forgatásnál a “varimax” módszert, míg az egyes személyek faktorértékeinek kiszámításánál a Bartlett-módszert alkalmazzuk.\n\nfa_2 <- factanal(d, factors = 2, rotation = \"varimax\", scores = \"Bartlett\")\nfa_2\n#> \n#> Call:\n#> factanal(x = d, factors = 2, scores = \"Bartlett\", rotation = ...\n#> \n#> Uniquenesses:\n#>    v1    v2    v3    v4    v5    v6 \n#> 0.408 0.081 0.005 0.030 0.022 0.009 \n#> \n#> Loadings:\n#>    Factor1 Factor2\n#> v1  0.404   0.655 \n#> v2  0.155   0.946 \n#> v3  0.175   0.982 \n#> v4  0.964   0.200 \n#> v5  0.949   0.280 \n#> v6 -0.970  -0.225 \n#> \n#>                Factor1 Factor2\n#> SS loadings      2.988   2.457\n#> Proportion Var   0.498   0.410\n#> Cumulative Var   0.498   0.908\n#> \n#> Test of the hypothesis that 2 factors are sufficient.\n#> The chi square statistic is 5.27 on 4 degrees of freedom.\n#> The p-value is 0.261\n\nA fenti outputban elsőként az egyes változók egyedi hatását, az egyedi fakorokat láthatjuk a „uniquenesses” címszó alatt. A egyedi faktorok és a kommunalitások kapcsolatban vannak egymással, összegük 1. Minél nagyobb egy változó egyedi faktorbeli értéke, annál kisebb lesz a kommunalitása, és minél nagyobb a kommunalitás értéke, annál nagyobb mértékben őrzi meg a faktor az eredeti változók szórását.\n\nkommunalitas <- 1 - fa_2$uniquenesses\nprint(kommunalitas, digits = 2)\n#>   v1   v2   v3   v4   v5   v6 \n#> 0.59 0.92 0.99 0.97 0.98 0.99\n\nAz egyes változók kommunalitását a fenti output tartalmazza. Láthatjuk, hogy a faktorok a legjobban a v6-os változó szórását őrizték meg, legkevésbé pedig az első (v1) itemét, hiszen ezek kommunalitása a legnagyobb, illetve a legkisebb. Mindez arra utal, hogy a faktorok az utolsó itemből származó információkat őrizték meg a leginkább, és az első itemből származókat a legkevésbé.\nAz egyedi faktorok után a “loadings” címszóval a faktorsúlyokat láthatjuk. A faktorsúlyok mutatják az egyes változók faktorokhoz való relatív hozzájárulását, a változók és a faktor közötti korrelációt. Ezek az értékek a már rotált faktorsúlyok. A faktorsúlyok megerősítik a korrelációs mátrix alapján felállított hipotézisünket, mely szerint két faktoros modell illeszkedik az adatokra. A v1-v3 faktor a második faktornál, míg a v4-v6 az első faktornál szerepel nagyobb súllyal. A v6 item faktorsúlya negatív előjelű, ennek oka, hogy fordított itemről van szó.\nEzután a főkomponens-analízisből már ismert varianciák és magyarázott varianciahányadok szerepelnek. A táblázatban látható, hogy az első faktor varianciája majdnem 3, míg a második faktoré 2,5 (“SS loadings”). Az első faktor a varianciahányad közel 50%-át magyarázza, míg a második a 41%-át („Proportion var”). A „Cumulative var” sor mutatja, hogy a két faktor összesen az összvariancia 91%-át magyarázza.\nAz eredmény utolsó soraiban egy khi-négyzet próbát látunk, amely azt teszteli, hogy illeszkedik-e az adatokra az általunk választott kétfaktoros modell. Ha a tesztstatisztika értéke túl nagy, akkor nem illeszkedik a modell, egy másik megoldást kell választanunk. A khi-négyzet statisztika értéke a mintára 5,27, 4 szabadsági fokkal, a hozzá tartozó valószínűség p=0,261. Mivel jelen esetben p>0,05, így megtartjuk a null-hipotézist, vagyis a kétfaktoros modell valóban jól illeszkedik az adatokra. A két faktort pedig a faktorsúlyoknál vizsgált szerkezet alapján a következőképpen nevezhetjük el: mivel az első három változó a második faktorral mutat szorosabb kapcsolatot, így azt elnevezhetjük az állapot-szorongás faktorának, míg az első faktort - amely a második három változóval mutat szorosabb kapcsolatot - a vonás-szorongásnak.\nÖsszegezve, statisztikai mutatók megerősítették az elméletben leírt kétfaktoros szorongás-modellt, melynek egyik faktora a vonás-, másik faktora az állapot-szorongás.\n\n\n\nVonás- és állapot-szorongás: Feltáró faktorelemzés"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-valóban-szétválasztható-a-reál-és-a-humán-tárgyakhoz-szükséges-tudás",
    "href": "sec_feltaro_faktorelemzes.html#példa-valóban-szétválasztható-a-reál-és-a-humán-tárgyakhoz-szükséges-tudás",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.7 Példa: Valóban szétválasztható a reál és a humán tárgyakhoz szükséges tudás?",
    "text": "4.7 Példa: Valóban szétválasztható a reál és a humán tárgyakhoz szükséges tudás?\n\nA példa forrása: Münnich és mtsai. (2006) 3.7.1 Probléma\nKapcsolódó jamovi állomány: faktor_real_human_targyak.omv\n\nEbben a példában azzal foglalkozunk, hogy a diákok teljesítménye alapján a tantárgyak “szétválnak-e” reál és humán tárgyakra, avagy illeszthetünk-e egy kétfaktoros modellt az adatokra.\nAz adatok a faktor_real_human_targyak.xlsx állományban találhatók.\n\nd <- rio::import(file = \"adat/faktor_real_human_targyak.xlsx\")\nstr(d)\n#> 'data.frame':    30 obs. of  6 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5 5 ...\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5 4 ...\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5 5 ...\n#>  $ irodalom   : num  5 4 2 5 3 5 3 5 4 2 ...\n#>  $ nyelvtan   : num  4 4 2 5 3 5 3 5 5 2 ...\n#>  $ angol      : num  5 5 3 5 3 5 3 5 5 2 ...\npsych::headTail(d)\n#>     matek informatika kemia irodalom nyelvtan angol\n#> 1       5           4     5        5        4     5\n#> 2       4           4     5        4        4     5\n#> 3       3           4     3        2        2     3\n#> 4       2           2     3        5        5     5\n#> ...   ...         ...   ...      ...      ...   ...\n#> 27      5           5     5        2        2     3\n#> 28      5           5     5        4        4     4\n#> 29      2           2     3        4        5     5\n#> 30      5           5     5        4        5     5\n\nÖsszesen hat változónk van. Az első hármat “hétköznapi” tudásunk alapján a reál tárgyak csoportjába, míg a második hármat a humán tárgyak csoportjába sorolnánk.\n\nprint(cor(d), digits = 2)\n#>             matek informatika kemia irodalom nyelvtan angol\n#> matek        1.00        0.94  0.91    -0.15    -0.21 -0.21\n#> informatika  0.94        1.00  0.82    -0.20    -0.23 -0.23\n#> kemia        0.91        0.82  1.00    -0.19    -0.23 -0.21\n#> irodalom    -0.15       -0.20 -0.19     1.00     0.93  0.89\n#> nyelvtan    -0.21       -0.23 -0.23     0.93     1.00  0.95\n#> angol       -0.21       -0.23 -0.21     0.89     0.95  1.00\n\nA korrelációs mátrix értékei azt sugallják, hogy két faktort azonosíthatunk. Az első faktort az első három változó (vagyis a reál tárgyak) alkotják, míg a második faktort a második három változó, azaz a humán tárgyak adják. A következő lépésben faktoranalízis segítségével teszteljük, hogy helyes-e a megérzésünk.\n\nfa_1 <- factanal(d, factors = 2, rotation = \"varimax\", scores = \"Bartlett\")\nfa_1\n#> \n#> Call:\n#> factanal(x = d, factors = 2, scores = \"Bartlett\", rotation = ...\n#> \n#> Uniquenesses:\n#>       matek informatika       kemia    irodalom    nyelvtan \n#>       0.005       0.114       0.173       0.122       0.006 \n#>       angol \n#>       0.094 \n#> \n#> Loadings:\n#>             Factor1 Factor2\n#> matek       -0.107   0.992 \n#> informatika -0.136   0.931 \n#> kemia       -0.139   0.898 \n#> irodalom     0.936         \n#> nyelvtan     0.991  -0.106 \n#> angol        0.946  -0.105 \n#> \n#>                Factor1 Factor2\n#> SS loadings      2.802   2.683\n#> Proportion Var   0.467   0.447\n#> Cumulative Var   0.467   0.914\n#> \n#> Test of the hypothesis that 2 factors are sufficient.\n#> The chi square statistic is 5.24 on 4 degrees of freedom.\n#> The p-value is 0.264\n\nLáthatjuk, hogy a khi-négyzet statisztika alapján a kétfaktoros modell illeszkedik az adatokra, hiszen a statisztikához tartozó szignifikancia-szint p=0,264.\nA “Proportion Var” sor mutatja, hogy egyes faktorok az összvariancia hány százalékát magyarázzák. Láthatjuk, hogy az első faktor 47%-át magyarázza az összvarianciának, míg a második 45%-át - kerekített értékben. A két faktor összesen kb. 91%-át magyarázza az összvarianciának.\nA “Loadings” résznél láthatjuk a faktorsúlyokat. A faktorsúlyok értékei megerősítik azt, amit a korrelációs mátrix és az előzetes tudásunk alapján véltünk: a matek, informatika és a kémia tárgyak alkotják az egyik faktort (a másodikat), a faktorsúlyok a második faktornál 0,9-es érték körül mozognak. Az irodalom, nyelvtan és angol tárgyak alkotják a másik faktort (az elsőt), az ide tartozó faktorsúlyok is 0,9 felett vannak.\n\nkommunalitas <- 1 - fa_1$uniquenesses\nprint(kommunalitas, digits = 3)\n#>       matek informatika       kemia    irodalom    nyelvtan \n#>       0.995       0.886       0.827       0.878       0.994 \n#>       angol \n#>       0.906\n\nA kommunalitások alapján látható, hogy az eredeti változók a szórásuk nagy részét megőrizték a faktorba kerüléskor. A magas, 0,9 körüli értékek arra utalnak, hogy a kétfaktoros modellnél az információveszteség elenyészően kicsi.\n\nprint(fa_1$scores, digits = 3)\n#>    Factor1 Factor2\n#> 1    0.400   0.950\n#> 2    0.299   0.314\n#> 3   -1.481  -0.542\n#> 4    0.965  -0.952\n#> 5   -0.534   0.875\n#> 6    0.893  -1.648\n#> 7   -0.534   0.875\n#> 8    0.965  -0.952\n#> 9    1.143   1.057\n#> 10  -1.391   0.752\n#> 11   1.107   0.403\n#> 12   0.181  -0.359\n#> 13  -1.601  -1.234\n#> 14   1.175   1.034\n#> 15  -0.818  -1.836\n#> 16   1.175   1.026\n#> 17   0.109  -1.046\n#> 18  -1.389   0.781\n#> 19   0.353   0.945\n#> 20  -0.604   0.215\n#> 21   0.181  -0.359\n#> 22   0.965  -0.952\n#> 23  -1.389   0.781\n#> 24   0.894  -1.620\n#> 25  -0.534   0.875\n#> 26  -1.586  -1.235\n#> 27  -1.341   0.786\n#> 28   0.321   0.969\n#> 29   0.931  -0.958\n#> 30   1.143   1.057\n\nVégül, nézzük meg az egyes személyek faktorértékeit. A faktorértékeknél azt láthatjuk, hogy akik reál tárgyakból értek el jobb eredményt, azok a második faktorban kaptak magasabb pontszámot, míg akik a humán tárgyakból kaptak jobb jegyeket, azok az első faktorban kaptak magasabb pontszámokat.\nÖsszefoglalva, az adatokra jól illeszkedik a kétfaktoros modell, vagyis azonosíthatjuk a humán és a reál tárgyakat az egyes tantárgyakból nyújtott eredmények alapján. Az egyes tárgyak faktorba történő besorolása összhangban van “hétköznapi”, előzetes tudásunkkal: a matek, informatika és a kémia sorolható a reál, míg az irodalom, nyelvtan és angol tárgyak a humán tárgyakhoz.\n\n\n\nValóban szétválasztható a reál és a humán tárgyakhoz szükséges tudás: Feltáró faktorelemzés"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-toleranciavizsgálat-egy-másik-aspektusból",
    "href": "sec_feltaro_faktorelemzes.html#példa-toleranciavizsgálat-egy-másik-aspektusból",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.8 Példa: Toleranciavizsgálat egy másik aspektusból",
    "text": "4.8 Példa: Toleranciavizsgálat egy másik aspektusból\n\nA példa forrása: Münnich és mtsai. (2006) 3.7.2 Probléma\nKapcsolódó jamovi állomány: faktor_munkahelyi_tolarencia.omv\n\nA főkomponenselemzés kapcsán már volt szó a toleranciáról. Megvizsgáltuk, hogy milyen jelenségek, milyen változók tartoznak a tolerancia körébe. Most azt próbáljuk megállapítani, hogyan épül fel a tolerancia, milyen a szerkezete, vannak-e látens dimenziói, ha igen, akkor melyek ezek.\nAz adatok a faktor_munkahelyi_tolarencia.xlsx állományban találhatók.\n\nd <- rio::import(\"adat/faktor_munkahelyi_tolarencia.xlsx\")\nstr(d)\n#> 'data.frame':    155 obs. of  18 variables:\n#>  $ alkohol    : num  1 1 1 1 1 2 1 1 1 1 ...\n#>  $ kabitoszer : num  1 1 1 1 1 1 1 1 1 1 ...\n#>  $ hianyzik   : num  3 1 1 2 1 1 5 1 1 3 ...\n#>  $ dohanyzas  : num  4 5 1 3 1 4 5 1 5 5 ...\n#>  $ udvariatlan: num  3 1 5 2 2 1 1 1 1 1 ...\n#>  $ rendetlen  : num  3 1 5 2 2 1 1 1 1 3 ...\n#>  $ pontatlan  : num  3 1 5 3 2 1 1 1 1 3 ...\n#>  $ pletykas   : num  1 1 5 2 1 2 1 1 1 3 ...\n#>  $ harsany    : num  4 3 5 2 2 4 1 1 2 3 ...\n#>  $ tudalekos  : num  3 2 4 3 2 2 1 1 2 1 ...\n#>  $ csamcsog   : num  3 1 5 3 3 1 1 1 1 3 ...\n#>  $ lusta      : num  3 1 5 2 3 4 1 1 1 5 ...\n#>  $ szemtelen  : num  3 1 5 2 2 1 1 1 1 1 ...\n#>  $ bufog      : num  3 1 5 2 2 5 5 1 1 1 ...\n#>  $ felelotlen : num  3 1 5 2 2 1 1 1 1 1 ...\n#>  $ bosszuallo : num  2 2 3 2 1 1 1 1 1 1 ...\n#>  $ durva      : num  2 1 5 2 2 1 1 1 1 1 ...\n#>  $ agressziv  : num  2 1 5 1 2 1 1 1 1 1 ...\npsych::headTail(d)\n#>     alkohol kabitoszer hianyzik dohanyzas udvariatlan rendetlen\n#> 1         1          1        3         4           3         3\n#> 2         1          1        1         5           1         1\n#> 3         1          1        1         1           5         5\n#> 4         1          1        2         3           2         2\n#> ...     ...        ...      ...       ...         ...       ...\n#> 152       3          1        2         5           3         4\n#> 153       3          1        2         2           2         1\n#> 154       4          4        2         5           3         4\n#> 155       3          3        4         5           3         4\n#>     pontatlan pletykas harsany tudalekos csamcsog lusta szemt...\n#> 1           3        1       4         3        3     3      ...\n#> 2           1        1       3         2        1     1      ...\n#> 3           5        5       5         4        5     5      ...\n#> 4           3        2       2         3        3     2      ...\n#> ...       ...      ...     ...       ...      ...   ...      ...\n#> 152         2        2       5         3        4     5      ...\n#> 153         1        1       1         2        1     1      ...\n#> 154         5        5       3         2        2     3      ...\n#> 155         4        2       2         1        1     3      ...\n#>     bufog felelotlen bosszuallo durva agressziv\n#> 1       3          3          2     2         2\n#> 2       1          1          2     1         1\n#> 3       5          5          3     5         5\n#> 4       2          2          2     2         1\n#> ...   ...        ...        ...   ...       ...\n#> 152     4          2          1     3         1\n#> 153     1          1          1     1         1\n#> 154     4          5          5     5         5\n#> 155     1          2          1     2         2\n\n\nprint(cor(d), digits = 2)\n#>             alkohol kabitoszer hianyzik dohanyzas udvariatlan\n#> alkohol       1.000     0.7293     0.50     0.285        0.40\n#> kabitoszer    0.729     1.0000     0.49     0.110        0.45\n#> hianyzik      0.498     0.4901     1.00     0.246        0.53\n#> dohanyzas     0.285     0.1095     0.25     1.000        0.15\n#> udvariatlan   0.404     0.4497     0.53     0.145        1.00\n#> rendetlen     0.372     0.4119     0.60     0.202        0.70\n#> pontatlan     0.340     0.4265     0.52     0.095        0.58\n#> pletykas      0.138     0.2321     0.19     0.071        0.38\n#> harsany       0.064    -0.0092     0.10     0.178        0.32\n#> tudalekos     0.129     0.1349     0.21     0.021        0.42\n#> csamcsog      0.324     0.3034     0.31     0.108        0.46\n#> lusta         0.274     0.2901     0.34     0.156        0.47\n#> szemtelen     0.304     0.4449     0.45     0.060        0.70\n#> bufog         0.283     0.3011     0.34     0.160        0.45\n#> felelotlen    0.304     0.4867     0.38    -0.068        0.53\n#> bosszuallo    0.372     0.5641     0.33    -0.010        0.46\n#> durva         0.389     0.4186     0.38     0.146        0.50\n#> agressziv     0.344     0.4207     0.36     0.024        0.48\n#>             rendetlen pontatlan pletykas harsany tudalekos\n#> alkohol          0.37     0.340    0.138  0.0636     0.129\n#> kabitoszer       0.41     0.427    0.232 -0.0092     0.135\n#> hianyzik         0.60     0.519    0.193  0.0995     0.206\n#> dohanyzas        0.20     0.095    0.071  0.1781     0.021\n#> udvariatlan      0.70     0.577    0.375  0.3230     0.416\n#> rendetlen        1.00     0.795    0.421  0.3791     0.378\n#> pontatlan        0.80     1.000    0.420  0.2896     0.361\n#> pletykas         0.42     0.420    1.000  0.5020     0.397\n#> harsany          0.38     0.290    0.502  1.0000     0.501\n#> tudalekos        0.38     0.361    0.397  0.5012     1.000\n#> csamcsog         0.49     0.447    0.300  0.4316     0.514\n#> lusta            0.55     0.469    0.335  0.4796     0.429\n#> szemtelen        0.62     0.532    0.264  0.2995     0.434\n#> bufog            0.39     0.336    0.212  0.2902     0.272\n#> felelotlen       0.54     0.582    0.280  0.1495     0.319\n#> bosszuallo       0.41     0.416    0.290  0.0583     0.333\n#> durva            0.48     0.419    0.190  0.1358     0.229\n#> agressziv        0.46     0.467    0.234  0.1348     0.309\n#>             csamcsog lusta szemtelen bufog felelotlen bosszuallo\n#> alkohol         0.32  0.27      0.30  0.28      0.304      0.372\n#> kabitoszer      0.30  0.29      0.44  0.30      0.487      0.564\n#> hianyzik        0.31  0.34      0.45  0.34      0.380      0.331\n#> dohanyzas       0.11  0.16      0.06  0.16     -0.068     -0.010\n#> udvariatlan     0.46  0.47      0.70  0.45      0.532      0.458\n#> rendetlen       0.49  0.55      0.62  0.39      0.542      0.410\n#> pontatlan       0.45  0.47      0.53  0.34      0.582      0.416\n#> pletykas        0.30  0.34      0.26  0.21      0.280      0.290\n#> harsany         0.43  0.48      0.30  0.29      0.149      0.058\n#> tudalekos       0.51  0.43      0.43  0.27      0.319      0.333\n#> csamcsog        1.00  0.54      0.55  0.67      0.400      0.461\n#> lusta           0.54  1.00      0.66  0.41      0.579      0.472\n#> szemtelen       0.55  0.66      1.00  0.52      0.695      0.601\n#> bufog           0.67  0.41      0.52  1.00      0.389      0.432\n#> felelotlen      0.40  0.58      0.69  0.39      1.000      0.712\n#> bosszuallo      0.46  0.47      0.60  0.43      0.712      1.000\n#> durva           0.44  0.54      0.66  0.44      0.571      0.556\n#> agressziv       0.45  0.53      0.60  0.39      0.643      0.731\n#>             durva agressziv\n#> alkohol      0.39     0.344\n#> kabitoszer   0.42     0.421\n#> hianyzik     0.38     0.360\n#> dohanyzas    0.15     0.024\n#> udvariatlan  0.50     0.476\n#> rendetlen    0.48     0.465\n#> pontatlan    0.42     0.467\n#> pletykas     0.19     0.234\n#> harsany      0.14     0.135\n#> tudalekos    0.23     0.309\n#> csamcsog     0.44     0.453\n#> lusta        0.54     0.529\n#> szemtelen    0.66     0.605\n#> bufog        0.44     0.392\n#> felelotlen   0.57     0.643\n#> bosszuallo   0.56     0.731\n#> durva        1.00     0.786\n#> agressziv    0.79     1.000\n\nVannak változók, melyek között szinte nincs is kapcsolat, olyan gyenge a korreláció (ilyen például az “alkohol” és a “harsány” változó közötti korreláció, melynek értéke 0,06), és vannak olyan változók is, melyek között szorosabb kapcsolat figyelhető meg (ilyen például az “alkohol” és a “kábítószer” változó, melyek közötti korreláció mértéke 0,73).\nVégezzünk faktorelemzést.\n\nfa_1 <- factanal(d, factors = 6, rotation = \"varimax\", scores = \"Bartlett\")\nfa_1\n#> \n#> Call:\n#> factanal(x = d, factors = 6, scores = \"Bartlett\", rotation = ...\n#> \n#> Uniquenesses:\n#>     alkohol  kabitoszer    hianyzik   dohanyzas udvariatlan \n#>       0.161       0.262       0.485       0.805       0.400 \n#>   rendetlen   pontatlan    pletykas     harsany   tudalekos \n#>       0.101       0.296       0.641       0.005       0.584 \n#>    csamcsog       lusta   szemtelen       bufog  felelotlen \n#>       0.005       0.436       0.320       0.513       0.274 \n#>  bosszuallo       durva   agressziv \n#>       0.190       0.005       0.247 \n#> \n#> Loadings:\n#>             Factor1 Factor2 Factor3 Factor4 Factor5 Factor6\n#> alkohol      0.157   0.182           0.827   0.146   0.275 \n#> kabitoszer   0.275   0.271           0.761                 \n#> hianyzik     0.174   0.552           0.383   0.104   0.146 \n#> dohanyzas            0.108           0.178           0.377 \n#> udvariatlan  0.333   0.569   0.263   0.244   0.184         \n#> rendetlen    0.244   0.833   0.275   0.139   0.190   0.121 \n#> pontatlan    0.233   0.733   0.228   0.171   0.178         \n#> pletykas     0.114   0.272   0.506                         \n#> harsany                      0.945           0.180   0.241 \n#> tudalekos    0.150   0.200   0.473           0.346         \n#> csamcsog     0.220   0.209   0.266   0.127   0.903         \n#> lusta        0.441   0.304   0.432   0.105   0.283         \n#> szemtelen    0.566   0.433   0.255   0.156   0.273         \n#> bufog        0.293   0.174   0.187   0.158   0.557         \n#> felelotlen   0.564   0.412   0.198   0.250   0.129  -0.346 \n#> bosszuallo   0.576   0.211   0.133   0.402   0.240  -0.443 \n#> durva        0.914   0.203           0.135   0.183   0.256 \n#> agressziv    0.769   0.224   0.117   0.209   0.202  -0.118 \n#> \n#>                Factor1 Factor2 Factor3 Factor4 Factor5 Factor6\n#> SS loadings      3.116   2.756   2.009   1.927   1.731   0.731\n#> Proportion Var   0.173   0.153   0.112   0.107   0.096   0.041\n#> Cumulative Var   0.173   0.326   0.438   0.545   0.641   0.682\n#> \n#> Test of the hypothesis that 6 factors are sufficient.\n#> The chi square statistic is 112.68 on 60 degrees of freedom.\n#> The p-value is 4.55e-05\n\nA fenti hatfaktoros megoldás eredményen látható, hogy a khi-négyzet statisztika szignifikancia-szintje szerint nem jól illeszkedik az adatokra. A “Cumulative Var” sorban azt is láthatjuk, hogy a hat faktor összesen az összvariancia 68%-át magyarázza. A faktorsúlyok alapján (3.17. R-eredmény) az egyes faktorok a következőképpen alakulnak. Az első faktorban olyan változók szerepelnek, mint a „lusta”, „szemtelen”, „felelőtlen”, „bosszúálló”, „durva”, „agresszív”. A második faktorban szerepel a „hiányzik”, „udvariatlan”, „rendetlen” és „pontatlan”. A harmadikban szerepel a „pletykás”, „harsány” és „tudálékos”. A negyedik faktorban következik az „alkohol” és a „kábítószer”, ötödikben a „csámcsog” és a „büfög”, míg az utolsóban a „dohányzás”.\n\n\n\nToleranciavizsgálat egy másik aspektusból: Feltáró faktorelemzés"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-a-big-five-személyiségvizsgáló-eljárás-faktoranalízise",
    "href": "sec_feltaro_faktorelemzes.html#példa-a-big-five-személyiségvizsgáló-eljárás-faktoranalízise",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.9 Példa: A Big Five személyiségvizsgáló eljárás faktoranalízise",
    "text": "4.9 Példa: A Big Five személyiségvizsgáló eljárás faktoranalízise\n\nA példa forrása: Münnich és mtsai. (2006) 3.7.3 Probléma\nKapcsolódó jamovi állomány: faktor_bigfive.omv\n\nSzinte minden pszichológus számára ismert a Big Five személyiségvizsgáló eljárás. A Big Five - ahogyan a neve is mutatja - egy olyan személyiségmodell, és arra épülő személyiségvizsgáló eljárás, amely azt feltételezi, hogy a személyiséget öt, egymástól független dimenzió, öt faktor alkotja. Az egyes dimenzióknak, faktoroknak több elnevezése is ismert, ebben a vizsgálatban a következő elnevezéseket fogjuk használni:\n\nExtroverzió - introverzió\nEgyüttműködés\nLelkiismeretesség\nStabilitás - neurocitás\nÉlményekre való nyitottság\n\nAz adatok a faktor_bigfive.xlsx állományban találhatók.\n\nd <- rio::import(file = \"adat/faktor_bigfive.xlsx\")\nstr(d)\n#> 'data.frame':    20 obs. of  10 variables:\n#>  $ V1 : num  2 3 4 5 7 5 1 4 5 6 ...\n#>  $ V2 : num  7 5 4 3 1 3 7 4 3 1 ...\n#>  $ V3 : num  2 4 5 7 6 3 5 6 1 4 ...\n#>  $ V4 : num  6 5 3 1 2 5 3 2 7 4 ...\n#>  $ V5 : num  4 7 5 7 1 2 5 4 5 3 ...\n#>  $ V6 : num  4 2 3 1 7 6 3 4 3 5 ...\n#>  $ V7 : num  1 2 5 7 5 4 3 5 4 2 ...\n#>  $ V8 : num  6 6 3 1 3 4 5 3 5 6 ...\n#>  $ V9 : num  2 5 7 4 5 3 5 4 6 6 ...\n#>  $ V10: num  7 3 2 4 3 5 3 4 2 2 ...\npsych::headTail(d)\n#>      V1  V2  V3  V4  V5  V6  V7  V8  V9 V10\n#> 1     2   7   2   6   4   4   1   6   2   7\n#> 2     3   5   4   5   7   2   2   6   5   3\n#> 3     4   4   5   3   5   3   5   3   7   2\n#> 4     5   3   7   1   7   1   7   1   4   4\n#> ... ... ... ... ... ... ... ... ... ... ...\n#> 17    5   3   2   6   1   7   5   3   5   3\n#> 18    7   1   5   3   2   6   5   3   6   2\n#> 19    4   3   2   5   7   2   2   6   3   5\n#> 20    7   1   4   4   5   3   7   1   5   3\n\nA fenti adatok egy Big Five eljárásra épülő hipotetikus vizsgálat adatait tartalmazza. Az egyes változókhoz tartozó itemeket egy 1-7 skálán jelölték meg a vizsgálati személyek attól függően, hogy mennyire illik vagy nem illik rájuk az adott állítás. A 7 jelenteti azt, hogy teljes mértékben illik, és az 1, hogy egyáltalán nem. Az egyes változókhoz tartozó itemek a következők:\n\nv1 (extroverzió): Általában beszédes, aktív és társaságkedvelő vagyok.\nv2 (introverzió): Jobban szeretek csendesen visszahúzódni egy sarokba, semmint a középpontban lenni.\nv3 (együttműködés): Szívesen segítek másoknak, vagy dolgozok másokkal együtt valamilyen közös feladaton.\nv4 (együttműködés): Gyakran viselkedem ellenségesen és kötözködően másokkal.\nv5 (lelkiismeretesség): Általában tudom, hogy mit akarok, és céltudatosan igyekszem elérni azt.\nv6 (lelkiismeretesség):Sokak szerint megbízhatatlan vagyok.\nv7 (stabilitás): Érzelmileg kiegyensúlyozottnak, higgadtnak tartom magam.\nv8 (neurocitás): Gyakran vagyok érzelmileg csapongó.\nv9 (élményekre való nyitottság): Kíváncsi vagyok.\nv10 (élményekre való nyitottság): Ragaszkodom a szokásaimhoz.\n\n\nprint(cor(d), digits = 3)\n#>           V1       V2       V3      V4      V5      V6      V7\n#> V1   1.00000 -0.98085  0.00408 -0.0645 -0.2771  0.2393  0.3714\n#> V2  -0.98085  1.00000  0.00000  0.0726  0.2307 -0.2069 -0.3294\n#> V3   0.00408  0.00000  1.00000 -0.9751  0.0661 -0.0680  0.2631\n#> V4  -0.06446  0.07256 -0.97510  1.0000 -0.0895  0.0905 -0.2257\n#> V5  -0.27711  0.23072  0.06615 -0.0895  1.0000 -0.9814 -0.1954\n#> V6   0.23926 -0.20689 -0.06797  0.0905 -0.9814  1.0000  0.0881\n#> V7   0.37135 -0.32942  0.26315 -0.2257 -0.1954  0.0881  1.0000\n#> V8  -0.33508  0.28028 -0.28799  0.2500  0.2179 -0.1087 -0.9848\n#> V9  -0.11472  0.06565  0.08152 -0.0377 -0.1790  0.1864  0.1554\n#> V10  0.05897  0.00323 -0.10682  0.0630  0.1865 -0.2005 -0.1900\n#>          V8      V9      V10\n#> V1  -0.3351 -0.1147  0.05897\n#> V2   0.2803  0.0656  0.00323\n#> V3  -0.2880  0.0815 -0.10682\n#> V4   0.2500 -0.0377  0.06298\n#> V5   0.2179 -0.1790  0.18647\n#> V6  -0.1087  0.1864 -0.20051\n#> V7  -0.9848  0.1554 -0.19002\n#> V8   1.0000 -0.0891  0.10854\n#> V9  -0.0891  1.0000 -0.98281\n#> V10  0.1085 -0.9828  1.00000\n\nLáthatjuk, hogy a Big Five modellje szerint összekapcsolódó itemek nagyon szoros, ám negatív korrelációban vannak egymással (tehát a v1 a v2-vel, v3 a v4-gyel stb.) a korreláció értékek -0,98 körül mozognak. A negatív előjelű kapcsolat utal arra, hogy az összekapcsolódó itemek egy dimenzió két végpontját ragadják meg. Hogy mennyire helytálló a korrelációs mátrix által felállított elképzelésünk, arra a faktoranalízis adhat választ.\n\nfa_1 <- factanal(d, factors = 5, rotation = \"varimax\", scores = \"Bartlett\")\nfa_1\n#> \n#> Call:\n#> factanal(x = d, factors = 5, scores = \"Bartlett\", rotation = ...\n#> \n#> Uniquenesses:\n#>    V1    V2    V3    V4    V5    V6    V7    V8    V9   V10 \n#> 0.022 0.005 0.005 0.034 0.005 0.019 0.012 0.005 0.025 0.005 \n#> \n#> Loadings:\n#>     Factor1 Factor2 Factor3 Factor4 Factor5\n#> V1          -0.194  -0.955   0.146         \n#> V2           0.136   0.983                 \n#> V3          -0.151                  -0.984 \n#> V4           0.104                   0.974 \n#> V5           0.124   0.123  -0.977         \n#> V6   0.109          -0.113   0.977         \n#> V7   0.114  -0.959  -0.197          -0.122 \n#> V8           0.972   0.140           0.149 \n#> V9   0.978                                 \n#> V10 -0.989                                 \n#> \n#>                Factor1 Factor2 Factor3 Factor4 Factor5\n#> SS loadings      1.978   1.977   1.975   1.972   1.961\n#> Proportion Var   0.198   0.198   0.197   0.197   0.196\n#> Cumulative Var   0.198   0.395   0.593   0.790   0.986\n#> \n#> Test of the hypothesis that 5 factors are sufficient.\n#> The chi square statistic is 9.02 on 5 degrees of freedom.\n#> The p-value is 0.108\n\nA Big Five jellegéből adódik, hogy egy ötfaktoros modellt teszteltünk, amely a khi-négyzet statisztika szerint illeszkedik is az adatokra. A “Cumulative Var” sorban azt is láthatjuk, hogy a modell magyarázóértéke igen jó, hiszen az öt faktor az összvarianciának majdnem a 99%-át magyarázza. A “Loadings”-szal jelölt faktorsúlyoknál megnézhetjük, hogyan alakulnak az egyes faktorok. A faktorok szerkezete teljes mértékben összecseng előzetes várakozásunkkal: minden egyes faktorba két változó tartozik, az összetartozó változók pedig úgy kapcsolódnak össze, ahogyan azt az elmélet alapján is vártuk (vagyis a v1 a v2-vel, v3 a v4-gyel stb.). A faktorsúlyok alapján az öt faktor a következőképpen alakul:\n\nfaktor: élményekre való nyitottság (v9, v10)\nfaktor: stabilitás-neurocitás (v7, v8)\nfaktor: extroverzió-introverzió (v1, v2)\nfaktor: lelkiismeretesség (v5, v6)\nfaktor: együttműködés (v3, v4)\n\n\nprint(fa_1$scores, digits = 3)\n#>    Factor1 Factor2 Factor3 Factor4 Factor5\n#> 1   -1.971  0.8369  1.7713  0.5375  1.0879\n#> 2    0.559  1.0027  0.5314 -1.4064  0.1571\n#> 3    1.066 -0.5120  0.3125 -0.5840 -0.2786\n#> 4   -0.250 -1.5838 -0.1453 -1.7374 -1.3075\n#> 5    0.155 -0.0311 -1.0713  1.7501 -1.0874\n#> 6   -0.956  0.0323 -0.0697  1.3117  0.6154\n#> 7    0.355  0.3940  1.8085 -0.2350 -0.4319\n#> 8   -0.350 -0.4407  0.4149  0.1847 -0.9641\n#> 9    1.148  0.2481 -0.3858 -0.7208  1.9149\n#> 10   1.035  1.5221 -1.3600  0.5723 -0.0805\n#> 11   0.403  1.9639  0.5569 -0.0237 -1.8494\n#> 12  -0.236 -0.7084 -0.1276 -0.0423  1.3856\n#> 13  -1.397  0.7453 -0.8566 -0.3500 -0.6176\n#> 14  -2.060 -0.3921 -1.2143 -0.4555 -0.4865\n#> 15   0.109 -1.7587  1.7177  0.7326 -0.6666\n#> 16   1.560 -0.0238  0.8113  0.0349  0.2353\n#> 17   0.210 -0.5591  0.0271  1.6983  1.3235\n#> 18   0.852 -0.1328 -1.1529  1.0491 -0.4370\n#> 19  -0.593  0.9647 -0.4275 -1.4764  1.0903\n#> 20   0.362 -1.5674 -1.1406 -0.8398  0.3971\n\nElőhívhatjuk a személyek egyes faktorbeli értékeit is.\n\n\n\nA Big Five személyiségvizsgáló eljárás faktoranalízise: Feltáró faktorelemzés"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-milyen-dimenziói-vannak-a-kockázatvállalásnak-és-változik-e-a-korral-a-kockázatvállalás",
    "href": "sec_feltaro_faktorelemzes.html#példa-milyen-dimenziói-vannak-a-kockázatvállalásnak-és-változik-e-a-korral-a-kockázatvállalás",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.10 Példa: Milyen dimenziói vannak a kockázatvállalásnak és változik-e a korral a kockázatvállalás?",
    "text": "4.10 Példa: Milyen dimenziói vannak a kockázatvállalásnak és változik-e a korral a kockázatvállalás?\n\nA példa forrása: Münnich és mtsai. (2006) 3.7.4 Probléma\nKapcsolódó jamovi állomány: faktor_kockazat.omv\n\nA példák is mutatják, hogy a kockázatvállalásokat csoportosíthatjuk a kockázatot jelentő tényezők alapján, ahol az egyik csoportban az emberek saját testi épségüket teszik kockára (mint az autóversenyzés esetében), de kockáztathatnak pénzt vagy valamilyen becsületbeli dolgot is (mint a kártyázás és a blöffölés esetében). Példánkban megnézzük, hogy a faktoranalízis alátámasztja-e feltevésünket, majd a faktoranalízis eredményeit felhasználva megnézzük, hogy a kockázatvállaló viselkedésre hatással van-e a kor.\nAz adatbázisban szereplő adatokat úgy kaptuk, hogy a vizsgálati személyeknek különböző foglalkozású, illetve különböző tevékenységet végző embereket kellett megítélniük, hogy mennyire tartják őket szimpatikusnak egy 1-7 skálán, ahol a 7 jelentette azt, hogy nagyon szimpatikus. Ily módon megkaptuk a személyek kockázat iránti attitűdjét. A változók között olyan személyek szerepelnek, mint kártyajátékosok, autóversenyzők, üzletemberek (akik sok pénzt kockáztatnak), veszélyes sportot űző emberek, nagy pénzekben fogadó emberek, blöffölők és hivatásos katonák.\nEzen kívül két adat szerepel az adatbázisban: a nem és a kor.\nAz adatok a faktor_kockazat.xlsx állományban találhatók.\n\nd <- rio::import(file = \"adat/faktor_kockazat.xlsx\")\nstr(d)\n#> 'data.frame':    156 obs. of  9 variables:\n#>  $ kartya        : num  5 4 2 1 4 5 4 4 3 5 ...\n#>  $ autoversenyzo : num  3 3 5 1 3 4 2 2 3 5 ...\n#>  $ uzletember    : num  3 3 2 1 4 3 2 3 2 3 ...\n#>  $ veszelyessport: num  3 2 4 1 3 1 2 1 2 3 ...\n#>  $ fogadas       : num  3 3 4 2 3 4 4 4 3 3 ...\n#>  $ bloff         : num  3 1 1 1 3 3 3 5 4 2 ...\n#>  $ katona        : num  1 1 2 1 2 2 2 1 2 2 ...\n#>  $ kor           : num  25 19 18 18 24 28 25 39 19 19 ...\n#>  $ nem           : num  1 0 1 0 1 1 0 1 0 1 ...\npsych::headTail(d)\n#>     kartya autoversenyzo uzletember veszelyessport fogadas bloff\n#> 1        5             3          3              3       3     3\n#> 2        4             3          3              2       3     1\n#> 3        2             5          2              4       4     1\n#> 4        1             1          1              1       2     1\n#> ...    ...           ...        ...            ...     ...   ...\n#> 153      4             2          3              4       4     4\n#> 154      5             3          4              5       5     3\n#> 155      4             1          1              3       5     3\n#> 156      4             3          3              2       4     3\n#>     katona kor nem\n#> 1        1  25   1\n#> 2        1  19   0\n#> 3        2  18   1\n#> 4        1  18   0\n#> ...    ... ... ...\n#> 153      2  26   1\n#> 154      3  24   1\n#> 155      2  25   0\n#> 156      4  21   1\n\n\nprint(cor(d[1:7]), digits = 2)\n#>                kartya autoversenyzo uzletember veszelyessport\n#> kartya           1.00        0.1702      0.316          0.080\n#> autoversenyzo    0.17        1.0000      0.113          0.222\n#> uzletember       0.32        0.1132      1.000          0.177\n#> veszelyessport   0.08        0.2224      0.177          1.000\n#> fogadas          0.56       -0.0062      0.148          0.055\n#> bloff            0.27        0.0023      0.253          0.142\n#> katona          -0.23        0.1833     -0.092          0.160\n#>                fogadas   bloff katona\n#> kartya          0.5579  0.2671 -0.233\n#> autoversenyzo  -0.0062  0.0023  0.183\n#> uzletember      0.1482  0.2535 -0.092\n#> veszelyessport  0.0553  0.1424  0.160\n#> fogadas         1.0000  0.1986 -0.096\n#> bloff           0.1986  1.0000 -0.120\n#> katona         -0.0961 -0.1197  1.000\n\nA korrelációs mátrixon nem látunk kiemelkedően magas értékeket, kissé nehéz egyértelmű következtetéseket levonni a faktorokra vonatkozóan, ezért teszteljünk egy kétfaktoros faktoranalízist az adatokra.\n\nfa_1 <- factanal(d[1:7], factors = 2, rotation = \"varimax\", scores = \"Bartlett\")\nfa_1\n#> \n#> Call:\n#> factanal(x = d[1:7], factors = 2, scores = \"Bartlett\", rotati...\n#> \n#> Uniquenesses:\n#>         kartya  autoversenyzo     uzletember veszelyessport \n#>          0.073          0.724          0.863          0.775 \n#>        fogadas          bloff         katona \n#>          0.663          0.916          0.796 \n#> \n#> Loadings:\n#>                Factor1 Factor2\n#> kartya          0.963         \n#> autoversenyzo   0.164   0.499 \n#> uzletember      0.330   0.169 \n#> veszelyessport          0.467 \n#> fogadas         0.577         \n#> bloff           0.285         \n#> katona         -0.244   0.380 \n#> \n#>                Factor1 Factor2\n#> SS loadings      1.544   0.646\n#> Proportion Var   0.221   0.092\n#> Cumulative Var   0.221   0.313\n#> \n#> Test of the hypothesis that 2 factors are sufficient.\n#> The chi square statistic is 14.81 on 8 degrees of freedom.\n#> The p-value is 0.063\n\nLáthatjuk, hogy a khi-négyzet statisztika szerint a modell illeszkedik az adatokra, ellenben a modell magyarázóértéke egy picit csekély: a két faktor az összvariancia 31%-át magyarázza (“Cumulative Var”).\nA faktorsúlyok alapján (“Loadings”) pedig az egyes faktorok a következőképpen alakulnak: első faktorba tartoznak a kártyajátékosok, üzletemberek, akik fogadnak, illetve a blöffölők, míg a második faktorba az autóversenyzők, veszélyes sportot űzők és a hivatásos katonák tartoznak. Az egyes faktorok szerkezete teljes mértékben összhangban van az előzetes elvárásunkkal.\n\nprint(fa_1$scores, digits = 3)\n#>     Factor1 Factor2\n#> 1     1.338  0.2060\n#> 2     0.191 -0.4557\n#> 3    -2.007  2.7851\n#> 4    -3.271 -2.7221\n#> 5     0.221  1.0535\n#> 6     1.390  0.1120\n#> 7     0.244 -0.9563\n#> 8     0.337 -1.8187\n#> 9    -0.918  0.1116\n#> 10    1.298  2.2779\n#> 11    0.127 -0.3024\n#> 12   -1.103 -1.0278\n#> 13    0.116  1.4488\n#> 14   -0.942  0.8179\n#> 15    0.153  0.0308\n#> 16    0.260 -0.2581\n#> 17    0.317 -1.0907\n#> 18   -0.952 -0.2752\n#> 19   -1.006  0.0461\n#> 20    0.248 -0.1641\n#> 21    1.263  0.9515\n#> 22   -0.872 -0.8891\n#> 23    0.252 -2.9866\n#> 24    1.410 -0.1078\n#> 25   -0.940  0.7251\n#> 26   -0.956 -0.0078\n#> 27   -0.980  1.3390\n#> 28    0.186  1.4272\n#> 29    1.302  0.3356\n#> 30    0.279  0.2009\n#> 31    1.291  0.0477\n#> 32   -0.958 -0.8053\n#> 33   -2.177  0.8512\n#> 34    1.502 -1.4686\n#> 35   -1.060 -0.7568\n#> 36    0.309 -1.9046\n#> 37   -0.989 -0.2453\n#> 38    0.268 -0.7376\n#> 39   -2.066  0.6141\n#> 40    0.187  1.5617\n#> 41    1.442 -0.3686\n#> 42    0.136 -3.1233\n#> 43    0.167 -0.7090\n#> 44    0.284 -0.0394\n#> 45   -0.938 -2.9296\n#> 46    0.239  1.8862\n#> 47   -0.918  0.1116\n#> 48    0.148 -0.8959\n#> 49   -0.917  1.5696\n#> 50    0.287 -2.2361\n#> 51    0.362  1.5434\n#> 52   -0.902  0.8298\n#> 53    0.177 -0.5210\n#> 54    0.233 -3.0390\n#> 55    0.215 -1.0421\n#> 56    1.338  0.2060\n#> 57   -0.917 -0.3597\n#> 58    0.290  2.2836\n#> 59    0.380  2.2216\n#> 60   -1.009  1.2532\n#> 61    0.167 -0.7090\n#> 62    0.237  0.2937\n#> 63    0.321 -0.4330\n#> 64   -0.865 -0.5882\n#> 65    1.472  1.5473\n#> 66    1.382  1.3820\n#> 67    0.216  2.3004\n#> 68   -0.901 -0.1799\n#> 69    0.136  0.4914\n#> 70    1.352 -0.1272\n#> 71    0.213 -0.3963\n#> 72    0.316 -1.2252\n#> 73    0.253 -0.5389\n#> 74    1.498 -1.3357\n#> 75    0.313 -1.1124\n#> 76    0.236 -2.5607\n#> 77    1.412 -1.5140\n#> 78   -0.806 -0.5440\n#> 79    0.357  1.3770\n#> 80    1.526 -1.8557\n#> 81   -0.956 -0.9328\n#> 82    0.213 -0.5508\n#> 83   -2.165 -2.0523\n#> 84    0.361 -2.3705\n#> 85    0.313 -1.1124\n#> 86   -0.953  0.2860\n#> 87    1.506 -1.2822\n#> 88    0.221  1.0535\n#> 89    0.287 -1.4456\n#> 90    0.163  0.5826\n#> 91   -0.919 -1.9523\n#> 92   -1.011 -1.8702\n#> 93    1.365 -0.0867\n#> 94    1.366  0.4117\n#> 95    0.133  1.7484\n#> 96    0.298  2.3371\n#> 97    1.484 -2.1467\n#> 98    0.226 -1.6345\n#> 99    1.443 -0.9944\n#> 100   1.447 -0.2023\n#> 101   0.124  0.5708\n#> 102   0.229  1.3344\n#> 103  -1.073  3.4903\n#> 104  -0.958  2.2036\n#> 105  -0.996  1.0046\n#> 106   0.219 -0.3845\n#> 107  -0.933 -1.2125\n#> 108  -0.944  1.4637\n#> 109  -0.822 -1.2422\n#> 110   0.215 -0.6436\n#> 111  -3.362  1.4583\n#> 112   0.216  0.8872\n#> 113   0.282 -1.4774\n#> 114   1.365  5.5972\n#> 115  -0.981  1.8921\n#> 116   0.276 -2.7679\n#> 117   0.256 -1.5686\n#> 118   0.167  1.3748\n#> 119   0.188 -1.2679\n#> 120  -0.878  0.6500\n#> 121   1.549 -1.0112\n#> 122  -2.162  1.4349\n#> 123   0.202 -0.3223\n#> 124   0.181 -0.5340\n#> 125   0.138  1.9148\n#> 126   1.421  2.1542\n#> 127   0.283 -1.4974\n#> 128   1.509  1.6139\n#> 129  -0.988  2.7435\n#> 130   0.432  0.4623\n#> 131   0.290  0.1269\n#> 132  -3.307  0.8877\n#> 133  -0.874 -0.2432\n#> 134  -2.065 -1.4897\n#> 135   1.471 -0.9086\n#> 136   1.485 -0.0976\n#> 137   0.277  0.8468\n#> 138   0.430 -0.4427\n#> 139   1.373  0.5580\n#> 140   0.252  1.0119\n#> 141   0.267  1.3663\n#> 142  -0.928 -0.6924\n#> 143   0.334  2.4618\n#> 144  -0.732 -1.4387\n#> 145  -0.811 -2.4603\n#> 146   0.178 -1.3014\n#> 147  -1.001  1.8978\n#> 148   1.424  0.8826\n#> 149  -0.895  2.4341\n#> 150   0.260  0.6669\n#> 151  -2.101 -0.2909\n#> 152   0.250 -1.5703\n#> 153   0.282  0.6064\n#> 154   1.445  2.5275\n#> 155   0.286 -1.4557\n#> 156   0.213  1.1345\n\nVégül kérjük le az egyes személyek faktorértékeit. Tehát az első faktor jelenti az anyagi/erkölcsi kockázatvállalás iránti attitűdöt, míg a második faktor a testi épséget veszélyeztető kockázatvállalás iránti attitűdöt.\nEzek után nézzük meg, hatással van-e az életkor a kockázatvállalás iránti attitűdre. A további munkát megkönnyítendő, bővítsük ki az adatbázisunkat a két faktor értékeivel.\n\nd <- cbind(d, fa_1$scores)\n\nElső lépésben azt nézzük meg, hogy van-e kapcsolat az életkor és az anyagi/erkölcsi téren vállalt kockázat iránti attitűd között. Eddigi ismereteink alapján ez azt jelenti, hogy lineáris regresszió-analízissel megnézzük, hogy van-e kapcsolat a kor és az első faktor faktorértékei között.\n\nsummary(lm(Factor1 ~ kor, data = d))\n#> \n#> Call:\n#> lm(formula = Factor1 ~ kor, data = d)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -2.76946 -0.43248  0.06417  0.61206  1.95774 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -2.046470   0.254725  -8.034 2.29e-13 ***\n#> kor          0.080761   0.009676   8.347 3.75e-14 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8628 on 154 degrees of freedom\n#> Multiple R-squared:  0.3115, Adjusted R-squared:  0.307 \n#> F-statistic: 69.67 on 1 and 154 DF,  p-value: 3.751e-14\n\nA fenti output kimutatja ugyan a kapcsolatot (a t- és az F-statisztika is szignifikáns), ám az R-négyzet („Multiple R-Squared”) értéke kissé gyenge magyarázóerőre utal (a független változó a függő változó varianciájának csupán 30%-át magyarázza). A kapcsolat irányáról azt állapíthatjuk meg, hogy minél idősebb valaki, annál inkább pozitívabb az anyagi/erkölcsi téren vállalt kockázat iránti attitűdje (kor változó együtthatója 0,08).\nEzt követően nézzük meg, hogy van-e kapcsolat az életkor és testi épség terén vállalt kockázat iránti attitűd között. Most is lineáris regresszió-analízissel nézzük meg, hogy van-e kapcsolat a kor és a második faktor faktorértékei között.\n\nsummary(lm(Factor2 ~ kor, data = d))\n#> \n#> Call:\n#> lm(formula = Factor2 ~ kor, data = d)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -3.6017 -0.7960 -0.0183  0.7935  4.9395 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  2.27054    0.39416   5.760 4.42e-08 ***\n#> kor         -0.08960    0.01497  -5.985 1.46e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.335 on 154 degrees of freedom\n#> Multiple R-squared:  0.1887, Adjusted R-squared:  0.1834 \n#> F-statistic: 35.82 on 1 and 154 DF,  p-value: 1.465e-08\n\nAz eredmény kimutatja ugyan a kapcsolatot ( a t- és az F-statisztika is szignifikáns), ám az R-négyzet („Multiple R-Squared”) értéke kissé gyenge magyarázóerőre utal (a független változó a függő változó varianciájának csupán 20%-át magyarázza. A kapcsolat irányáról azt állapíthatjuk meg, hogy minél idősebb valaki, annál inkább kedvezőtlenebb a testi épség terén vállalt kockázat iránti attitűdje (kor változó együtthatója -0,08).\nÖsszefoglalva, sikerült a faktoranalízissel alátámasztanunk a kockázatvállalás két faktorát. Azt is megállapítottuk, hogy mindkét faktor függ a kortól: az anyagi/erkölcsi téren vállalt kockázat iránti attitűd az évek múlásával egyre kedvezőbbé válik, míg a testi épség terén vállalt kockázat iránti attitűd idővel egyre elutasítóbbá válik.\n\n\n\nMilyen dimenziói vannak a kockázatvállalásnak és változik-e a korral a kockázatvállalás: Feltáró faktorelemzés"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#sec-bf2",
    "href": "sec_feltaro_faktorelemzes.html#sec-bf2",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.11 Példa: Még egyszer Big Five",
    "text": "4.11 Példa: Még egyszer Big Five\n\nA példa forrása: NavarroFoxcroft2022 15.1 Exploratory Factor Analysis\nKapcsolódó jamovi állomány: faktor_bfi_sample.omv\n\nA feltáró faktorlemzés (Exploratory Factor Analysis, EFA) feltár minden olyan rejtett, látens tényezőt, amelyre a megfigyelt adatainkból következtethetünk. A pszichológiában a látens tényezők olyan pszichológiai jelenségeket vagy konstruktumokat képviselnek, amelyeket nehéz közvetlenül megfigyelni vagy mérni.\nEbben a példában 25 személyiségpszichológai item elemzését végezzük, amely része a Synthetic Aperture Personality Assessment SAPA webalapú rendszernek.\nAz itemek a következők (az R-rel jelölt itemek fordított pontozásúak):\n\nBARATSA_1 - (R) Közömbös vagyok mások érzései iránt.\nBARATSA_2 - Érdeklődöm mások jólétéről.\nBARATSA_3 - Tudom, hogyan vigasztaljak meg másokat.\nBARATSA_4 - Szeretem a gyerekeket.\nBARATSA_5 - Megnyugtatom az embereket.\nLELKIIS_1 - Igényes vagyok a munkában.\nLELKIIS_2 - Addig dolgozom, amíg minden tökéletes nem lesz.\nLELKIIS_3 - A dolgokat terv szerint csinálom.\nLELKIIS_4 - (R) Félgőzzel csinálom a dolgaimat..\nLELKIIS_5 - (R) Vesztegetem az időmet.\nEXTRAVE_1 - (R) Nem beszélek sokat.\nEXTRAVE_2 - (R) Nehezemre esik másokhoz közeledni.\nEXTRAVE_3 - Tudom, hogyan nyűgözzem le az embereket.\nEXTRAVE_4 - Könnyen szerzek barátokat.\nEXTRAVE_5 - Szeretek irányítani.\nNEUROTI_1 - Hamar dühbe gurulok.\nNEUROTI_2 - Könnyen felbosszantanak.\nNEUROTI_3 - Gyakran vannak hangulat-ingadozásaim.\nNEUROTI_4 - Gyakran vagyok szomorú.\nNEUROTI_5 - Könnyen pánikba esem.\nNYITOTT_1 - Tele vagyok ötletekkel.\nNYITOTT_2 - (R) Kerülöm a nehéz olvasmányokat.\nNYITOTT_3 - A beszélgetéseket magasabb szintre viszem.\nNYITOTT_4 - Fordítok időt arra, hogy visszatekintve elmélkedjek a dolgokon.\nNYITOTT_5 - (R) Nem szoktam elmélyülni egy adott témában.\n\nA fenti táblázat összeállításához felhasználtam:\n\nHungarian Translation of the IPIP NEO Domains\nHungarian Translation of IPIP Scales Related to Intelligence and Creativity\n\nAz itemekre adott válaszok 1-6 pontos válaszskálával rendelkeztek, ahol\n\n1 - Nagyon nem értek egyet\n2 - Közepesen nem értek egyet\n3 - Kissé nem értek egyet\n4 - Kissé egyetértek\n5 - Közepesen egyetértek\n6 - Nagyon egyetértek.\n\nA válaszokat a bfi_sample.xlsx adatbázis tartalmazza. Kutatóként szeretnénk feltárni az adatokat, hogy megtudjuk, vannak-e olyan mögöttes látens tényezők, amelyeket ésszerűen jól mérnek a 25 megfigyelt változóval kapcsolatban.\n\nd <- rio::import(file = \"adat/faktor_bfi_sample.xlsx\")\nstr(d)\n#> 'data.frame':    250 obs. of  28 variables:\n#>  $ ID       : num  64432 66278 66391 62920 64835 ...\n#>  $ BARATSA_1: num  2 1 1 2 1 4 2 3 2 1 ...\n#>  $ BARATSA_2: num  3 6 6 6 5 2 5 6 5 6 ...\n#>  $ BARATSA_3: num  3 5 5 6 6 1 4 3 4 5 ...\n#>  $ BARATSA_4: num  5 1 1 6 5 4 4 5 4 6 ...\n#>  $ BARATSA_5: num  5 5 3 6 6 1 6 4 5 5 ...\n#>  $ LELKIIS_1: num  4 3 6 5 1 3 4 2 3 5 ...\n#>  $ LELKIIS_2: num  2 2 6 5 1 2 3 5 3 5 ...\n#>  $ LELKIIS_3: num  4 2 5 5 1 1 3 5 5 3 ...\n#>  $ LELKIIS_4: num  2 4 1 2 6 2 2 2 5 5 ...\n#>  $ LELKIIS_5: num  3 6 4 3 6 1 4 5 5 4 ...\n#>  $ EXTRAVE_1: num  4 5 1 5 6 6 3 2 5 4 ...\n#>  $ EXTRAVE_2: num  5 5 6 5 6 6 2 2 5 1 ...\n#>  $ EXTRAVE_3: num  4 3 4 5 6 2 4 4 3 4 ...\n#>  $ EXTRAVE_4: num  3 4 5 5 5 1 5 5 5 5 ...\n#>  $ EXTRAVE_5: num  2 5 6 4 2 5 3 5 4 6 ...\n#>  $ NEUROTI_1: num  5 2 1 1 6 1 1 5 3 4 ...\n#>  $ NEUROTI_2: num  4 4 5 5 5 1 1 6 2 4 ...\n#>  $ NEUROTI_3: num  3 4 1 4 6 1 2 6 2 3 ...\n#>  $ NEUROTI_4: num  2 5 6 6 6 1 4 5 6 5 ...\n#>  $ NEUROTI_5: num  4 2 5 6 6 1 2 5 5 4 ...\n#>  $ NYITOTT_1: num  4 4 6 6 6 5 3 6 3 4 ...\n#>  $ NYITOTT_2: num  2 4 3 2 1 1 4 2 5 5 ...\n#>  $ NYITOTT_3: num  4 3 5 6 6 6 5 4 3 5 ...\n#>  $ NYITOTT_4: num  6 6 6 6 6 4 5 5 5 6 ...\n#>  $ NYITOTT_5: num  3 1 2 2 1 1 3 5 4 1 ...\n#>  $ nem      : chr  \"Females\" \"Females\" \"Females\" \"Females\" ...\n#>  $ kor      : num  27 24 19 22 32 24 29 14 23 51 ...\npsych::headTail(d)\n#>        ID BARATSA_1 BARATSA_2 BARATSA_3 BARATSA_4 BARATSA_5\n#> 1   64432         2         3         3         5         5\n#> 2   66278         1         6         5         1         5\n#> 3   66391         1         6         5         1         3\n#> 4   62920         2         6         6         6         6\n#> ...   ...       ...       ...       ...       ...       ...\n#> 247 67401         1         5         5         6         4\n#> 248 61661         1         5         6         5         6\n#> 249 65674         2         6         5         6         5\n#> 250 63479         1         2         5         6         5\n#>     LELKIIS_1 LELKIIS_2 LELKIIS_3 LELKIIS_4 LELKIIS_5 EXTRAVE_1\n#> 1           4         2         4         2         3         4\n#> 2           3         2         2         4         6         5\n#> 3           6         6         5         1         4         1\n#> 4           5         5         5         2         3         5\n#> ...       ...       ...       ...       ...       ...       ...\n#> 247         6         5         5         1         1         3\n#> 248         4         3         2         4         5         2\n#> 249         4         3         5         2         3         1\n#> 250         3         4         5         1         1         2\n#>     EXTRAVE_2 EXTRAVE_3 EXTRAVE_4 EXTRAVE_5 NEUROTI_1 NEUROTI_2\n#> 1           5         4         3         2         5         4\n#> 2           5         3         4         5         2         4\n#> 3           6         4         5         6         1         5\n#> 4           5         5         5         4         1         5\n#> ...       ...       ...       ...       ...       ...       ...\n#> 247         2         5         5         6         2         4\n#> 248         1         2         5         2         2         2\n#> 249         2         5         2         6         4         2\n#> 250         2         5         5         5         1         1\n#>     NEUROTI_3 NEUROTI_4 NEUROTI_5 NYITOTT_1 NYITOTT_2 NYITOTT_3\n#> 1           3         2         4         4         2         4\n#> 2           4         5         2         4         4         3\n#> 3           1         6         5         6         3         5\n#> 4           4         6         6         6         2         6\n#> ...       ...       ...       ...       ...       ...       ...\n#> 247         3         4         2         5         1         5\n#> 248         2         2         2         6         1         5\n#> 249         4         5         4         4         2         5\n#> 250         2         4         2         5         1         5\n#>     NYITOTT_4 NYITOTT_5     nem kor\n#> 1           6         3 Females  27\n#> 2           6         1 Females  24\n#> 3           6         2 Females  19\n#> 4           6         2 Females  22\n#> ...       ...       ...    <NA> ...\n#> 247         4         2 Females  40\n#> 248         5         2   Males  68\n#> 249         6         2 Females  45\n#> 250         5         2   Males  34\n\nAlkalmazási feltételek. Először ellenőrizzük az alkalmazási feltételeket:\n\na Bartlett-féle szférikus teszt szignifikáns, tehát ez a feltétel teljesül\nmintavétel megfelelőségének KMO-mértéke (MSA), összességében jó mintavételi megfelelőségre utal.\n\nFaktorok száma. Most a párhuzamos elemzési technikával kapott faktorszámot őrizzük meg, ez jelen esetben 5. A Horn-féle szimulációs módszer lényege, hogy az adatokból kapott sajátértékeket összehasonlítjuk azokkal, amelyeket véletlenszerű adatokból kapnánk. A kinyert faktorok száma az a szám, amelynek a sajátértéke nagyobb, mint amit véletlenszerű adatokkal kapnánk.\nForgatás moódja. A forgatásnak két fő megközelítése van: az ortogonális (például “varimax”) forgatás, amikor a kapott faktorok nem fognak korrelálni egymással, míg a hegyesszögű (ferde) (például “Oblimin”) forgatás lehetővé teszi a kiválasztott tényezők korrelációját. A pszichológusok tipikusan olyan dimenziókat vizsgálnak, amelyekről nem azt feltételezzük, hogy ortogonálisak egymásra, így a ferde megoldások vitathatatlanul ésszerűbbek!\nHa a ferde forgatás során a faktorok kimutatható korrelációt mutatnak (pozitív vagy negatív, és >0,3) – mint esetünkben – ez megerősítené megérzésünket, hogy a ferde forgatást részesítsük előnyben. Ha a tényezők valójában korrelálnak, akkor a ferde elforgatás jobb becslést ad a valódi tényezőkről és jobb egyszerű struktúrát, mint az ortogonális elforgatás. És ha a ferde elforgatás azt jelzi, hogy a tényezők közel nulla korrelációt mutatnak egymás között, akkor a kutató továbbléphet és végrehajthat egy ortogonális elforgatást (ami ekkor körülbelül ugyanazt a megoldást adja, mint a ferde elforgatás). A kinyert faktorok közötti korreláció ellenőrzésekor legalább egy korreláció nagyobb volt, mint 0,3, ezért az öt kinyert faktor ferde (“oblimin”) elforgatása előnyös.\nMagyarázott varianciahányad. Az adatok összesített varianciájának aránya, amelyet az öt tényező magyaráz, 46%. Az első faktor a variancia körülbelül 10%-át, a 2-4 faktor egyenként körülbelül 9%-át, az ötös faktor pedig valamivel több mint 7%-át teszi ki. Ez nem öröm, jobb lett volna ha ez az arány nagyobb.\nFaktorsúlyok - Faktorok értelmezése. A faktormátrix tartalmazza a faktorsúlyokat, vagyis, hogy a 25 különböző személyiségitem, hogyan töltődik be az öt kiválasztott faktor mindegyikére.Az 1-4 faktor az előzetes elvárásoknak megfelelően tartalmazza az itemeket. Az 5. faktor is majdnem rendben van, mindössze a NYITOTT_4 item nem az 5. faktorra, hanem a 4. faktorra illeszkedik.\nVegyük észre, hogy a fordított pontozású itemek negatív faktorterhelésűek. Például a BARATSA_1 (“Közömbös vagyok mások érzései iránt.”) és a BARATSA_2 (” Érdeklődöm mások jólétéről.”) itemek esetében láthatjuk, hogy a BARATSA_1-on a magas pontszám alacsony barátságosságot jelent, míg BARATSA_2-n a magas pontszám magas barátságosságot jelez. Emiatt BARATSA_1 negatívan korrelál a többi “barátságosság” változóval, és ezért van negatív faktorterhelése.\nA faktormátrix mellett az “egyediségét” is láthatjuk. Az egyediség a variancia azon aránya, amely “egyedi” a változóra nézve, és nem magyarázható a faktorokkal. Például BARATSA_1 varianciájának 72%-a nem magyarázható az ötfaktoros megoldásban szereplő tényezőkkel. Ezzel szemben a NEUROTI_1-nek viszonylag alacsony az a varianciája, amelyet a faktormegoldás nem vesz figyelembe (35%). Minél nagyobb az „egyediség”, annál kisebb a változó relevanciája vagy hozzájárulása a faktormodellben.\nFaktorértékek. Úgy tűnik, hogy van egy elég jó öttényezős megoldásunk, bár a megfigyelt varianciahányad összességében viszonylag alacsony. Tételezzük fel, hogy elégedettek vagyunk ezzel a megoldással, és szeretnénk felhasználni tényezőinket a további elemzésekhez. Az egyszerű lehetőség az, hogy minden egyes tényezőre kiszámoljuk az összesített (átlagos) pontszámot úgy, hogy összeadjuk minden olyan változó pontszámát, amely érdemben töltődik a faktoron, majd elosztjuk a változók számával (más szóval létrehozunk egy “átlagpontszámot” minden egyes személy számára az egyes skálák elemei között). Az adatbázisunkban szereplő minden egyes személy esetében számoljuk ki a Barátságosság pontszámát.\nMásik megoldás a faktor pontszám meghatározása. Ehhez mentenünk kell a faktorértékeket, és öt új oszlop keletkezik az adatbázisunkban. A 4. faktor jelenti a Barátságosság pontszámát.\n\n\n\nMég egyszer Big Five: Feltáró faktorelemzés\n\n\n\n\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nRózsa, S., Hupuczi, E., Martin, L., Birkás, B., Hartung, I., Hargitai, R., Varga, J., Láng, A., Tiringer, I. és Kállai, J. (2019). A Tellegen Abszorpciós Skála részletes pszichometriai elemzése. Mentálhigiéné és Pszichoszomatika, 20, 35–77. https://doi.org/10.1556/0406.20.2019.003\n\n\nWatkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best Practice. Journal of Black Psychology, 44, 219–246. https://doi.org/10.1177/0095798418771807"
  },
  {
    "objectID": "sec_megerosito_faktorelemzes.html#faktorstruktúra-megadása",
    "href": "sec_megerosito_faktorelemzes.html#faktorstruktúra-megadása",
    "title": "5  Megerősítő faktorelemzés",
    "section": "5.1 Faktorstruktúra megadása",
    "text": "5.1 Faktorstruktúra megadása\nA jamovi-ban a Factor / Confirmatory Factor Analysis menüpontban kell felvinni a fenti struktúrát.\n\n\n\nBig Five: Faktorstruktúra felépítése"
  },
  {
    "objectID": "sec_megerosito_faktorelemzes.html#eredmények-értékelése",
    "href": "sec_megerosito_faktorelemzes.html#eredmények-értékelése",
    "title": "5  Megerősítő faktorelemzés",
    "section": "5.2 Eredmények értékelése",
    "text": "5.2 Eredmények értékelése\nAz elemzés elvégzése után nézzük meg az eredményeket.\n\n5.2.1 Illeszkedési mutatók vizsgálata\nAz első dolog, amit meg kell nézni, a modellillesztés, mivel ez megmutatja, hogy a modellünk mennyire illeszkedik a megfigyelt adatokra. Számos módja van a modell illeszkedésének értékelésére.\n\nKhí-négyzet próba. A khí-négyzet próbastatisztika kis értéke azt jelzi, hogy a modell jól illeszkedik az adatokhoz. Ebben az esetben a próba nem szignifikáns \\((p>0,05)\\). A modell illeszkedésének értékelésére használt khí-négyzet statisztika azonban meglehetősen érzékeny a minta méretére, azaz nagy minta esetén a modell és az adatok elég jó illeszkedése is szinte mindig szignifikáns próbastatisztikát eredményez.\nCFI - összehasonlító illeszkedési mutató (Comparative Fit Index) - A CFI azt méri fel, hogy faktorstruktúra milyen mértékben reprodukálja a valós adatokon nyugvó kovarianciamátrixot egy független modellhez képest. A CFI mutatók értéke 0 és 1 közötti tartományba eshet, ahol az 1-hez közeli érték jelzi a szoros illeszkedést. Kezdetben a mutatók elfogadhatósági kritériumának 0,90-et adtak meg, de az utóbbi időkben inkább a 0,95-ot tekintik az elfogadhatóság alsó határának.\nTLI - Tucker–Lewis-féle Illeszkedési mutató - A TLI a CFI-hez hasonló módon méri az illeszkedést, annyi különbséggel, hogy ez a mutató a modellben használt szabadságfokot is figyelembe veszi, így kiküszöböli a vizsgálati minta méretének befolyásoló szerepét. A TLI mutatók értéke 0 és 1 közötti tartományba eshet, ahol az 1-hez közeli érték jelzi a szoros illeszkedést. Kezdetben a mutatók elfogadhatósági kritériumának 0,90-et adtak meg, de az utóbbi időkben inkább a 0,95-ot tekintik az elfogadhatóság alsó határának.\nRMSEA - a becslési hiba négyzetes átlagának gyöke (Root-Mean-Square Error of Approximation) - A Steiger-féle RMSEA mutatót a modell populációs kovariancia mátrixhoz viszonyított illeszkedésének becsléséhez használjuk. Az RMSEA az elemszámtól függetlenül hasonlítja össze, hogy a valós és az optimális paraméterekkel rendelkező hipotetikus modell kovarianciamátrixa milyen mértékben illeszkedik. Az RMSEA a modell takarékosságának megbízható jelzője, a komplex modellek hibás specifikálásának hatékony mutatója. Az RMSEA értéke is 0 és 1 közé eshet, itt azonban a kisebb, 0-hoz közel eső érték jelzi a jobb illeszkedést. Az RMSEA értékei 0,05-ig szoros illeszkedést jeleznek; 0,08-os értékig pedig megfelelő illeszkedést.\n\nA saját eredményeinket szemlélve azt láthatjuk, hogy a khi-négyzet értéke nagy és nagyon szignifikáns. A mintánk mérete nem túl nagy, így ez valószínűleg rossz illeszkedést jelez. A CFI 0,762 a TLI pedig 0,731, ami rossz illeszkedést jelez a modell és az adatok között. Az RMSEA 0,085 90%-kos konfidencia intervallum 0,077 és 0,092, és ez megint nem jó illeszkedést jelez.\n\n\n\nBig Five: Illeszkedési mutatók\n\n\n\n\n5.2.2 Faktorterhelések és faktorkovariancia becslése\nNézzük tovább a faktorterheléseket és a faktorkovariancia becsléseket. A táblázatokban látható a Z-statisztika és a p-érték mindegyik paraméterre azt jelzi, hogy ésszerűen járulnak hozzá a modellhez (azaz nem nullák), így úgy tűnik, nincs ok a megadott változó-faktor útvonalak, vagy faktor-faktor korrelációk eltávolítására a modellből. A standardizált becslések gyakran könnyebben értelmezhetők. Ezeket a Estimates / Standardized estimate opciónál lehet megadni jamovi-ban. Ezek a táblázatok könnyen beépíthetők a tudományos írásokba.\n\n\n\nBig Five: Faktorterhelés becslése\n\n\n\n\n\nBig Five: Faktorkovariancia becslése\n\n\n\n\n5.2.3 Modell javítása\nHogyan javíthatnánk a modellt? Az egyik lehetőség az, hogy átírjuk az általunk kifejlesztett itemeket. Egy másik lehetőség az, hogy néhány utólagos (post-hoc) módosítást végzünk a modellen az illeszkedés javítása érdekében. Ennek egyik módja a Modification indices használata, amely a jamovi-ban az Additional Output részben jelölhető be.\n\n\n\nBig Five: Faktorterhelések MI értékei\n\n\nAz első táblázatban (Factor Loadings - Modification Indices) a legmagasabb módosítási index (MI) értéket keressük. Eldöntjük, hogy van-e értelme ezt az itemet a modellbe bevinni. Például a táblázatban láthatjuk, hogy a modellben még nem szereplő faktorterhelések legnagyobb MI értéke 28,786, a NEUROTI_4 (“Gyakran vagyok szomorú.”) item töltése a látens “Extraverzió” faktorra. Ez azt jelzi, hogy ha ezt az utat hozzáadjuk a modellhez, akkor a khí-négyzet értéke körülbelül ugyanennyivel csökken.\nDe a mi modellünkben ennek az itemnek a hozzáadása sem elméleti sem módszertani szempontból nem támasztható alá, ezért nem jó ötlet (hacsak nem tud olyan meggyőző érvvel előállni, hogy a “Gyakran vagyok szomorú.” a neuroticizmust és az extraverziót is méri). A példa kedvéért tegyünk úgy, mintha lenne valami értelme, és adjuk hozzá ezt az utat a modellhez. Menjünk vissza a CFA felülethez, és adjuk hozzá NEUROTI_4-t az “Extraverzió” faktorhoz. A CFA eredményei most megváltoznak; a khi-négyzet 728 környékére zuhant (10 körüli esés, nagyjából az MI méretéhez hasonló, de azért annál kisebb), és a többi illeszkedési index is javult, bár csak egy kicsit. Ez nem elég: ez még mindig nem egy jól illeszkedő modell.\nHa új paramétereket adunk a modellhez, akkor mindig ellenőrizzük le újra az MI-táblázatokat, mivel az MI-k minden alkalommal frissülnek.\nVan egy másik jamovi táblázat is (Residual Covariance - Modification Indices), amely a maradék kovariancia-módosítási indexeket tartalmazza. Más szavakkal, ha egymással korreláló hibatagokat adnánk a modellhez, ilyen mértékben nőne a modell illeszkedése. Esetünkben a legnagyobb MI érték a NEUROTI_1 és NEUROTI_2 itemek által meghatározott cellában olvasható (45), vagyis e két item kovarianciájának modellhez adása esetén nő leginkább a modell illeszkedése. Adjuk a modellhez ezt az együttjárást.\n\n\n\nBig Five: Reziduálisok kovarianciája\n\n\nCélszerű egyszerre vizsgálni mindkét MI táblát, és úgy meghatározni a legnagyobb MI-t, majd átgondolni, hogy a javasolt paraméter hozzáadása ésszerűen-e, és ha lehet, akkor hozzáadjuk a modellhez. Ezután újra megkeressük a legnagyobb MI-t a már újraszámolt táblázatokban."
  },
  {
    "objectID": "sec_tobbszempontos_variancielemzes.html",
    "href": "sec_tobbszempontos_variancielemzes.html",
    "title": "6  Többszempontos varianciaelemzés",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "sec_klaszter.html#példa-fogyasztók-vásárlással-kapcsolatos-attitűdjei",
    "href": "sec_klaszter.html#példa-fogyasztók-vásárlással-kapcsolatos-attitűdjei",
    "title": "7  Klaszterelemzés",
    "section": "7.1 Példa: Fogyasztók vásárlással kapcsolatos attitűdjei",
    "text": "7.1 Példa: Fogyasztók vásárlással kapcsolatos attitűdjei\n\n7.1.1 1. A probléma megfogalmazása\nEbben a példában fogyasztókat vásárlással kapcsolatos attitűdjeik alapján szeretnénk csoportosítani. Összesen hat, attitűdváltozót vettek figyelembe: megkérték őket, hogy fejezzék ki a következő állításokkal kapcsolatban egy hétfokozatú skálán az egyetértésüket:\n\nv1: A vásárlás szórakozás.\nv2: A vásárlás nem tesz jót a pénztárcának.\nv3: A vásárlást gyakran összekötöm étteremlátogatással.\nv4: Vásárláskor megpróbálom a legjobb vételt csinálni.\nv5: Nem érdekel a vásárlás.\nv6: Az árak összehasonlításával rengeteg pénzt lehet megtakarítani.\n\nAz adatok a klaszter_fogyaszto.xlsx Excel állományban találhatók.\n\n# adatok beolvasása R-ben\nfogyaszto <- rio::import(file = \"adat/klaszter_fogyaszto.xlsx\")\nstr(fogyaszto)\n#> 'data.frame':    20 obs. of  6 variables:\n#>  $ v1: num  6 2 7 4 1 6 5 7 2 3 ...\n#>  $ v2: num  4 3 2 6 3 4 3 3 4 5 ...\n#>  $ v3: num  7 1 6 4 2 6 6 7 3 3 ...\n#>  $ v4: num  3 4 4 5 2 3 3 4 3 6 ...\n#>  $ v5: num  2 5 1 3 6 3 3 1 6 4 ...\n#>  $ v6: num  3 4 3 6 4 4 4 4 3 6 ...\npsych::headTail(fogyaszto)\n#>      v1  v2  v3  v4  v5  v6\n#> 1     6   4   7   3   2   3\n#> 2     2   3   1   4   5   4\n#> 3     7   2   6   4   1   3\n#> 4     4   6   4   5   3   6\n#> ... ... ... ... ... ... ...\n#> 17    4   4   7   2   2   5\n#> 18    3   7   2   6   4   3\n#> 19    4   6   3   7   2   7\n#> 20    2   3   2   4   7   2\n\n\n\n7.1.2 2. Távolsági vagy hasonlósági mérték kiválasztása\nMivel a klaszterelemzés célja, hogy a hasonló megfigyelési egységek egy csoportba kerüljenek, szükségünk van egy mérőszámra, azaz a hasonlóság vagy különbség számszerűsítésére.\nA klaszteranalízis kiindulópontja tehát az elemek közötti hasonlóság vagy távolság. Ezzel kapcsolatban általában rendelkezünk előzetes információkkal, amelyek alapján kiszámítjuk ezeket a hasonlóságokat vagy távolságokat. Más esetekben csak a hasonlóságok vagy távolságok mértékéről rendelkezünk információkkal.\nA legelterjedtebb módszer a hasonlóság mérésére a megfigyelési egységek páronkénti távolsága. Azok a megfigyelési egységek, amelyek között kisebb a távolság hasonlóbbak egymáshoz, mint azok, amelyek között nagyobb. Megjegyezzük, hogy a hasonlóság és a távolság egymással ellentétes fogalmak. Ebből a kapcsolatból adódik, hogy a hasonlóság és a távolság mérőszáma egymásba átalakítható. Ennek képlete a következő:\n\\[h_{ij}=100\\frac{d_{max}−d_{ij}}{d_{max}}\\] A képletben a \\(h_{ij}\\) jelöli az \\(i\\)-edik és a \\(j\\)-edik objektum közötti hasonlóságot, míg a \\(d_{ij}\\) a távolságot, a \\(d_{max}\\) pedig a távolságmátrix legnagyobb elemét jelöli.\nA legelterjedtebb távolsági mérték az euklideszi távolság: az egyes változók értékei közötti különbség négyzetösszegének a négyzetgyöke. További távolságmértékek is léteznek.\nEbben a példában az Euklideszi távolságot használjuk.\n\n# Euklideszi távolság kiszámítása a\ntavolsagmatrix <- dist(fogyaszto, method = \"euclidean\")\ntavolsagmatrix\n#>           1        2        3        4        5        6     ...\n#> 2  8.000000                                                  ...\n#> 3  2.828427 8.246211                                         ...\n#> 4  5.567764 5.567764 6.557439                                ...\n#> 5  8.306624 2.645751 9.110434 6.633250                       ...\n#> 6  1.732051 6.855655 3.316625 4.472136 7.211103              ...\n#> 7  2.236068 6.244998 3.316625 4.690416 6.480741 1.414214     ...\n#> 8  2.236068 8.774964 1.732051 6.000000 9.486833 2.828427 3.16...\n#> 9  6.928203 2.828427 8.000000 5.567764 2.236068 5.916080 5.38...\n#> 10 6.928203 4.242641 7.483315 2.236068 5.744563 5.744563 5.56...\n#> 11 7.745967 2.000000 8.366600 6.244998 1.732051 6.855655 6.08...\n#> 12 2.645751 5.916080 3.316625 3.464102 6.782330 2.000000 2.00...\n#> 13 8.062258 1.732051 7.810250 5.830952 4.000000 7.071068 6.32...\n#> 14 6.782330 6.000000 7.615773 1.732051 7.141428 5.567764 5.74...\n#> 15 3.605551 7.000000 4.358899 4.690416 7.615773 3.162278 3.74...\n#> 16 6.928203 5.291503 7.615773 2.236068 6.403124 5.744563 5.56...\n#> 17 3.000000 7.416198 4.795832 4.898979 7.211103 2.828427 2.44...\n#> 18 7.483315 4.898979 8.366600 4.123106 6.403124 6.708204 6.85...\n#> 19 7.483315 6.633250 7.745967 2.645751 8.306624 6.557439 6.70...\n#> 20 8.306624 3.000000 8.888194 7.071068 3.162278 7.348469 6.78...\n#>           8        9       10       11       12       13     ...\n#> 2                                                            ...\n#> 3                                                            ...\n#> 4                                                            ...\n#> 5                                                            ...\n#> 6                                                            ...\n#> 7                                                            ...\n#> 8                                                            ...\n#> 9  8.306624                                                  ...\n#> 10 7.280110 4.898979                                         ...\n#> 11 8.888194 2.000000 5.291503                                ...\n#> 12 3.162278 5.567764 4.582576 6.082763                       ...\n#> 13 8.485281 4.123106 4.358899 3.000000 5.830952              ...\n#> 14 7.000000 6.164414 2.000000 6.928203 4.795832 6.244998     ...\n#> 15 4.242641 6.708204 6.244998 7.141428 2.828427 7.211103 6.24...\n#> 16 7.141428 5.656854 1.414214 6.164414 4.795832 5.385165 1.41...\n#> 17 4.000000 6.403124 6.244998 7.000000 3.162278 7.615773 6.08...\n#> 18 8.426150 4.898979 3.741657 5.477226 5.567764 5.385165 4.69...\n#> 19 7.280110 7.483315 2.828427 7.745967 5.196152 6.403124 2.44...\n#> 20 9.486833 2.236068 5.916080 2.645751 6.928203 4.000000 7.41...\n#>          15       16       17       18       19\n#> 2                                              \n#> 3                                              \n#> 4                                              \n#> 5                                              \n#> 6                                              \n#> 7                                              \n#> 8                                              \n#> 9                                              \n#> 10                                             \n#> 11                                             \n#> 12                                             \n#> 13                                             \n#> 14                                             \n#> 15                                             \n#> 16 6.557439                                    \n#> 17 4.000000 5.916080                           \n#> 18 6.557439 4.898979 7.681146                  \n#> 19 6.403124 2.828427 7.000000 4.898979         \n#> 20 8.246211 6.855655 8.246211 5.567764 8.544004\n\n\n\n7.1.3 3. A klasztermódszer kiválasztása\nSzámos eljárás született a klaszteranalízis módszerén belül. Ebben a könyvben két eljárással foglalkozunk részletesen:\n\na hierarchikus eljárások: hierarchikus, faszerű felépítéssel jellemezhetők\n\nösszevonó: kiinduláskor minden elem külön klasztert alkot. A klaszterek képzése úgy történik, hogy a klasztereket egyre nagyobb klaszterekbe vonják össze.\n\nláncmódszerek: az elemeket a köztük lévő távolság kiszámíása alapján csoportosítjuk\n\negyszerű lánc: a minimális távolság, vagyis a legközelebbi szomszéd elvén alapul\nteljes lánc: a maximális távolság, vagyis a legtávolabb szomszéd elvén alapul\nátlagos lánc: két klaszter távolságát az összes elem páronkénti távolságának átlagából számítja ki.\n\nvariancia-módszer: ahol a klasztereket oly módon képzik, hogy a klasztereken belül a szórásnégyzetet minimalizálják\n\nWard-féle eljárás: a klaszterátlagoktól való négyzetes euklideszi távolságot minimalizálják\ncentroidmódszer: a klaszeterek közötti távolságot az összes változó átlagaként számított centroidok közötti távolságként határozzák meg.\n\n\nfelosztó: kiinduláskor az összes elem egyetlen egy klasztert alkot. A klaszterek képzése úgy történik, hogy a klasztereket egyre kisebb klaszterekre osztják fel.\n\nK-középpontú klaszteranalízis: olyan eljárás, amely előre meghatározott klaszterközéppontból indul ki, és úgy csoportosítja az elemeket, hogy a középponttól számított küszöbértéken belül essenek.\n\nszekvenciális küszöbértékek: kiválasztanak egy klaszterközéppontot, és minden megfigyelési egység, amely a középponttól az előre meghatározott küszöbértéken belül esik, azonos csoportba kerül. Ezután új küszöbértéket választanak és a folyamatot megismétlik a még nem csoportosított pontokra. Egy korábban már csoportosított megfigyelési egységet nem fognak újra csoportosítani.\npárhuzamos küszöbértékek: az előző módszertől annyiban tér el, hogy a klaszterközéppontokat egyidejűleg választják ki és a küszöbértékeken belüli megfigyelési egységeket a legközelebb eső középponthoz rendelik.\naz optimális felosztás módszere: abban különbözik a két fenti módszertől, hogy a megfigyelési egységeket újra hozzárendelik a klaszterhez, hogy egy általános kritériumot (például adott számú klaszterre a klaszteren belüli távolságok átlagát) optimalizáljanak.\n\n\nA K-középpontú klaszterelemzés hátránya, hogy a klaszterek számát előre meg kell adni, és a klaszterközéppontok kiválasztása esetleges. Azonban ez az eljárás gyorsabb, mint a hierarchikus eljárás és főképp nagy mintaelemszám esetén javasolt a használata.\nCélszerű a hierarchikus és nem hierarchikus módszereket egymásra építve alkalmazni. Először a hierarchikus klaszterelemzéssel, az átlagos lánc vagy Ward-féle módszert felhasználva egy kiinduló klasztermegoldáshoz jutunk. A kapott klaszterszámot és a klaszterközéppontokat inputként felhasználhatjuk az optimális felosztás módszeréhez.\nMost a hierarchikus klaszterelemzést szemléltetjük Ward-féle eljárással.\n\n# hierarchikus klaszterelemzés R-ben\nklaszter <- hclust(tavolsagmatrix, method = \"ward.D2\")\nplot(klaszter)\n\n\n\n\nA klaszterelemzés eredményének értékes ábrája a dendrogram. A fenti ábrán a vízszintes vonalak az összevont klasztereket ábrázolják. A vonal skálán való elhelyezkedése azt a távolságot mutatja meg, ahol a klasztereket összevonták. Mivel a kezdeti lépésekben a távolságok hasonló méretűek, nehéz megmondani, milyen sorrendben alakultak ki a klaszterek. Erről a pontosabb információt a következő parancsokkal kaphatunk.\n\nklaszter$merge  # az összevonások lépései: az egyes lépésekben miket vont össze: negatív szám elem, pozitív klaszter\n#>       [,1] [,2]\n#>  [1,]   -6   -7\n#>  [2,]  -10  -16\n#>  [3,]   -2  -13\n#>  [4,]   -3   -8\n#>  [5,]   -4  -14\n#>  [6,]   -5  -11\n#>  [7,]   -1    1\n#>  [8,]   -9    6\n#>  [9,]    2    5\n#> [10,]  -12    7\n#> [11,]  -20    8\n#> [12,]  -19    9\n#> [13,]  -17   10\n#> [14,]  -15   13\n#> [15,]    3   11\n#> [16,]    4   14\n#> [17,]  -18   12\n#> [18,]   15   17\n#> [19,]   16   18\nklaszter$height  # az egyes összevonások milyen távolság esetén történtek meg\n#>  [1]  1.414214  1.414214  1.732051  1.732051  1.732051  1.732051\n#>  [7]  2.160247  2.236068  2.345208  2.415229  3.000000  3.082207\n#> [13]  3.271085  4.057914  4.582576  5.033223  5.507571 13.638182\n#> [19] 17.659747\ncbind(klaszter$merge, klaszter$height)  # együtt a két fenti információ\n#>       [,1] [,2]      [,3]\n#>  [1,]   -6   -7  1.414214\n#>  [2,]  -10  -16  1.414214\n#>  [3,]   -2  -13  1.732051\n#>  [4,]   -3   -8  1.732051\n#>  [5,]   -4  -14  1.732051\n#>  [6,]   -5  -11  1.732051\n#>  [7,]   -1    1  2.160247\n#>  [8,]   -9    6  2.236068\n#>  [9,]    2    5  2.345208\n#> [10,]  -12    7  2.415229\n#> [11,]  -20    8  3.000000\n#> [12,]  -19    9  3.082207\n#> [13,]  -17   10  3.271085\n#> [14,]  -15   13  4.057914\n#> [15,]    3   11  4.582576\n#> [16,]    4   14  5.033223\n#> [17,]  -18   12  5.507571\n#> [18,]   15   17 13.638182\n#> [19,]   16   18 17.659747\n\nA fenti outputból kiolvasható, hogy 19 lépésben jutottunk el az 1 klaszteres struktúrához. Az első két oszlopban az összevont elemek vagy más kialakított klaszterek azonosítója szerepel. Negatív azonosító az objektum adatbázisban elfoglalt helyét mutatja, a pozitív azonosító pedig azt a klasztert, amelyet a hivatkozott lépésben alakítottunk ki. A 3.oszlopban azt a távolságot láthatjuk, amelyen az összevonás történt.\nVilágos, hogy az utolsó két lépésben az összevont klaszterek közötti távolság nagy. Ez az információ hasznos lehet a klaszterek számának eldöntésénél.\nA fenti elemzés jamovi-ban a snowCluster / Hierarchical Clustering vagy snowCluster / Clustering Dendrogram menüpontjaival is elvégezhető.\n\n\n\nFogyasztók hierarchikus klaszterelemzése: snowCluster / Hierarchical Clustering\n\n\n\n\n\nFogyasztók hierarchikus klaszterelemzése: snowCluster / Clustering Dendrogram\n\n\nAmennyiben K-középpontú klaszterelemzést szeretnénk végrehajtani, akkor ismerettel kell rendelkezünk a klaszterek számáról. A korábbi hierarchikus klaszterelemzés eredménye alapján a 3 klaszteres megoldás mellett döntünk. A kiinduló klaszterközéppontokat az első három véletlenszerűen választott eset értéke adja. A csoportosítás középpontjai ideiglenes középpontok, amelyekhez eseteket rendel hozzá az algoritmus. Mindegyik esetet a legközelebbi középponthoz rendeli. A klasszifikációs középpontokat mindig módosítják, amíg egy határértéket el nem érnek. A végső klaszterközéppontok a változók átlagait tükrözik a végleges megoldásban.\n\nkkozep <- kmeans(x = tavolsagmatrix, centers = 3)\nkkozep\n#> K-means clustering with 3 clusters of sizes 6, 8, 6\n#> \n#> Cluster means:\n#>          1        2        3        4        5        6        7\n#> 1 6.862188 5.439023 7.564144 2.162174 6.772019 5.799111 5.855728\n#> 2 2.285490 7.306763 2.958135 5.042656 7.775617 2.160253 2.290041\n#> 3 7.891613 2.034372 8.403615 6.152633 2.296025 6.876338 6.216759\n#>          8        9       10       11       12       13       14\n#> 1 7.187966 5.778384 2.036728 6.308718 4.733710 5.601384 2.047695\n#> 2 2.670468 6.651896 6.259566 7.270421 2.389420 7.301405 6.229253\n#> 3 8.904788 2.237278 5.075444 1.896300 6.184682 2.809193 6.649207\n#>         15       16       17       18       19       20\n#> 1 6.116402 2.131984 6.303994 3.725523 2.608512 6.895128\n#> 2 3.242432 6.283385 3.029503 7.205784 6.796789 8.029135\n#> 3 7.320453 5.959452 7.315402 5.438540 7.519380 2.507349\n#> \n#> Clustering vector:\n#>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 \n#>  2  3  2  1  3  2  2  2  3  1  3  2  3  1  2  1  2  1  1  3 \n#> \n#> Within cluster sum of squares by cluster:\n#> [1] 120.51554 170.68012  77.21363\n#>  (between_SS / total_SS =  82.1 %)\n#> \n#> Available components:\n#> \n#> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"    \n#> [5] \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"        \n#> [9] \"ifault\"\nkkozep$totss\n#> [1] 2063.469\nfogyaszto$group_2 <- kkozep$cluster  # a kapott csoportváltozó beszúrása\ntable(fogyaszto$group_2)\n#> \n#> 1 2 3 \n#> 6 8 6\n\nA fenti eredmény a klaszteranalízis eredményét mutatja. Az első sor (K-means clustering with 3 clusters of sizes 8, 6, 6) arról ad információt, hogy háromklaszteres megoldásunk van, melyek mérete 8, illetve 6 és 6 elemszám. Hogy az egyes elemek melyik klaszterbe esnek, arról a Clustering vector ad információt. Az első sor az egyes elemeket, a második pedig a csoporttagságot mutatja.\nA Cluster means az egyes klaszterek átlagos tagjának, centroidjának a jellemzőit mutatják. A Within cluster sum of squares by cluster értékei a klaszteren belüli eltérések négyzetösszegét mutatja.\nA fenti K-közép klaszterelemzés jamovi-ban is elvégezhető a snowCluster / K-means Clustering menüponttal.\n ### 4. Döntés a klaszterek számáról\nA klaszterelemzés egyik legfontosabb kérdése a klaszterek számának eldöntése. Milyen általános szabályok alapján dönthetünk:\n\nElméleti vagy gyakorlati megfontolások alapján dönthetünk a klaszterek számáról.\nHierarchikus klaszterelemzés során a klaszterek összevonására alkalmazott távolságok felhasználhatók kritériumként. A dendrogramból kiolvasható ez az információ. Az utolsó lépésnél az összevont klaszterek között nagy a távolság. Ebből következően a háromklaszteres megoldás tűnik megfelelőnek.\nA nem hierarchikus klaszterelemzésénél a belső és a külső variancia hányadosát ábrázolják a klaszterek számának függvényében. Az a pont, ahol egy könyök vagy éles törés látható, a megfelelő klaszterek számára utal. E ponton túl nem érdemes a klaszterek számát növelni.\nA klaszterek relatív méretét is érdemes figyelembe venni. Az egyelemű vagy túl kicsi gyakoriságú csoportoknak nincs értelme.\n\nAmennyiben a klaszterek összevonásánál használt távolságokat használjuk, akkor egy 10-es távolságot beállítva 3 csoportot képezhetünk:\n\nfogyaszto$group_1 <- cutree(tree = klaszter, h = 10)\ntable(fogyaszto$group_1)\n#> \n#> 1 2 3 \n#> 8 6 6\n\nLátható, hogy az egyes csoportok 8, 6 és 6 elemet tartalmaznak.\nA fenti 3 csoportnak megfelelő dendrogramot a {factoextra} csomaggal is megjeleníthetjük.\n\nhc <- factoextra::hcut(fogyaszto, 3, stand = FALSE, hc_method = \"ward.D2\",\n    hc_metric = \"euclidean\")\nfactoextra::fviz_dend(hc, repel = TRUE, lwd = 1, horiz = TRUE, cex = 0.9,\n    color_labels_by_k = TRUE)\n\n\n\n\nKassambara összefoglalja az optimális klaszterszám meghatározásának 3 leggyakoribb módszerét (Determining The Optimal Number Of Clusters: 3 Must Know Methods). A jamovi snowCluster / K-means Clustering menüpontja alatt az egyik eljárás, a gap-módszer elérhető.\nA három módszer a\n\nkönyök módszer (elbow method),\nsziluett módszer (silhouette method) és a\ngap-statisztika módszer (gap statistic method).\n\n\n7.1.3.1 Könyök módszer\nIsmert, hogy a K-közép klaszterezési eljárás mögötti alapötlet az, hogy a klasztereket úgy határozzuk meg, hogy a teljes klaszteren belüli variabilitás (a teljes klaszteren belüli négyzetösszeg, WSS) minimális legyen. A teljes WSS a klaszterezés tömörségét méri, és azt szeretnénk, hogy az a lehető legkisebb legyen.\nA könyök módszer a teljes WSS-t a klaszterek számának függvényében vizsgálja: az az optimális klaszterszám, amikor már egy újabb klaszter hozzáadása nem javítja számottevően a teljes WSS-t.\nA klaszterek optimális száma a következőképpen határozható meg:\n\nValamely klaszterezési algoritmust (például K-közép klaszterezés) futtatása \\(k\\) különböző értékeire. Például \\(k\\) értéke 1-től 10-ig fut.\nMinden \\(k\\) esetében kiszámítjuk a teljes WSS értéket.\nÁbrázoljuk a WSS görbéjét a \\(k\\) klaszterek számának megfelelően.\nA könyök elhelyezkedését az ábrán általában a klaszterek megfelelő számát jelenti.\n\n\n\n7.1.3.2 Átlagos sziluett módszer\nAz átlagos sziluett megközelítés a klaszterezés minőségét méri. Minden egyes \\(i\\) megfigyelési egységre kiszámítható a sziluett szélessége, amely az \\(S_i=(b_i−a_i)/max(a_i,b_i)\\) képlettel számolható. A fenti képletben\n\n\\(a_i\\) az \\(i\\)-t tartalmazó klaszteren belül az átlagos klaszteren belüli távolság, azaz a klaszteren belüli egyes pontok közötti átlagos távolság\n\\(b_i\\) az \\(i\\) és a tőle minimális távolságra lévő (szomszédos) klaszter távolsága (\\(i\\) és egy másik klaszter távolsága: \\(i\\) és másik klaszterben lévő pontok átlagos távolsága).\n\nAz \\(S_i\\) értéke -1 és +1 közötti lehet:\n\nA nagy \\(S_i\\)-értékkel (majdnem 1) végzett megfigyelések nagyon jól klaszterezettek.\nA kis \\(S_i\\) (körülbelül 0) azt jelenti, hogy a megfigyelés két klaszter között van.\nA negatív \\(S_i\\) értékkel rendelkező megfigyelések valószínűleg rossz klaszterbe kerültek.\n\nAz átlagos sziluett módszer a megfigyelések átlagos sziluettjét számítja ki különböző \\(k\\) értékeihez. A \\(k\\) klaszterek optimális száma az, amely maximalizálja az átlagos sziluettet a \\(k\\) lehetséges értékeinek tartományában.\nAz algoritmus hasonló a könyök módszerhez, és a következőképpen számítható ki:\n\nValamely klaszterezési algoritmust (például K-közép klaszterezés) futtatása \\(k\\) különböző értékeire. Például \\(k\\) értéke 1-től 10-ig fut.\nMinden \\(k\\) esetében kiszámítjuk a megfigyelések átlagos sziluettjét (avg.sil).\nÁbrázoljuk az avg.sil görbéjét a klaszterek száma szerint (\\(k\\)).\nA görbe maximum helyét tekintjük megfelelő számú klaszternek.\n\n\n\n7.1.3.3 A gap-statisztika módszer\nA gap-statisztikát R. Tibshirani, G. Walther és T. Hastie tette közzé 2001-ben. A megközelítés bármely klaszterezési módszerre alkalmazható.\nA gap-statisztika összehasonlítja a klaszteren belüli összesített variabilitást az adatok null referenciaeloszlása mellett várt értékévek, különböző \\(k\\)-értékeknél. Az optimális klaszterek becslése olyan érték lesz, amely maximalizálja a gap-statisztikát (azaz a legnagyobb gap-statisztikát eredményezi). Ilyenkor a klaszterezési struktúra messze van a pontok véletlenszerű egyenletes eloszlásától.\nAz algoritmus a következőképpen működik:\n\nKlaszterezzük a megfigyelt adatokat úgy, hogy a klaszterek számát \\(k=1, \\dots, k_{max}\\) értékkel változtatjuk, és számítsuk ki a \\(W_k\\) klasztereken belüli összvariabilitást.\nGeneráljunk B referencia adatkészletet véletlenszerű egyenletes eloszlással. Végezzünk klaszterezést ezen a referenciaadatkészleten változó számú klaszterrel \\(k=1, \\dots, k_{max}\\) és számítsuk ki a megfelelő teljes klasztereken belüli összvariabilitást (\\(W_{kb}\\)).\nSzámítsuk ki a becsült gap-statisztikát: \\(Gap(k)=\\frac{1}{B}\\sum_{b=1}^Blog(W_{kb})−log(W_k)\\). Számítsuk ki a statisztika szórását is.\n1.Válasszuk meg a klaszterek számát a legkisebb olyan \\(k\\)-ra, amely kielégíti a következő feltételt: \\(Gap(k)\\geq Gap(k+1)−s_{k+1}\\).\n\nA fenti 3 módszerhez tartozó ábra a {factoextra} csomag fviz_nbclust() függvényével is megjeleníthető.\n\nlibrary(factoextra)\n# Elbow method\nfviz_nbclust(x = fogyaszto, kmeans, method = \"wss\") + geom_vline(xintercept = 4,\n    linetype = 2) + labs(subtitle = \"Elbow method\")\n\n# Silhouette method\nfviz_nbclust(x = fogyaszto, kmeans, method = \"silhouette\") + labs(subtitle = \"Silhouette method\")\n\n# Gap statistic nboot = 50 to keep the function speedy.  recommended\n# value: nboot= 500 for your analysis.  Use verbose = FALSE to hide\n# computing progression.\nset.seed(123)\nfviz_nbclust(x = fogyaszto, kmeans, nstart = 25, method = \"gap_stat\", nboot = 50) +\n    labs(subtitle = \"Gap statistic method\")\n\n\n\n\n\n\n\n\n\n\nA könyök módszer 4, a sziluett módszer és a gap-statisztikán alapuló módszer 3 klasztert tart optimálisnak.\n\n\n\n7.1.4 5. A klaszterek értelmezése és jellemzése\nA klaszterek értelmezését és jellemzését a klasztercentroidok (átlagok) értelmezésével végezzük. A centroidokon a klaszterekbe tartozó megfigyelési egységeknek a az összes változó alapján számított átlagát értjük. A centroidok lehetővé teszik, hogy mindegyik klaszterhez egy nevet vagy címkét rendeljünk.\nAz 1. klaszteren viszonylag magas az értéke az 1. változónak (a vásárlás szórakozás) és a 3. változónak (a vásárlást étteremlátogatással köti össze). Alacsony az értéke az 5. változónak (nem érdekel a vásárlás). Az 1. klaszter a “Szórakozáskedvelő, érdeklődő vásárlók” névvel jelölhető. Ez a klaszter az 1, 3, 6, 7, 8, 12, 15 és a 17 eseteket tartalmazza. A 2. klaszter éppen az előző klaszter ellentettje, mivel alacsony az 1. és a 3. változó értéke, és magas az 5. változó átlaga, ezért “Apatikus vásárlónak” nevezhetjük el. A 2. klaszter tagjait a 2, 5, 9, 11, 13 és 20 elemek alkotják. A 3. klaszternél a 2. változó (a vásárlás megterheli a pénztárcát), a 4. változó (vásárláskor a legjobb vételt akarom csinálni) és a 6. változó (az árak összehasonlításával sokat lehet megtakarítani) értéke magas. Ennek következtében ez a klaszter a “Takarékos vásárlók” nevet kapta. A klasztereket a 4, 10, 14, 16, 18 és 19 eseteket foglalja magában.\nGyakran segít a klaszterek értelmezésében és jellemzésében olyan változók bevonása, amelyeket nem használtunk fel a klaszterelemzésben. Ezek lehetnek például demográfiai adatok.\n\n\n7.1.5 6. A klaszterelemzés megbízhatóságának és érvényességének ellenőrzése\nA klasztermegoldás megbízhatóságát és érvényességét is ellenőrizni kell. Ezek igen komplex eljárások, és teljes mértékben nem igazolhatók. A következő eljárások jól használhatók a klasztereredmények minőségének értékelésére.\n\nA klaszterelemzést elvégezzük ugyanazokkal az adatokkal, de más távolságmértéket használunk. A két mérték alapján kapott eredményeket összehasonlítjuk.\nKülönböző klasztereljárásokat alkalmazunk, és összehasonlítjuk az eredményeket.\nAz adatokat véletlenszerűen két csoportra osztjuk. Mindkét részre elvégezzük a klaszterelemzést. Összehasonlítjuk a a két alminta klaszterátlagait. Véletlenszerűen elhagyunk változókat, és a klaszterelemzést a csökkentett számú változók alapján végezzük el. Hasonlítsuk össze az eredményeket a teljes változókészlettel kapott eredménnyel.\nA nem hierarchikus klaszterelemzésnél a megoldás az esetek adatbázisban elfoglalt sorrendjétől is függhet. Futtassuk az elemzést az esetek különböző sorrendjével, amíg a megoldás nem stabilizálódik.\n\n\ntable(fogyaszto$group_1, fogyaszto$group_2)\n#>    \n#>     1 2 3\n#>   1 0 8 0\n#>   2 0 0 6\n#>   3 6 0 0\n\nA fenti kétdimenziós gyakorisági táblázatból kiolvasható, hogy a hierarchikus klaszterelemzés és a K-középpontú klaszterelemzés ugyanazt az eredményt szolgáltatja (kivéve a csoportok elnevezését)."
  },
  {
    "objectID": "sec_klaszter.html#példa-vállalatok-vizsgálata",
    "href": "sec_klaszter.html#példa-vállalatok-vizsgálata",
    "title": "7  Klaszterelemzés",
    "section": "7.2 Példa: Vállalatok vizsgálata",
    "text": "7.2 Példa: Vállalatok vizsgálata\nA következő problémában különböző vállalatokat próbálunk meg klaszterezni. A vállalatokat számtalan jellemző mentén mérhetjük, vizsgálhatjuk, ezáltal többféleképpen is csoportosíthatjuk őket. A csoportosítás alapjául mi most a vállalat nagyságát, a hatalmi távolságot és a vállalat szemléletében jelen levő konzervativizmus mértékét választottuk. Az adatok, ahogyan az az 5.27. R-forráskódon is látható.\n\nvallalat <- rio::import(file = \"adat/klaszter_vallalatok.xlsx\")\nstr(vallalat)\n#> 'data.frame':    10 obs. of  4 variables:\n#>  $ NEV     : chr  \"A vallalat\" \"B vallalat\" \"C vallalat\" \"D v...\n#>  $ MERET   : num  75 1500 2000 21 1000 900 1000 35 120 100\n#>  $ HATALMIT: num  1 10 11 3 10 11 10 4 2 5\n#>  $ KONZERVA: num  2 9 8 4 9 8 11 3 2 4\npsych::headTail(vallalat)\n#>            NEV MERET HATALMIT KONZERVA\n#> 1   A vallalat    75        1        2\n#> 2   B vallalat  1500       10        9\n#> 3   C vallalat  2000       11        8\n#> 4   D vallalat    21        3        4\n#> ...       <NA>   ...      ...      ...\n#> 7   G vallalat  1000       10       11\n#> 8   H vallalat    35        4        3\n#> 9   I vallalat   120        2        2\n#> 10  J vallalat   100        5        4\n\nVégezzünk hierarchikus klaszterelemzést. Ehhez először a távolságmátrixot határozzuk meg. Ehhez első lépésként másoljuk a sornevekbe a vállalatok nevét, mert akkor a kapott dendrogram levelein a vállalatok neveit fogjuk látni és így sokkal áttekinthetőbb ábrát fogunk kapni és könnyebben tudjuk azonosítani az egyes klasztereket.\n\n# a vállalatnevek a sornevekbe íródnak\nrownames(vallalat) <- vallalat$NEV\n\nSzámítsuk ki a távolságmátrixot, használjunk Euklideszi távolságot.\n\ntavolsagmatrix <- dist(vallalat[2:4], method = \"euclidean\")\nprint(tavolsagmatrix, digits = 1)\n#>            A vallalat B vallalat C vallalat D vallalat E vall...\n#> B vallalat       1425                                        ...\n#> C vallalat       1925        500                             ...\n#> D vallalat         54       1479       1979                  ...\n#> E vallalat        925        500       1000        979       ...\n#> F vallalat        825        600       1100        879       ...\n#> G vallalat        925        500       1000        979       ...\n#> H vallalat         40       1465       1965         14       ...\n#> I vallalat         45       1380       1880         99       ...\n#> J vallalat         25       1400       1900         79       ...\n#>            F vallalat G vallalat H vallalat I vallalat\n#> B vallalat                                            \n#> C vallalat                                            \n#> D vallalat                                            \n#> E vallalat                                            \n#> F vallalat                                            \n#> G vallalat        100                                 \n#> H vallalat        865        965                      \n#> I vallalat        780        880         85           \n#> J vallalat        800        900         65         20\n\nA távolságmátrix birtokában már futtathatunk egy klaszteranalízist, az egyszerű lánc módszert használjuk a klaszterképzéshez.\n\nklaszter <- hclust(tavolsagmatrix, method = \"single\")\nplot(klaszter)\n\n\n\n\nA fenti dendrogramon látható, hogy alapvetően két nagy csoportja van a vizsgált vállalatoknak. Az egyikbe tartoznak a D, H, A, I és a J vállalatok, míg a másikba az F, E, G és egy kicsit távolabb a B és a C. A B és a C vállalat akár önálló klasztert is alkothat.\n\nklaszter$merge  # az összevonások lépései: az egyes lépésekben miket vont össze: negatív szám elem, pozitív klaszter\n#>       [,1] [,2]\n#>  [1,]   -5   -7\n#>  [2,]   -4   -8\n#>  [3,]   -9  -10\n#>  [4,]   -1    3\n#>  [5,]    2    4\n#>  [6,]   -6    1\n#>  [7,]   -2    6\n#>  [8,]   -3    7\n#>  [9,]    5    8\nklaszter$height  # az egyes összevonások milyen távolság esetén történtek meg\n#> [1]   2.00000  14.07125  20.32240  25.39685  40.12481 100.01000\n#> [7] 500.00000 500.00200 780.07500\ncbind(klaszter$merge, klaszter$height)  # együtt a két fenti információ\n#>       [,1] [,2]      [,3]\n#>  [1,]   -5   -7   2.00000\n#>  [2,]   -4   -8  14.07125\n#>  [3,]   -9  -10  20.32240\n#>  [4,]   -1    3  25.39685\n#>  [5,]    2    4  40.12481\n#>  [6,]   -6    1 100.01000\n#>  [7,]   -2    6 500.00000\n#>  [8,]   -3    7 500.00200\n#>  [9,]    5    8 780.07500\n\nA fenti elemzés jamovi-ban a snowCluster / Hierarchical Clustering vagy snowCluster / Clustering Dendrogram menüpontjaival is elvégezhető.\n\n\n\nVállalatok hierarchikus klaszterelemzése: snowCluster / Hierarchical Clustering\n\n\n\n\n\nVállalatok hierarchikus klaszterelemzése: snowCluster / Clustering Dendrogram"
  },
  {
    "objectID": "sec_klaszter.html#példa-étteremlátogatással-kapcsolatos-attitűdök-vizsgálata",
    "href": "sec_klaszter.html#példa-étteremlátogatással-kapcsolatos-attitűdök-vizsgálata",
    "title": "7  Klaszterelemzés",
    "section": "7.3 Példa: Étteremlátogatással kapcsolatos attitűdök vizsgálata",
    "text": "7.3 Példa: Étteremlátogatással kapcsolatos attitűdök vizsgálata\nA vásárláshoz hasonlóan az étteremlátogatás is viszonylag megosztja az embereket. Vannak, akik felesleges kiadásnak tartják, és inkább otthon, saját maguk főznek. Vannak, akik igyekeznek kímélni magukat az ilyesfajta házimunkáktól - vagy egyszerűen nem tudnak főzni - és ebből kifolyólag az éttermek rendszeres látogatói. Megint mások csupán praktikus okokból járnak étterembe: ünnepek alkalmával, baráti összejövetelekkor stb. A következőkben a klaszteranalízis segítségével az étteremlátogatással kapcsolatos attitűdöket fogjuk szemügyre venni.\nA vizsgálathoz szükséges adatok a klaszter_etteremlatogatas.xlsx állományban találhatok.\n\netterem <- rio::import(file = \"adat/klaszter_etteremlatogatas.xlsx\")\nstr(etterem)\n#> 'data.frame':    20 obs. of  8 variables:\n#>  $ V1: num  6 2 7 4 1 6 5 7 2 3 ...\n#>  $ V2: num  4 3 2 6 3 4 3 3 4 5 ...\n#>  $ V3: num  7 1 6 4 2 6 6 7 3 3 ...\n#>  $ V4: num  3 4 4 5 2 2 3 4 3 6 ...\n#>  $ V5: num  2 5 1 3 6 3 3 1 6 4 ...\n#>  $ V6: num  4 4 3 6 4 4 4 4 3 6 ...\n#>  $ V7: num  2 5 1 3 7 3 3 1 6 4 ...\n#>  $ V8: num  5 4 3 6 4 4 5 4 3 6 ...\npsych::headTail(etterem)\n#>      V1  V2  V3  V4  V5  V6  V7  V8\n#> 1     6   4   7   3   2   4   2   5\n#> 2     2   3   1   4   5   4   5   4\n#> 3     7   2   6   4   1   3   1   3\n#> 4     4   6   4   5   3   6   3   6\n#> ... ... ... ... ... ... ... ... ...\n#> 17    4   4   7   2   2   5   2   5\n#> 18    3   7   2   6   4   3   4   3\n#> 19    4   6   3   7   2   7   2   7\n#> 20    3   3   2   4   7   2   5   3\n\nAz egyes itemek a következők:\n\nV1: Ha csak tehetem, étteremben ebédelek.\nV2: Munkahelyemen szívesen választom a munkahelyi étkezdét.\nV3: Szerintem éttermek nélkül nem is lenne kerek a világ.\nV4: Családi alkalmak, ünnepek esetén szívesen étkezem étteremben.\nV5: Szerintem étteremben étkezni merő pénzpocséklás.\nV6: Időnként szívesen étkezem házon kívül.\nV7: Előnyben részesítem a saját főztömet.\nV8: Szívesen járok korrekt árakkal dolgozó éttermekbe.\n\nVégezzünk K-közép klaszterelemzést!\nElső lépésként most is a csoporton belüli négyzetösszegeket ábrázoljuk a lehetséges klaszterszámok függvényében, hogy el tudjuk dönteni, hány klaszteres megoldás lenne a megfelelő az adatokra.\n\nn <- length(etterem$V1)\nwss1 <- (n - 1) * sum(apply(etterem, 2, var))  # teljes variabilitás\nwss <- numeric(0)\n# 2-6 klaszteres megoldás kipróbálása\nfor (i in 2:6) {\n    W <- sum(kmeans(etterem, i)$withinss)\n    wss <- c(wss, W)\n}\nwss <- c(wss1, wss)\nplot(1:6, wss, type = \"l\", xlab = \"Csoportok száma\", ylab = \"Csoporton belüli\nnégyzetösszegek\",\n    lwd = 2)\n\n\n\n\nA fenti ábrán láthatjuk, hogy a hármas értéknél van éles törés a görbén, ez alapján a háromklaszteres megoldást fogjuk vizsgálni K-középpontú klaszteranalízissel.\n\nkkozep <- kmeans(x = etterem, centers = 3)\nkkozep\n#> K-means clustering with 3 clusters of sizes 7, 5, 8\n#> \n#> Cluster means:\n#>      V1       V2       V3       V4       V5       V6       V7\n#> 1 2.000 3.571429 1.857143 3.857143 5.285714 3.285714 5.142857\n#> 2 3.600 5.600000 3.600000 6.400000 3.400000 6.600000 3.400000\n#> 3 6.125 3.625000 6.000000 3.000000 2.000000 4.000000 2.000000\n#>         V8\n#> 1 3.428571\n#> 2 6.600000\n#> 3 4.250000\n#> \n#> Clustering vector:\n#>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 \n#>  3  1  3  2  1  3  3  3  1  2  1  3  1  2  3  2  3  1  2  1 \n#> \n#> Within cluster sum of squares by cluster:\n#> [1] 52.85714 17.60000 44.25000\n#>  (between_SS / total_SS =  73.8 %)\n#> \n#> Available components:\n#> \n#> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"    \n#> [5] \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"        \n#> [9] \"ifault\"\nkkozep$betweenss\n#> [1] 323.2429\n\nA fenti eredmény a klaszteranalízis eredményét mutatja. Az első sor (K-means clustering with 3 clusters of sizes 7,5,8) arról ad információt, hogy háromklaszteres megoldásunk van, melyek mérete 7, illetve 5 és 8 elemszám. Hogy az egyes elemek melyik klaszterbe esnek, arról a Clustering vector ad információt. Az első sor az egyes elemeket, a második pedig a csoporttagságot mutatja.\nA Cluster means az egyes klaszterek átlagos tagjának, centroidjának a jellemzőit mutatják. Az első klaszter átlagos tagja kiválóan érzi magát éttermek nélkül is, csak pénzpocséklásnak tartja azokat és inkább saját maga főz. A második klaszter átlagos alkalomadtán jár éttermekben (családi ünnepek esetén például), esetleg a munkahelyi étkezdét használja, előnyben részesíti a mérsékeltebb árakat. Míg a harmadik klaszter átlagos tagja szívesen jár éttermekbe, nem is nagyon szeret főzni.\nA Within cluster sum of squares by cluster értékei a klaszteren belüli eltérések négyzetösszegét mutatja.\nAz eredmények alapján vannak olyan emberek, akik szeretnek étterembe járni, az számukra egy életforma, s vannak olyanok, akik az otthoni konyhát részesítik előnyben. Ugyanakkor vannak megfontoltabb emberek is, akik igyekeznek energiájukkal takarékoskodni, ezért munkahelyen vagy valamilyen nagyobb összejövetel esetén szívesen étkeznek házon kívül.\nA fenti K-közép klaszterelemzés jamovi-ban is elvégezhető a snowCluster / K-means Clustering menüponttal.\n\n\n\nÉtteremlátogatás - snowCluster / K-means Clustering"
  },
  {
    "objectID": "sec_klaszter.html#példa-vásárlói-attitűdök-vizsgálata",
    "href": "sec_klaszter.html#példa-vásárlói-attitűdök-vizsgálata",
    "title": "7  Klaszterelemzés",
    "section": "7.4 Példa: Vásárlói attitűdök vizsgálata",
    "text": "7.4 Példa: Vásárlói attitűdök vizsgálata\nVásárolni mindenki szokott. Van, akinek szenvedélye a vásárlás, mások, pedig ha csak lehet, kerülik az üzleteket. Ebben a példában annak fogunk utánajárni, hogy milyen tipikus vásárlási attitűdök vannak. A vizsgálathoz szükséges adatokat a klaszter_vasarloi_attitudok.xlsx tartalmazza.\n\nvasarlok <- rio::import(file = \"adat/klaszter_vasarloi_attitudok.xlsx\")\nstr(vasarlok)\n#> 'data.frame':    20 obs. of  6 variables:\n#>  $ V1: num  6 2 7 4 1 6 5 7 2 3 ...\n#>  $ V2: num  4 3 2 6 3 4 3 3 4 5 ...\n#>  $ V3: num  7 1 6 4 2 6 6 7 3 3 ...\n#>  $ V4: num  3 4 4 5 2 2 3 4 3 6 ...\n#>  $ V5: num  2 5 1 3 6 3 3 1 6 4 ...\n#>  $ V6: num  4 4 3 6 4 4 4 4 3 6 ...\npsych::headTail(vasarlok)\n#>      V1  V2  V3  V4  V5  V6\n#> 1     6   4   7   3   2   4\n#> 2     2   3   1   4   5   4\n#> 3     7   2   6   4   1   3\n#> 4     4   6   4   5   3   6\n#> ... ... ... ... ... ... ...\n#> 17    4   4   7   2   2   5\n#> 18    3   7   2   6   4   3\n#> 19    4   6   3   7   2   7\n#> 20    3   3   2   4   7   2\n\nA fenti outputban lévő változók jelentése a következő:\n\nV1: Általában igyekszem diszkont áruházakban vásárolni.\nV2: Imádok vásárolgatni.\nV3: Mindig figyelem az árleszállításokat.\nV4: A vásárlás számomra szinte egy hobbi.\nV5: Ha csak tehetem, nem én vásárolok.\nV6: Szívesen járom az üzleteket baráti társaságban.\n\nElső lépésként a csoporton belüli négyzetösszegeket ábrázoljuk a lehetséges klaszterszámok függvényében, hogy el tudjuk dönteni, hány klaszteres megoldás lenne a megfelelő az adatokra.\n\nn <- length(vasarlok$V1)\nwss1 <- (n - 1) * sum(apply(vasarlok, 2, var))\nwss <- numeric(0)\nfor (i in 2:6) {\n    W <- sum(kmeans(vasarlok, i)$withinss)\n    wss <- c(wss, W)\n}\nwss <- c(wss1, wss)\nplot(1:6, wss, type = \"l\", xlab = \"Csoportok száma\", ylab = \"Csoporton belüli\nnégyzetösszegek\",\n    lwd = 2)\n\n\n\n\nA fenti képen láthatjuk, hogy a hármas értéknél van törés a görbén, ez alapján a háromklaszteres megoldást fogjuk vizsgálni K-középpontú klaszteranalízissel.\n\nkkozep <- kmeans(vasarlok, 3)\nkkozep\n#> K-means clustering with 3 clusters of sizes 6, 8, 6\n#> \n#> Cluster means:\n#>         V1       V2       V3       V4  V5       V6\n#> 1 3.500000 5.833333 3.333333 6.333333 3.5 6.000000\n#> 2 6.125000 3.625000 6.000000 3.000000 2.0 4.000000\n#> 3 1.833333 3.000000 1.833333 3.500000 5.5 3.333333\n#> \n#> Clustering vector:\n#>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 \n#>  2  3  2  1  3  2  2  2  3  1  3  2  3  1  2  1  2  1  1  3 \n#> \n#> Within cluster sum of squares by cluster:\n#> [1] 28.50 36.75 22.00\n#>  (between_SS / total_SS =  75.1 %)\n#> \n#> Available components:\n#> \n#> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"    \n#> [5] \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"        \n#> [9] \"ifault\"\nkkozep$totss\n#> [1] 350.05\n\nA fenti output a klaszteranalízis eredményét mutatja. Az első sor (K-means clustering with 3 clusters of sizes 8,6,6) arról ad információt, hogy háromklaszteres megoldásunk van, melyek mérete 8, illetve 6, 6 elemszám. Hogy az egyes elemek melyik klaszterbe esnek, arról a Clustering vector ad információt. Az első sor az egyes elemeket, a második pedig a csoporttagságot mutatja.\nA Cluster means az egyes klaszterek átlagos tagjának, centroidjának a jellemzőit mutatják. Az első klaszter átlagos tagja igyekszik diszkontáruházakban és árleszállításokon vásárolni, minél több pénzt megtakarítani. A második klaszter átlagos tagja ha csak teheti, másokkal vásároltat be. Míg a harmadik klaszter átlagos tagja szenvedélyes vásárló, baráti társaságokkal is szívesen járja az üzleteket.\nA Within cluster sum of squares by cluster értékei a klaszteren belüli eltérések négyzetösszegét mutatja.\nAz eredmények alapján vannak olyan emberek, akik nem szeretnek vásárolni, s vannak olyanok, akiknek egyfajta hobbi a vásárlás. Ugyanakkor vannak megfontoltabb emberek is, akik igyekeznek takarékossági szempontokat is figyelembe venni, és minél olcsóbban elintézni a bevásárlásokat.\nA fenti K-közép klaszterelemzés jamovi-ban is elvégezhető a snowCluster / K-means Clustering menüponttal.\n\n\n\nVásárlói attitűdök - snowCluster / K-means Clustering"
  },
  {
    "objectID": "sec_klaszter.html#példa-csokoládémárkák-vizsgálata",
    "href": "sec_klaszter.html#példa-csokoládémárkák-vizsgálata",
    "title": "7  Klaszterelemzés",
    "section": "7.5 Példa: Csokoládémárkák vizsgálata",
    "text": "7.5 Példa: Csokoládémárkák vizsgálata\nA klaszteranalízissel elemzett jelen problémában csokoládémárkákat vizsgálunk. Összesen tíz csokimárkát ítéltek meg a személyek a csoki nagysága, krémességének és töménységének tekintetében. Azt fogjuk megvizsgálni, hogy mely csokoládék állnak a vizsgálati személyek szerint közel egymáshoz. Ennek ismerete hasznos lehet marketing szempontból - például mely csokoládékat érdemes közel tenni egymáshoz a polcon.\nAz adatokat a klaszter_csokolademarkak.xlsx tartalmazza.\n\ncsokolade <- rio::import(file = \"adat/klaszter_csokolademarkak.xlsx\")\nstr(csokolade)\n#> 'data.frame':    10 obs. of  4 variables:\n#>  $ CSOKI  : chr  \"Boci\" \"Milka\" \"Tibi\" \"Balaton\" ...\n#>  $ NAGYSAG: num  10 10 9 4 4 3 2 5 5 4\n#>  $ KREMES : num  9 10 8 5 2 7 5 7 7 8\n#>  $ TOMENY : num  7 8 6 6 4 7 7 8 9 9\npsych::headTail(csokolade)\n#>         CSOKI NAGYSAG KREMES TOMENY\n#> 1        Boci      10      9      7\n#> 2       Milka      10     10      8\n#> 3        Tibi       9      8      6\n#> 4     Balaton       4      5      6\n#> ...      <NA>     ...    ...    ...\n#> 7   Kapuciner       2      5      7\n#> 8        Mars       5      7      8\n#> 9    Snickers       5      7      9\n#> 10  Sportszel       4      8      9\n\nMost sem távolságmátrixszal dolgozunk, hanem az „eredeti” változókkal. Az adatokból számított távolságmátrixot természetesen elkészíthetjük az R segítségével is. Ehhez első lépésként a CSOKI változót másoljuk át az adatbázis sorneveibe, mert így a kapott dendrogram levelein a csokoládék neveit fogjuk látni, nem pedig számokat. Ezáltal sokkal áttekinthetőbb ábrát fogunk kapni és könnyebben tudjuk azonosítani az egyes klasztereket.\n\nrownames(csokolade) <- csokolade$CSOKI\n\nEzután kiszámíttathatjuk a távolságmátrixot az adatokra, használjuk az Euklideszi távolságot.\n\ntavolsagmatrix <- dist(csokolade[2:4])\nprint(tavolsagmatrix, digits = 1)\n#>           Boci Milka Tibi Balaton Müzliszel 3-bit Kapuciner Mars\n#> Milka        1                                                  \n#> Tibi         2     3                                            \n#> Balaton      7     8    6                                       \n#> Müzliszel   10    11    8       4                               \n#> 3-bit        7     8    6       2         6                     \n#> Kapuciner    9     9    8       2         5     2               \n#> Mars         5     6    5       3         6     2         4     \n#> Snickers     6     6    5       4         7     3         4    1\n#> Sportszel    6     6    6       4         8     2         4    2\n#>           Snickers\n#> Milka             \n#> Tibi              \n#> Balaton           \n#> Müzliszel         \n#> 3-bit             \n#> Kapuciner         \n#> Mars              \n#> Snickers          \n#> Sportszel        1\n\nA távolságmátrix birtokában már futtathatunk egy klaszteranalízist, az egyszerű lánc módszert használva a klaszterképzéshez.\n\nklaszter <- hclust(tavolsagmatrix, method = \"single\")\nplot(klaszter)\n\n\n\n\n\nklaszter$merge\n#>       [,1] [,2]\n#>  [1,]   -8   -9\n#>  [2,]   -1   -2\n#>  [3,]  -10    1\n#>  [4,]   -3    2\n#>  [5,]   -4   -7\n#>  [6,]   -6    5\n#>  [7,]    3    6\n#>  [8,]   -5    7\n#>  [9,]    4    8\nklaszter$height\n#> [1] 1.000000 1.414214 1.414214 1.732051 2.236068 2.236068 2.2...\n#> [8] 3.605551 4.582576\n\nLáthatjuk, hogy a klaszterek kialakítása 9 lépésben történt és legutolsó elemet 4,58-as távolságnál vontuk be a klaszterbe.\nA dendrogram látható, hogy alapvetően két nagy csoportja van a vizsgált csokoládéknak. Az egyikbe tartoznak a táblás csokoládék (Tibi, Milka és a Boci), míg a másikba a szeletes csokik. Az utóbbiba vonta be a módszer a müzliszeletet is, bár meglehetősen távol van a többi csokoládétól.\nA fenti elemzés jamovi-ban a snowCluster / Hierarchical Clustering vagy snowCluster / Clustering Dendrogram menüpontjaival is elvégezhető.\n\n\n\nCsokoládémárkák hierarchikus klaszterelemzése: snowCluster / Hierarchical Clustering\n\n\n\n\n\nCsokoládémárkák hierarchikus klaszterelemzése: snowCluster / Clustering Dendrogram\n\n\n\n\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-kikből-lesznek-a-balesetezők",
    "href": "sec_diszkrimninancia.html#példa-kikből-lesznek-a-balesetezők",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.1 Példa: Kikből lesznek a balesetezők?",
    "text": "8.1 Példa: Kikből lesznek a balesetezők?\nEbben a példában azt vizsgáljuk, mely tényezők járulnak hozzá a balesetekhez.\n\nbaleset <- rio::import(file = \"adat/diszkriminancia_baleset.xlsx\")\nbaleset$baleset <- factor(baleset$baleset, labels = c(\"nem volt baleste\",\n    \"volt baleste\"))\nstr(baleset)\n#> 'data.frame':    36 obs. of  5 variables:\n#>  $ baleset   : Factor w/ 2 levels \"nem volt baleste\",..: 1 1 ...\n#>  $ megosztott: num  7 6 5 6 7 3 6 7 5 6 ...\n#>  $ pontossag : num  6 6 5 6 7 3 5 7 5 6 ...\n#>  $ kockazat  : num  2 3 1 2 4 7 2 1 3 2 ...\n#>  $ eszleles  : num  7 6 5 6 7 7 7 6 3 7 ...\npsych::headTail(baleset)\n#>              baleset megosztott pontossag kockazat eszleles\n#> 1   nem volt baleste          7         6        2        7\n#> 2   nem volt baleste          6         6        3        6\n#> 3   nem volt baleste          5         5        1        5\n#> 4   nem volt baleste          6         6        2        6\n#> ...             <NA>        ...       ...      ...      ...\n#> 33      volt baleste          3         3        5        4\n#> 34      volt baleste          2         2        7        1\n#> 35      volt baleste          3         3        4        4\n#> 36      volt baleste          4         4        6        4\n\nAz adatbázisban a baleset változó azt rögzíti, hogy volt-e már balesete a személynek vagy sem. Ez lesz tehát a csoportosító változó. A többi változó, melyek segítségével próbáljuk a csoportok közötti különbséget jellemezni, olyan dolgot mérnek, mint a megosztott figyelem (megosztott változó), a figyelem pontossága (pontossag), kockázatvállalási hajlandóság (kockazat) és az észlelés gyorsasága (eszleles).\nA diszkriminancia-analízisben az első lépés annak megállapítása, vajon valóban szét lehet-e választani a balesetezők és a nem balesetezők csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(megosztott, pontossag, kockazat, eszleles) ~ baleset,\n    data = baleset)\nsummary(man_1, test = \"Wilks\")\n#>           Df   Wilks approx F num Df den Df    Pr(>F)    \n#> baleset    1 0.27605   20.324      4     31 2.645e-08 ***\n#> Residuals 34                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a balesetet szenvedett és a balesetmentes autóvezetők között.\nFuttassuk le a diszkriminancia-analízis.\n\nlda_1 <- MASS::lda(baleset ~ megosztott + pontossag + kockazat + eszleles,\n    data = baleset)\nlda_1\n#> Call:\n#> lda(baleset ~ megosztott + pontossag + kockazat + eszleles, d...\n#> \n#> Prior probabilities of groups:\n#> nem volt baleste     volt baleste \n#>        0.4722222        0.5277778 \n#> \n#> Group means:\n#>                  megosztott pontossag kockazat eszleles\n#> nem volt baleste   5.941176  5.647059 2.588235 5.941176\n#> volt baleste       2.842105  2.684211 5.578947 3.105263\n#> \n#> Coefficients of linear discriminants:\n#>                    LD1\n#> megosztott -0.25764616\n#> pontossag  -0.07708289\n#> kockazat    0.36270659\n#> eszleles   -0.36702363\n\nA fenti output alapján az előzetes valószínűsége annak, hogy valakinek még nem volt balesete 0,472, míg annak a valószínűsége, hogy már volt balesete a személynek 0,528. Ezután vizsgálhatjuk a csoportátlagokat. A balesetmentes vezetők esetében magasabb a megosztott figyelem, a figyelem pontosságának és az észlelés változójának az átlaga, míg a kockázatvállalásé alacsonyabb. Ugyanakkor a másik csoport esetében a kockázatvállalás változójának az átlaga magasabb, míg a másik három képesség változójának átlaga alacsonyabb. Vagyis a balesetmentes vezetők gyorsabban képesek észlelni és jobban meg tudják osztani a figyelmüket, figyelmük pontosabb. A balesetet szenvedett vezetők esetében ezek a képességek gyengébbek, míg jobban szeretnek kockázatot vállalni.\nVégül a kanonikus diszkriminancia együtthatók segítségével felírhatjuk a kanonikus diszkriminancia-függvényt a következő módon:\nZ = 0,3627 * kockázat - 0,367 * észlelés - 0,2567 * megosztott-0,0771 * pontosság\nUtolsó lépésként pedig megnézhetjük, mennyire hatékony a diszkriminancia-analízis vagyis összevethetjük az eredeti csoporttagságokat a modell alapján alkotott besorolásokkal.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, baleset$baleset)\ntab_1\n#>                   \n#>                    nem volt baleste volt baleste\n#>   nem volt baleste               16            2\n#>   volt baleste                    1           17\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 91.66667\n\nA fenti sorok elkészík a predikciót, majd egy táblázatban reprezentálják az eredeti és a becsült csoportba tartozásokat. A legtöbb adat a főátlóban helyezkedik el, ami igen magas helyes besorolási arányra utal. A helyes besorolások aránya 91,7%.\nA példában a gépjárműbalesetek emberi okait vizsgáltuk. Az eredmények alapján a balesetmentes vezetők gyorsabban képesek észlelni és jobban meg tudják osztani a figyelmüket, figyelmük pontosabb is. Ellenben a balesetet szenvedett vezetők esetében ezek a képességek gyengébbek, míg jobban szeretnek kockázatot vállalni."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-a-szülés-utáni-depresszió-vizsgálata",
    "href": "sec_diszkrimninancia.html#példa-a-szülés-utáni-depresszió-vizsgálata",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.2 Példa: A szülés utáni depresszió vizsgálata",
    "text": "8.2 Példa: A szülés utáni depresszió vizsgálata\nEbben a példában a szülés utáni depresszió pszichés és szociális hátterét vizsgáljuk meg a diszkriminancia-analízis segítségével.\n\ndepresszio <- rio::import(file = \"adat/diszkriminancia_depresszio.xlsx\")\ndepresszio$ppdepresszio <- factor(depresszio$ppdepresszio, labels = c(\"nincs depresszió\",\n    \"van depresszió\"))\nstr(depresszio)\n#> 'data.frame':    20 obs. of  5 variables:\n#>  $ ppdepresszio: Factor w/ 2 levels \"nincs depresszió\",..: 1 ...\n#>  $ szeretet    : num  7 6 2 6 7 4 6 7 6 7 ...\n#>  $ tulvedes    : num  4 2 8 3 9 5 3 5 3 5 ...\n#>  $ kor         : num  24 20 19 22 23 25 26 18 19 22 ...\n#>  $ iskola      : num  12 17 8 16 17 17 12 17 16 17 ...\npsych::headTail(depresszio)\n#>         ppdepresszio szeretet tulvedes kor iskola\n#> 1   nincs depresszió        7        4  24     12\n#> 2   nincs depresszió        6        2  20     17\n#> 3   nincs depresszió        2        8  19      8\n#> 4   nincs depresszió        6        3  22     16\n#> ...             <NA>      ...      ... ...    ...\n#> 17    van depresszió        4        7  30      6\n#> 18    van depresszió        4        6  24      8\n#> 19    van depresszió        3        7  21      9\n#> 20    van depresszió        2        8  18     10\n\nAz adatbázisban a ppdepresszio változó mutatja a depresszió jelenlétét, vagy hiányát. A magyarázó változók között a következő változók szerepelnek: a szeretet skála (szeretet változó), amely azt méri, hogy a személyek mennyire érzik, hogy a szüleik szeretik őket; tulvedes-sel jelölt túlvédés iránti tendencia azt mutatja, hogy mennyire hajlamosak arra a személyek, hogy túlságosan is burokban tartsák, túlvédjék gyerekeiket, illetve szeretteiket; ezeken kívül két szociológiai adat is a rendelkezésünkre áll, nevezetesen az életkor (kor változó) és az elvégzett iskolai osztályok száma (iskola).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a depressziósok és a nem depressziósok csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(szeretet, tulvedes, kor, iskola) ~ ppdepresszio,\n    data = depresszio)\nsummary(man_1, test = \"Wilks\")\n#>              Df   Wilks approx F num Df den Df    Pr(>F)    \n#> ppdepresszio  1 0.29985   8.7561      4     15 0.0007461 ***\n#> Residuals    18                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a depressziós és a nem depressziós nők között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést!\n\nlibrary(MASS)\nlda_1 <- lda(ppdepresszio ~ szeretet + tulvedes + kor + iskola, data = depresszio)\nlda_1\n#> Call:\n#> lda(ppdepresszio ~ szeretet + tulvedes + kor + iskola, data =...\n#> \n#> Prior probabilities of groups:\n#> nincs depresszió   van depresszió \n#>              0.5              0.5 \n#> \n#> Group means:\n#>                  szeretet tulvedes  kor iskola\n#> nincs depresszió      5.8      4.7 21.8   14.9\n#> van depresszió        3.3      7.5 24.0    8.3\n#> \n#> Coefficients of linear discriminants:\n#>                  LD1\n#> szeretet -0.21900671\n#> tulvedes  0.18422053\n#> kor       0.03467147\n#> iskola   -0.26661705\n\nAz fenti output alapján az előzetes valószínűségek egyenlőek. A csoportátlagok közötti különbségek azt mutatják, hogy a nem depressziósok átlaga szeretet tekintetében magasabb (5,8), mint a depressziósoké (3,3), az iskolai végzettségük is magasabb (14,9), mint a depressziósoké (8,3). Ellenben a túlvédésnél a depressziósok értek el magasabb átlagot, ők az idősebbek is (24). Vagyis azok, akik postpartum depresszióban szenvednek, úgy érzik, a szüleik kevésbé szeretik őket, túlvédőbbek a gyerekeikkel szemben, idősebbek, és az iskolai végzettségük is alacsonyabb. A kanonikus diszkriminancia egyenlet alakja:\nZ =0,1842 * túlvédés + 0,0347 * kor - 0,2666 * iskola - 0,219 * szeretet\nUtolsó momentumként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, depresszio$ppdepresszio)\ntab_1\n#>                   \n#>                    nincs depresszió van depresszió\n#>   nincs depresszió                9              0\n#>   van depresszió                  1             10\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 95\n\nLáthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit, az arány 95%.\nVagyis azok, akik postpartum depresszióban szenvednek, úgy érzik, a szüleik kevésbé szeretik őket, túlvédőbbek a gyerekeikkel szemben, idősebbek, és az iskolai végzettségük is alacsonyabb."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-pszichoszomatikus-megbetegedésekre-hajlamosító-tényezők",
    "href": "sec_diszkrimninancia.html#példa-pszichoszomatikus-megbetegedésekre-hajlamosító-tényezők",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.3 Példa: Pszichoszomatikus megbetegedésekre hajlamosító tényezők",
    "text": "8.3 Példa: Pszichoszomatikus megbetegedésekre hajlamosító tényezők\nEbben a példában a pszichoszomatikus megbetegedéseket vizsgáljuk a diszkriminancia-analízis segítségével.\n\npszichoszomatikus <- rio::import(file = \"adat/diszkriminancia_pszichoszomatika.xlsx\")\npszichoszomatikus$pszichoszomatika <- factor(pszichoszomatikus$pszichoszomatika,\n    labels = c(\"pszichoszomatikus megbetegedése van\", \"egészséges\"))\nstr(pszichoszomatikus)\n#> 'data.frame':    36 obs. of  4 variables:\n#>  $ pszichoszomatika: Factor w/ 2 levels \"pszichoszomatikus me...\n#>  $ stressz         : num  5 6 5 6 7 3 6 7 5 6 ...\n#>  $ szorongas       : num  6 6 5 6 7 3 3 7 5 6 ...\n#>  $ coping          : num  2 3 1 2 4 7 2 1 3 2 ...\npsych::headTail(pszichoszomatikus)\n#>                        pszichoszomatika stressz szorongas coping\n#> 1   pszichoszomatikus megbetegedése van       5         6      2\n#> 2   pszichoszomatikus megbetegedése van       6         6      3\n#> 3   pszichoszomatikus megbetegedése van       5         5      1\n#> 4   pszichoszomatikus megbetegedése van       6         6      2\n#> ...                                <NA>     ...       ...    ...\n#> 33                           egészséges       3         3      5\n#> 34                           egészséges       2         2      7\n#> 35                           egészséges       3         3      4\n#> 36                           egészséges       4         4      6\n\nAz adatbázisban most a pszichoszomatika változó jelzi, hogy valamilyen pszichoszomatikus megbetegedése van vagy nincs a személynek. A változók közt szerepel a személyt ért stressz mértéke (stressz), a szorongási szintje (szorongás) és a megküzdési stratégiáinak hatékonysága (coping).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a pszichoszomatikusok és a nem pszichoszomatikusok csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(stressz, szorongas, coping) ~ pszichoszomatika, data = pszichoszomatikus)\nsummary(man_1, test = \"Wilks\")\n#>                  Df   Wilks approx F num Df den Df   Pr(>F)    \n#> pszichoszomatika  1 0.37974   17.423      3     32 6.92e-07 ***\n#> Residuals        34                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a két csoport között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést.\n\nlibrary(MASS)\nlda_1 <- lda(pszichoszomatika ~ stressz + coping + szorongas, data = pszichoszomatikus)\nlda_1\n#> Call:\n#> lda(pszichoszomatika ~ stressz + coping + szorongas, data = p...\n#> \n#> Prior probabilities of groups:\n#> pszichoszomatikus megbetegedése van \n#>                           0.4722222 \n#>                          egészséges \n#>                           0.5277778 \n#> \n#> Group means:\n#>                                      stressz   coping szorongas\n#> pszichoszomatikus megbetegedése van 5.764706 2.588235  5.529412\n#> egészséges                          2.842105 5.578947  2.684211\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1\n#> stressz   -0.31309547\n#> coping     0.46637406\n#> szorongas -0.06258674\n\nA fenti outputból láthatjuk, hogy a csoporttagságok előzetes valószínűsége a pszichoszomatikusok esetében kicsit kisebb (0,472). A két csoport összevetésénél azt láthatjuk, hogy a stressz és a szorongás változó átlaga a pszichoszomatikusok esetében, míg a coping változó átlaga az egészségesen esetében magasabb. Vagyis az egészséges személyeket kevesebb stressz éri, és azzal hatékonyabban is tudnak megküzdeni, mint a pszichoszomatikusok, illetve kevesebbet is szoronganak.\nA kanonikus diszkriminancia egyenlet pedig a következő módon alakul:\nZ = 0.4664 * coping - 0,3131 * stressz - 0,0626 * szorongas\nUtolsó lépésként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, pszichoszomatikus$pszichoszomatika)\ntab_1\n#>                                      \n#>                                       pszichoszomatikus megbe...\n#>   pszichoszomatikus megbetegedése van                        ...\n#>   egészséges                                                 ...\n#>                                      \n#>                                       egészséges\n#>   pszichoszomatikus megbetegedése van          2\n#>   egészséges                                  17\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 91.66667\n\nAz eredményen láthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit. Ez az arány 91,7%.\nEbben a példában a pszichoszomatikus megbetegedések lelki okait vizsgáltuk. Az diszkriminancia-analízis eredménye szerint az egészséges személyeket kevesebb stressz éri, és azzal hatékonyabban is tudnak megküzdeni, mint a pszichoszomatikusok, valamint kevesebbet is szoronganak."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-kik-vásárolnak-gyakran-bio-termékeket",
    "href": "sec_diszkrimninancia.html#példa-kik-vásárolnak-gyakran-bio-termékeket",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.4 Példa: Kik vásárolnak gyakran bio termékeket?",
    "text": "8.4 Példa: Kik vásárolnak gyakran bio termékeket?\nUtolsó példánk a marketingkutatás területére kalauzol minket. Azt próbáljuk megvizsgálni, hogy főként kik vásárolnak bio termékeket.\n\nbio <- rio::import(file = \"adat/diszkriminancia_bio.xlsx\")\nbio$vasarlas <- factor(bio$vasarlas, labels = c(\"soha nem vesz\", \"időnként vesz\",\n    \"gyakran vesz\"))\ntable(bio$vasarlas)\n#> \n#> soha nem vesz időnként vesz  gyakran vesz \n#>            10            10            10\nstr(bio)\n#> 'data.frame':    30 obs. of  5 variables:\n#>  $ vasarlas: Factor w/ 3 levels \"soha nem vesz\",..: 1 1 1 1 1...\n#>  $ ertek   : num  2 4 2 3 1 1 2 3 4 6 ...\n#>  $ attitud : num  2 4 2 3 1 3 5 3 1 2 ...\n#>  $ fizetes : num  55 67 89 78 99 112 132 78 95 64 ...\n#>  $ kor     : num  32 56 59 48 44 39 37 40 44 43 ...\npsych::headTail(bio)\n#>          vasarlas ertek attitud fizetes kor\n#> 1   soha nem vesz     2       2      55  32\n#> 2   soha nem vesz     4       4      67  56\n#> 3   soha nem vesz     2       2      89  59\n#> 4   soha nem vesz     3       3      78  48\n#> ...          <NA>   ...     ...     ... ...\n#> 27   gyakran vesz     6       6      62  19\n#> 28   gyakran vesz     9       9      69  27\n#> 29   gyakran vesz     9       9      78  28\n#> 30   gyakran vesz     8       8      73  30\n\nAz adatbázisban a vasarlas változó mutatja a biotermékek vásárlásának gyakoriságát, amely három értéket vehet fel: a személy szinte soha nem vesz ilyen termékeket, időnként vesz, illetve gyakran vesz. A vásárlás gyakoriságát a következő változókkal próbáljuk előre jelezni: milyen értékeket tulajdonít ezeknek a termékeknek (ertek változó, minél nagyobb pontszámot kap a skálán, annál jobban értékeli a személy a bio termékeket); az attitud skála a termékek iránti attitűdöt méri, a magasabb értékek itt is kedvezőbb atttitűdöt jeleznek; ezen túl szerepel még a személy életkora (kor változó) és a fizetése is (fizetes).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a bio termékeket vásárlók három csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(ertek, attitud, fizetes, kor) ~ vasarlas, data = bio)\nsummary(man_1, test = \"Wilks\")\n#>           Df   Wilks approx F num Df den Df    Pr(>F)    \n#> vasarlas   2 0.12109   11.242      8     48 8.599e-09 ***\n#> Residuals 27                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary.aov(man_1)\n#>  Response ertek :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> vasarlas     2 146.07  73.033  27.656 2.915e-07 ***\n#> Residuals   27  71.30   2.641                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response attitud :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> vasarlas     2 211.67 105.833  57.495 1.853e-10 ***\n#> Residuals   27  49.70   1.841                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response fizetes :\n#>             Df  Sum Sq Mean Sq F value  Pr(>F)  \n#> vasarlas     2  6427.5  3213.7  3.1857 0.05726 .\n#> Residuals   27 27237.5  1008.8                  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response kor :\n#>             Df Sum Sq Mean Sq F value   Pr(>F)   \n#> vasarlas     2 1449.3  724.63  7.3001 0.002922 **\n#> Residuals   27 2680.1   99.26                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti elemzés tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a három csoport között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést.\n\nlibrary(MASS)\nlda_1 <- lda(vasarlas ~ ertek + attitud + fizetes + kor, data = bio)\nlda_1\n#> Call:\n#> lda(vasarlas ~ ertek + attitud + fizetes + kor, data = bio)\n#> \n#> Prior probabilities of groups:\n#> soha nem vesz időnként vesz  gyakran vesz \n#>     0.3333333     0.3333333     0.3333333 \n#> \n#> Group means:\n#>               ertek attitud fizetes  kor\n#> soha nem vesz   2.8     2.6    86.9 44.2\n#> időnként vesz   5.3     5.6   106.5 34.9\n#> gyakran vesz    8.2     9.1    70.7 27.2\n#> \n#> Coefficients of linear discriminants:\n#>                  LD1          LD2\n#> ertek    0.278041839 -0.175361797\n#> attitud  0.578431017  0.066376341\n#> fizetes -0.003687657 -0.032311789\n#> kor     -0.019282287  0.003972177\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9687 0.0313\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\nA fenti output alapján az elemzés elején a három vásárlási gyakoriság valószínűsége egyenlő (0,333). Ha a csoportátlagokat vizsgáljuk akkor láthatjuk, hogy mind az értékek, mind az attitűd változójának tekintetében a soha sem vásárolók átlaga a legalacsonyabb (3 mindkét változó esetében), az időnként bio termékeket vásárlók csoport átlaga középen helyezkedik el mind a két változó esetében (5 és 6), és a gyakran vásárlók átlaga a legmagasabb (8 és 9). Életkor tekintetében egy kissé másképpen alakulnak a csoportok. A legidősebbek szinte sohasem vásárolnak bio termékeket, a legfiatalabbak pedig igen gyakran vásárolnak. Fizetés tekintetében nem figyelhető meg jól magyarázható összefüggés: a legalacsonyabb fizetésűek gyakran, míg a közepes fizetésűek szinte soha sem vásárolnak bio termékeket.\nA két kanonikus diszkriminancia-egyenlet a következőképpen alakul:\nZ1 = 0,278 * ertek + 0,578 * attitud - 0,019 * kor - 0,004 *fizetes\nZ2 = -0,175 * ertek + 0,066 * attitud + 0,004 * kor - 0,032 *fizetes\nUtolsó lépésként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, bio$vasarlas)\ntab_1\n#>                \n#>                 soha nem vesz időnként vesz gyakran vesz\n#>   soha nem vesz             9             1            0\n#>   időnként vesz             1             7            1\n#>   gyakran vesz              0             2            9\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 83.33333\n\nA fenti eredményben láthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit. Ez az arány 83%.\nAz utolsó probléma körében a bio termékek vásárlásának gyakoriságát vizsgáltuk. A kapott eredményeink alapján azok, akik gyakran vásárolnak ilyen termékeket, pozitívabbak értékelik és pozitívabb attitűdökkel rendelkeznek a bio termékek irányában, fiatalabbak, fizetésük viszont alacsonyabb."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-vezetési-programok",
    "href": "sec_diszkrimninancia.html#példa-vezetési-programok",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.5 Példa: Vezetési programok",
    "text": "8.5 Példa: Vezetési programok\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nvezetes <- rio::import(file = \"adat/diszkriminancia_vezetesi_program.xlsx\")\nvezetes$SUE <- factor(vezetes$SUE)\nstr(vezetes)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ SUE      : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1...\n#>  $ szelkot  : num  4 4 5 5 3 3 3 5 3 5 ...\n#>  $ elegedett: num  1 3 4 1 2 2 4 2 1 1 ...\n#>  $ rendszer : num  2 1 2 4 4 3 2 3 4 2 ...\npsych::headTail(vezetes)\n#>      SUE szelkot elegedett rendszer\n#> 1      1       4         1        2\n#> 2      1       4         3        1\n#> 3      1       5         4        2\n#> 4      1       5         1        4\n#> ... <NA>     ...       ...      ...\n#> 27     3       1         1        5\n#> 28     3       5         1        4\n#> 29     3       5         1        5\n#> 30     3       5         3        4\n\nVégezzük el a többváltozós variancia elemzést.\n\nman_1 <- manova(cbind(szelkot, elegedett, rendszer) ~ SUE, data = vezetes)\nsummary(man_1, test = \"Wilks\")\n#>           Df  Wilks approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.1894   10.815      6     50 1.102e-07 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary.aov(man_1, test = \"Wilks\")\n#>  Response szelkot :\n#>             Df Sum Sq Mean Sq F value Pr(>F)\n#> SUE          2  2.867  1.4333  1.1057 0.3455\n#> Residuals   27 35.000  1.2963               \n#> \n#>  Response elegedett :\n#>             Df Sum Sq Mean Sq F value   Pr(>F)   \n#> SUE          2 17.267  8.6333  8.4152 0.001444 **\n#> Residuals   27 27.700  1.0259                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response rendszer :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> SUE          2 52.267 26.1333      48 1.287e-09 ***\n#> Residuals   27 14.700  0.5444                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlm_1 <- lm(szelkot ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: szelkot\n#>           Sum Sq Df F value Pr(>F)\n#> SUE        2.867  2  1.1057 0.3455\n#> Residuals 35.000 27\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.9242958\n\nlm_1 <- lm(elegedett ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: elegedett\n#>           Sum Sq Df F value   Pr(>F)   \n#> SUE       17.267  2  8.4152 0.001444 **\n#> Residuals 27.700 27                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.6160119\n\nlm_1 <- lm(rendszer ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: rendszer\n#>           Sum Sq Df F value    Pr(>F)    \n#> SUE       52.267  2      48 1.287e-09 ***\n#> Residuals 14.700 27                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.2195122\n\n\nbiotools::boxM(data = vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")], grouping = vezetes$SUE)\n#> \n#>  Box's M-test for Homogeneity of Covariance Matrices\n#> \n#> data:  vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")]\n#> Chi-Sq (approx.) = 19.607, df = 12, p-value = 0.0749\n\n\nlibrary(MASS)\nlda_1 <- lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\nlda_1\n#> Call:\n#> lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\n#> \n#> Prior probabilities of groups:\n#>         1         2         3 \n#> 0.3333333 0.3333333 0.3333333 \n#> \n#> Group means:\n#>   szelkot elegedett rendszer\n#> 1     4.0       2.1      2.7\n#> 2     4.7       3.4      1.5\n#> 3     4.1       1.6      4.7\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1       LD2\n#> szelkot   -0.07056752 0.4959142\n#> elegedett  0.10193972 0.8596451\n#> rendszer  -1.32360357 0.5392379\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9616 0.0384\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, vezetes$SUE)\ntab_1\n#>    \n#>      1  2  3\n#>   1  4  1  0\n#>   2  3  9  0\n#>   3  3  0 10\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 76.66667"
  },
  {
    "objectID": "sec_diszkrimninancia.html#megjegyzések",
    "href": "sec_diszkrimninancia.html#megjegyzések",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.6 Megjegyzések",
    "text": "8.6 Megjegyzések\nDiszkriminancia analízis esetén az adatokat nem szükséges standardizálni, ennek oka, hogy az analízis eredményét nem befolyásolja jelentős mértékben az egyes változók mértékegysége.\nA függő változónk tehát kategorikus, a függetlenek pedig numerikusak. Arra vagyunk kíváncsiak, hogy a függő változó által meghatározott csoportok mely független változókban különböznek egymástól, melyek különböztetik meg egy egymástól a függő változó kategóriáit.\nHa a kategorikus függő változónk csupán kétértékű, akkor kétváltozós diszkriminancia elemzésről beszélünk, több szint esetén többváltozós diszkiriminancia elemzésről."
  },
  {
    "objectID": "sec_diszkrimninancia.html#az-alkalmazási-feltételek",
    "href": "sec_diszkrimninancia.html#az-alkalmazási-feltételek",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.7 Az alkalmazási feltételek",
    "text": "8.7 Az alkalmazási feltételek\nA fűggő változó kategorikus két vagy több szinttel. A független változók intervallum vagy arány skálájú változók, de használhatunk dichotóm változókat és a legalább 5 fokú likert skálán mért értékeket is. A függő változó csoportjaiban nagyjából azanosnak kell lennie a csoportnagyságnak, minden csoportnak legalább két adatsort tartalmaznia kell. A mintanagyságra is figyelnünk kell, a független változók számának kisebb kell lenni, mint a legkisebb csoport esetszáma, a teljes mintanagyság legalább 10-szer nagyobb a független változók számánál. A diszkriminancia elemzés feltételezi a független változók közötti lineáris kapcsolatot.\nAz egyváltozós normalitás vizsgálatára a kiugró értékek vizsgálata javasolt, illetve megfelelő mérési skála (például nem dichotóm változó esetén) a Shapiro–Wilk-próbát is használhatjuk. A többváltozós normalitás vizsgálatához\nA csoportok szétválasztásának egyik megközelítése a Mahalanobis-féle távolságot használja. Az eljárás lényege, hogy az \\(m\\) csoportot tartalmazó minta átlagvektorával becsüljük a csoportok valódi átlagvektorát. Az egyes személyek csoportközéptől való átlagát számoljuk ki a Mahalanobis-féle távolsággal, és minden személyt abba a csoportba sorolunk be ez alapján, amelyhez közelebb esik. Ez lehet az a csoport, amelybe a személy valóban beletartozik, de lehet másik is. A helyes besorolások aránya világosan megmutatja, hogy mennyire jól lehet a csoportokat szétválasztani a használt változók alapján.\n\n# remotes::install_github('hyunsooseol/snowCluster')\n\n\nlibrary(snowCluster)\nvallalat <- rio::import(file = \"adat/diszkriminancia_vezetesi_program.sav\")\nsnowCluster::disc(\n    data = vallalat,\n    dep = SUE,\n    covs = vars(szelköt, elégedett, rendszer),\n    gm = TRUE,\n    coef = TRUE,\n    prop = TRUE,\n    tes = TRUE,\n    plot = TRUE,\n    plot1 = TRUE,\n    plot2 = TRUE)\n\n\nstr(vallalat)\nvallalat$SUE <- factor(vallalat$SUE)\n\nlda_1 <- MASS::lda(SUE ~ szelköt + elégedett + rendszer, data = vallalat)\nlda_1\n\nman_1 <- stats::manova(cbind(szelköt, elégedett, rendszer)~SUE, data=vallalat)\nman_1\nsummary(man_1, test=\"Wilks\")\nsummary.aov(man_1)\n\nF <- 1.1057 # F próbastatisztika érték\np <- 1 # függő változók száma\nn <- 30 # mintaelemszám\nk <- 3  # a független változó csoportjainak a száma\n  \nWilks_1 <-  1 / (1 + (F * p) / (n - k - 1 - p))\nWilks_1\n\n 1 - (F / (F + 27))\n\nahol F az F-érték, df1 pedig az első szab\nanova(lm(szelköt~SUE, data=vallalat), test=\"Wilks\")\n\n\nman_1 <- manova(cbind(szelköt, elégedett, rendszer)~SUE, data=vallalat)\nsummary(man_1, test=\"Wilks\")\nsummary(man_1)\n\n\ninstall.packages(\"klaR\")\ngw_1 <- klaR::greedy.wilks(SUE ~ szelköt + elégedett + rendszer, data = vallalat, output=T)\nunclass(gw_1)\nplot(gw_1)\n\njmv::mancova(\n    data = vallalat,\n    deps = vars(szelköt, elégedett, rendszer),\n    factors = SUE,\n    multivar = \"wilks\",\n    boxM = TRUE,\n    shapiro = TRUE)\n\n??'Wilk'\nrrcov::Wilks.test(SUE ~ szelköt + elégedett + rendszer, data = vallalat)\nrrcov::Wilks.test(x = vallalat[2:4], grouping=vallalat$SUE)\n\nlibrary(klaR)\ndata(iris)\nlibrary(MASS)\niris.d <- iris[,1:4]  # the data    \niris.c <- iris[,5]    # the classes \nsc_obj <- stepclass(iris.d, iris.c, \"lda\", start.vars = \"Sepal.Width\")\nsc_obj\nplot(sc_obj)\n\n## or using formulas:\nsc_obj <- stepclass(Species ~ ., data = iris, method = \"qda\", \n    start.vars = \"Sepal.Width\", criterion = \"AS\")  # same as above \nsc_obj\n\n\ndata <- rio::import(file = \"adat/diszkriminancia_alkalmassag.xlsx\")\ndata <- rio::import(file = \"adat/diszkriminancia_baleset.xlsx\")\nsnowCluster::disc(data = data, dep = baleset, covs = vars(megosztott, pontossag,\n    kockazat, eszleles), gm = TRUE, coef = TRUE, prop = TRUE, tra = TRUE,\n    plot = TRUE, plot1 = TRUE, plot2 = TRUE)\n\n\niris\n\n\n\n\n\nsnowCluster::disc(data = iris, dep = Species, covs = vars(Sepal.Length,\n    Sepal.Width, Petal.Length, Petal.Width), gm = TRUE, coef = TRUE, prop = TRUE,\n    tra = TRUE, plot = TRUE, plot1 = TRUE, plot2 = TRUE)"
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#elméleti-háttér",
    "href": "sec_tobbvaltozos_variancia.html#elméleti-háttér",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.1 Elméleti háttér",
    "text": "9.1 Elméleti háttér\nA MANOVA a többváltozós varianciaelemzés angol megfelelőjéből képzett betűszó (Multivariate ANOVA vagy Multivariate Analysis of Variance). A szokásos ANOVA kiterjesztésének tekinthető, ahol nem egy, hanem kettő vagy több függő változóval dolgozhatunk, de a cél ugyanaz: a független változó több csoportja közötti különbségek elemzése.\nFelmerülhet bennünk, hogy ha több függő változónk van, akkor mindegyikre végezzünk el külön egy-egy hagyományos ANOVA-t, azonban ez az elsőfajú hiba emelkedéséhez vezet. A MANOVA olyan megoldást kínál, amivel több függő változó kombinált információi alapján képes kimutatni a csoportkülönbségeket.\nMivel a MANOVA egynél több függő változót használ, a null- és az ellenhipotézisek kissé megváltoznak:\n\n\\(H_0\\): A csoportok várható érték vektorai minden csoportban azonosak.\n\\(H_1\\): A csoportok várható érték vektorainak legalább egyike eltér egy másiktól."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#példa-vezetési-programok",
    "href": "sec_tobbvaltozos_variancia.html#példa-vezetési-programok",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.2 Példa: Vezetési programok",
    "text": "9.2 Példa: Vezetési programok\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer). Vizsgáljuk meg, hogy a SÜE három csoportja azonosnak tekinthető-e a vizsgált 3 kérdésre (szelkot, elegedett és rendszer) adott válaszok tekintetében.\n\nvezetes <- rio::import(file = \"adat/manova_vezetesi_program.xlsx\")\nvezetes$SUE <- factor(vezetes$SUE)\nstr(vezetes)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ SUE      : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1...\n#>  $ szelkot  : num  4 4 5 5 3 3 3 5 3 5 ...\n#>  $ elegedett: num  1 3 4 1 2 2 4 2 1 1 ...\n#>  $ rendszer : num  2 1 2 4 4 3 2 3 4 2 ...\npsych::headTail(vezetes)\n#>      SUE szelkot elegedett rendszer\n#> 1      1       4         1        2\n#> 2      1       4         3        1\n#> 3      1       5         4        2\n#> 4      1       5         1        4\n#> ... <NA>     ...       ...      ...\n#> 27     3       1         1        5\n#> 28     3       5         1        4\n#> 29     3       5         1        5\n#> 30     3       5         3        4\n\nMivel a MANOVA a három stratégiai üzleti egységben (SÜE) a kérdőívek pontszámainak (vagyis a függő változók) átlagainak különbségire kérdez rá, így készítsünk dobozdiagramot mindhárom csoportban\n\nlibrary(ggplot2)\np1 <- ggplot(vezetes, aes(x = SUE, y = szelkot, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\np2 <- ggplot(vezetes, aes(x = SUE, y = elegedett, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\np3 <- ggplot(vezetes, aes(x = SUE, y = rendszer, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\ngridExtra::grid.arrange(p1, p2, p3, nrow = 1)\n\n\n\n\nÚgy tűnik, hogy a mindhárom csoport eléggé különbözik egymástól.\nVégezzük el az egyszempontos többváltozós variancia elemzést. A manova() függvény a formula= argumentumában a kettő vagy több numerikus függő változót és legalább egy független változót vár. A függő változókat most a cbind() függvénnyel fűztük egymás mellé, a független változónk pedig a 3 szintű kategorikus SUE.\n\nman_1 <- manova(formula = cbind(szelkot, elegedett, rendszer) ~ SUE, data = vezetes)\nsummary(man_1)\n#>           Df  Pillai approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.90947   7.2278      6     52 1.211e-05 ***\n#> Residuals 27                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAlapértelmezés szerint a MANOVA az R-ben a Pillai-féle tesztstatisztikáit használja. A p-érték gyakorlatilag nulla, ami azt jelenti, hogy nyugodtan elvethetjük a nullhipotézist: legalább egy csoportátlagvektor eltér a többitől.\nHasználhat más teszteket is, mint például a Wilk-lambda, a Roy-féle vagy a Hotelling-Lawley statisztikákat, de a Pillai-féle a legrobusztosabb.\n\nsummary(man_1, test = \"Wilks\")\n#>           Df  Wilks approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.1894   10.815      6     50 1.102e-07 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(man_1, test = \"Hotelling-Lawley\")\n#>           Df Hotelling-Lawley approx F num Df den Df    Pr(>F...\n#> SUE        2           3.7577   15.031      6     48 1.375e-0...\n#> Residuals 27                                                 ...\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(man_1, test = \"Roy\")\n#>           Df    Roy approx F num Df den Df    Pr(>F)    \n#> SUE        2 3.6133   31.315      3     26 8.724e-09 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA hatásnagyság kiszámítására MANOVA esetében a parciális Eta négyzet \\((\\eta_p^2)\\) mutatót használhatjuk. Azt méri, hogy a független változó milyen hatással van a függő változókra. Ha az érték 0,14 vagy nagyobb, akkor azt mondhatjuk, hogy a hatás mérete nagy. Ez most 0,45, ami azt jelenti, hogy a hatás mérete nagy.\n\neffectsize::eta_squared(man_1, partial = T)\n#> # Effect Size for ANOVA (Type I)\n#> \n#> Parameter | Eta2 (partial) |       95% CI\n#> -----------------------------------------\n#> SUE       |           0.45 | [0.24, 1.00]\n#> \n#> - One-sided CIs: upper bound fixed at [1.00].\neffectsize::interpret_eta_squared(0.45, partial = T)\n#> [1] \"large\"\n#> (Rules: field2013)\n\nMivel a MANOVA szignifikáns lett, további kérdés, hogy melyik csoport átlagvektora különbözik a többitől? Post-hoc tesztet kell végeznünk, amely esetünkben a lineáris diszkriminancia elemzés és az egyváltozós ANOVA lesz."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#post-hoc-teszt-lda",
    "href": "sec_tobbvaltozos_variancia.html#post-hoc-teszt-lda",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.3 Post-hoc teszt: LDA",
    "text": "9.3 Post-hoc teszt: LDA\nA lineáris diszkriminancia elemzés (LDA) célja, hogy változók olyan lineáris kombinációját találja meg, amely a legjobban elválaszt két vagy több csoportot. Ezáltal képesek leszünk egy olyan pontdiagramot megjeleníteni, amely az X és Y tengely két lineáris diszkriminánst jeleníti meg, a pontokat pedig a független változónak (SUE) megfelelően fogjuk színezni.\nA lineáris diszkriminancia elemzést R-ben a {MASS} csomag lda() függvényével végzünk.\n\nlibrary(MASS)\nlda_1 <- lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\nlda_1\n#> Call:\n#> lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\n#> \n#> Prior probabilities of groups:\n#>         1         2         3 \n#> 0.3333333 0.3333333 0.3333333 \n#> \n#> Group means:\n#>   szelkot elegedett rendszer\n#> 1     4.0       2.1      2.7\n#> 2     4.7       3.4      1.5\n#> 3     4.1       1.6      4.7\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1       LD2\n#> szelkot   -0.07056752 0.4959142\n#> elegedett  0.10193972 0.8596451\n#> rendszer  -1.32360357 0.5392379\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9616 0.0384\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\nA fenti együtthatókból megtudhatjuk hogyan használják fel a függő változókat az LDA döntési szabályának kialakítására. Az LD1 a következőképpen számítható ki:\nA vezetes adatmátrix numerikus változóira magunk is kiszámolhatjuk az LD1 és LDA2 értékét a predict() függvénnyel:\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\npsych::headTail(lda_1_pred$x)\n#>       LD1   LD2\n#> 1    1.16 -1.83\n#> 2    2.69 -0.65\n#> 3    1.39  1.25\n#> 4   -1.56 -0.25\n#> ...   ...   ...\n#> 27   -2.6  -1.7\n#> 28  -1.56 -0.25\n#> 29  -2.88  0.29\n#> 30  -1.35  1.47\n\nA post-hoc teszt utolsó lépése a fenti a pontdiagram megjelenítése. Ideális esetben egy vagy több csoport kiemelkedik:\n\nd <- data.frame(lda_1_pred$x, SUE = vezetes$SUE)\npsych::headTail(d)\n#>       LD1   LD2  SUE\n#> 1    1.16 -1.83    1\n#> 2    2.69 -0.65    1\n#> 3    1.39  1.25    1\n#> 4   -1.56 -0.25    1\n#> ...   ...   ... <NA>\n#> 27   -2.6  -1.7    3\n#> 28  -1.56 -0.25    3\n#> 29  -2.88  0.29    3\n#> 30  -1.35  1.47    3\n\n\nggplot(d, aes(x = LD1, y = LD2, colour = SUE)) + geom_point(size = 4)\n\n\n\n\nA képen látható, hogy a harmadik SÜE csoport eltér mindkét másik csoporttól, míg a az első két csoport eltérése egymástól nem mondható markánsnak. Könnyen elképzelhető, hogy a SÜE harmadik csoportja volt a legnagyobb hatással a nullhipotézis elutasítására."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#post-hoc-test-egyváltozós-vizsgálatok",
    "href": "sec_tobbvaltozos_variancia.html#post-hoc-test-egyváltozós-vizsgálatok",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.4 Post-hoc test: egyváltozós vizsgálatok",
    "text": "9.4 Post-hoc test: egyváltozós vizsgálatok\nA statisztikailag szignifikáns egyszempontos MANOVA után az egyváltozós egyszempontos ANOVA-val is vizsgálódhatunk, amely minden függő változót külön-külön vizsgál. A cél az, hogy azonosítsuk azokat a konkrét függő változókat, amelyek hozzájárultak a jelentős globális hatáshoz. A klasszikus ANOVA mellett a Welch-féle változat és a Kruskal–Wallis-próba is használható, a feltételek egyre nagyobb csorbulása esetén. Most a nemparaméteres Kruskal–Wallis-próbát használjuk.\n\nkruskal.test(szelkot ~ SUE, data = vezetes)$p.value\n#> [1] 0.2499069\nkruskal.test(elegedett ~ SUE, data = vezetes)$p.value\n#> [1] 0.003003241\nkruskal.test(rendszer ~ SUE, data = vezetes)$p.value\n#> [1] 1.690362e-05\n\nLátjuk, hogy az elegedett és a rendszer függő változókban nem egyeznek a várható értékek a SÜE egyes csoportjaiban. Megjegyezzük, hogy mivel 3 függő változónk van, a Bonferroni-féle többszörös tesztelési korrekciót alkalmaznunk kell, vagyis a statisztikai szignifikancia szintet csökkenteni kell. Ez úgy történik, hogy a klasszikus alfa szintet (0,05) elosztjuk a tesztek (vagy függő változók, itt 3) számával. Ez p < 0,017-es szignifikancia elfogadási kritériumhoz vezet. A fenti próbák szignifikáns voltán ez most nem változtat.\nA statisztikailag szignifikáns egyváltozós ANOVA-t (esetünkben Kruskal–Wallis-próbát) többszörös páronkénti összehasonlítás követi annak meghatározására, hogy mely csoportok különböznek egymástól. Most a Kruskal–Wallis-próba szokásos utóvizsgálatát a Dunn-próbát fogjuk használni.\n\nlibrary(DescTools)\nDunnTest(formula = szelkot ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff   pval    \n#> 2-1            5.6 0.3179    \n#> 3-1            4.0 0.4964    \n#> 3-2           -1.6 0.6442    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDunnTest(formula = elegedett ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff   pval    \n#> 2-1           8.75 0.0410 *  \n#> 3-1          -3.80 0.3143    \n#> 3-2         -12.55 0.0027 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDunnTest(formula = rendszer ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff    pval    \n#> 2-1          -6.95  0.0694 .  \n#> 3-1          10.85  0.0092 ** \n#> 3-2          17.80 9.9e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti utóvizsgálatok világossá teszik, hogy a harmadik SÜE csoport a rendszer változó esetén mindkét másik csoporttól, az elegedett változó esetén pedig a második csoporttól szignifikánsan eltér. Legjelentősebb mértékben tehűt a harmadik csoport különül el a másik két csoporttól, tehát ez okozza a MANOVA nullhipotézisének elvetését."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#elemzés-jamovi-ban",
    "href": "sec_tobbvaltozos_variancia.html#elemzés-jamovi-ban",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.5 Elemzés jamovi-ban",
    "text": "9.5 Elemzés jamovi-ban\nA fenti elemzés jamovi-ban is elvégezhető az ANOVA / MANCOVA menüpontok kiválasztásával.\n\n\n\nMANOVA jamovi-ban"
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#alkalmazási-feltételek-vizsgálata",
    "href": "sec_tobbvaltozos_variancia.html#alkalmazási-feltételek-vizsgálata",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.6 Alkalmazási feltételek vizsgálata",
    "text": "9.6 Alkalmazási feltételek vizsgálata\nA MANOVA statisztikai próbának számos szigorú alkalmazási feltétele van. Néhány az ANOVA-ból jön, például a megfigyelések függetlensége vagy a variancia homogenitása, azonban vannak újdonságok is.\n\nMegfelelő mintanagyság. Ökölszabály: a mintaelemszám mindegyik független változó csoportban nagyobb az függő változók számánál.\n\n\nsummarytools::freq(vezetes$SUE, cumul = FALSE)\n#> Frequencies  \n#> vezetes$SUE  \n#> Type: Factor  \n#> \n#>               Freq   % Valid   % Total\n#> ----------- ------ --------- ---------\n#>           1     10     33.33     33.33\n#>           2     10     33.33     33.33\n#>           3     10     33.33     33.33\n#>        <NA>      0                0.00\n#>       Total     30    100.00    100.00\n\nLátható, hogy a függő változók számát (3) minden csoport elemszáma (10) meghaladja.\n\nA megfigyelések függetlensége. Minden személynek csak egy csoportba kell tartoznia. Az egyes csoportok megfigyelései között nincs kapcsolat. Az ismételt mérések nem megengedettek. A minta kiválasztásának teljesen véletlenszerűnek kell lennie.\nAz egyváltozós vagy többváltozós kiugró értékek hiánya.\n\nAz egydimenziós kiugró értékek dobozdiagramokkal is ellenőrizhetők, ezt korábban elvégeztük, láttuk csak egyetlen részcsoportban van kiugró értékek (a szelkot változó változó esetén a SÜE harmadik csoportjában). Használhatjuk a kényelmes rstatix::identify_outliers() függvényt is.\n\nlibrary(tidyverse)\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(szelkot)\n#> # A tibble: 2 × 6\n#>   SUE   szelkot elegedett rendszer is.outlier is.extreme\n#>   <fct>   <dbl>     <dbl>    <dbl> <lgl>      <lgl>     \n#> 1 3           1         1        5 TRUE       TRUE      \n#> 2 3           1         1        5 TRUE       TRUE\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(elegedett)\n#> [1] SUE        szelkot    elegedett  rendszer   is.outlier\n#> [6] is.extreme\n#> <0 rows> (or 0-length row.names)\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(rendszer)\n#> [1] SUE        szelkot    elegedett  rendszer   is.outlier\n#> [6] is.extreme\n#> <0 rows> (or 0-length row.names)\n\nA többváltozós kiugró értékek olyan adatpontok, amelyek szokatlan értékkombinációt tartalmaznak a kimeneti (vagy függő) változókon. A Mahalanobis távolságot általában a többváltozós kiugró értékek észlelésére használják. A távolság megmondja, milyen messze van egy megfigyelés a felhő középpontjától, figyelembe véve a felhő alakját (kovariancia) is. A rstatix::mahalanobis_distance() függvény könnyen használható a Mahalanobis-távolság kiszámítására és a többváltozós kiugró értékek megjelölésére. A Mahalanobis-távolságot csoportonként kell kiszámítani:\n\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::mahalanobis_distance() %>%\n    filter(is.outlier == TRUE) %>%\n    as.data.frame()\n#> [1] szelkot    elegedett  rendszer   mahal.dist is.outlier\n#> <0 rows> (or 0-length row.names)\n\nLátható, hogy nincs többváltozós kiugró érték az adatbázisban.\n\nTöbbváltozós normalitás.\n\nA többváltozós normalitás Shapiro-Wilk tesztjének végrehajtása:\n\nrstatix::mshapiro_test(vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")])\n#> # A tibble: 1 × 2\n#>   statistic   p.value\n#>       <dbl>     <dbl>\n#> 1     0.772 0.0000214\n\nLátható, hogy ez az alkalmazási feltétel nem teljesül.\nAz egyváltozós normalitásokat is érdemes lehet tesztelni:\n\n# egyváltozós Shapiro–Wilk próba több csoportra\nlibrary(onewaytests)\nnor.test(formula = szelkot ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : szelkot and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.7685823 6.009970e-03      Reject\n#> 2     2 0.5941735 4.713464e-05      Reject\n#> 3     3 0.5876023 3.936679e-05      Reject\n#> --------------------------------------------------\nnor.test(formula = elegedett ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : elegedett and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.8236140 2.802300e-02      Reject\n#> 2     2 0.7172415 1.425861e-03      Reject\n#> 3     3 0.5941735 4.713464e-05      Reject\n#> --------------------------------------------------\nnor.test(formula = rendszer ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : rendszer and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.8737456 1.105101e-01  Not reject\n#> 2     2 0.6552710 2.539627e-04      Reject\n#> 3     3 0.5941735 4.713464e-05      Reject\n#> --------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\nA multikollinearitás hiánya. A függő (eredmény) változók nem korrelálhatnak túlságosan egymással. Egyetlen korreláció sem lehet r = 0,90 feletti.\n\nIdeális esetben az eredményváltozók közötti korreláció mérsékelt, nem túl magas. A 0,9 feletti korreláció a multikollinearitást jelzi, ami a MANOVA esetében problematikus. Másrészt, ha a korreláció túl alacsony, fontolóra kell vennie külön egyszempontos ANOVA futtatását minden függő változóra.\nSzámítsuk ki a páronkénti Pearson-korrelációs együtthatókat a függő változók között.\n\ncor(vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")])\n#>              szelkot  elegedett   rendszer\n#> szelkot    1.0000000  0.1954881 -0.2528624\n#> elegedett  0.1954881  1.0000000 -0.6129079\n#> rendszer  -0.2528624 -0.6129079  1.0000000\n\nLátható, hogy a korrelációs együtthatók nem támogatják a multikollinearitás tényét.\n\nLinearitás az összes függő változó között minden csoportban.\n\nMivel a függő változók közötti páronkénti kapcsolatnak lineárisnak kell lennie minden csoport esetében, ezért érdemes ezt a feltételt vizuálisan ellenőrizni. A {GGally} csomag ggpairs() függvényét használhatjuk.\n\nlibrary(GGally)\nres <- vezetes %>%\n    select(SUE, szelkot, elegedett, rendszer) %>%\n    group_by(SUE) %>%\n    rstatix::doo(~ggpairs(.) + theme_bw(), result = \"plots\")\nres$plots\n#> [[1]]\n#> \n#> [[2]]\n#> \n#> [[3]]\n\n\n\n\n\n\n\n\n\n\nA fenti ábrák megkérdőjelezik a páronkénti lineáris kapcsolatok létezését.\n\nA varianciák homogenitása. A Levene-próba használható a csoportok közötti varianciák egyenlőségének tesztelésére. A Levene-próba nem szignifikáns értékei a varianciák homogenitását támogatják.\n\nAz egyszempontos MANOVA mindegyik függő változó esetében azt feltételezi, hogy a csoportok között egyenlők a varianciák.\n\nDescTools::LeveneTest(szelkot ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  2  0.9755 0.3899\n#>       27\nDescTools::LeveneTest(elegedett ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  2  0.4112  0.667\n#>       27\nDescTools::LeveneTest(rendszer ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value   Pr(>F)   \n#> group  2     5.6 0.009238 **\n#>       27                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLátható, hogy a szóráshomogenitás a rendszer változó kivételével teljesül.\n\nVariancia-kovariancia mátrixok homogenitása. A BoxM-próba használható a csoportok közötti kovariancia egyenlőségének ellenőrzésére. Ez egyenértékű a variancia többváltozós homogenitásával. Ez a teszt rendkívül érzékenynek tekinthető. Ezért ennek a tesztnek a szignifikanciáját alfa = 0,001 értéknél határozzuk meg. A {biotools} csomag megvalósított boxM() függvényét használhatjuk.\n\n\nbiotools::boxM(data = vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")], grouping = vezetes$SUE)\n#> \n#>  Box's M-test for Homogeneity of Covariance Matrices\n#> \n#> data:  vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")]\n#> Chi-Sq (approx.) = 19.607, df = 12, p-value = 0.0749\n\nA teszt statisztikailag nem szignifikáns (azaz p > 0,001), tehát az adatok nem sértették meg a variancia-kovariancia mátrixok homogenitásának feltételezését.\nKiegyensúlyozott a csoportelemszámok esetén nem probléma a variancia-kovariancia mátrixok homogenitásának megsértése miatt, de kiegyensúlyozatlan kialakításnál már problémás lehet."
  },
  {
    "objectID": "sec_logisztikus_regresszio.html",
    "href": "sec_logisztikus_regresszio.html",
    "title": "10  Logisztikus regresszió",
    "section": "",
    "text": "A logisztikus regresszió céljait tekintve megegyezik a diszkriminancia elemzéssel, de sokkal robusztusabb, azaz kevesebb alkalmazási feltétellel rendelkezik. Használható a logisztikus regresszió akkor is, ha a független változók között kategorikus változók is előfordulnak, illetve a normalitásra és homoszkedaszticitásra vonatkozó feltétel megsértésre sem érzékeny a módszer.\nA logisztikus regressziónak 3 típusa van:\n\nbinomiális logisztikus regresszió: a függő változónk dichotóm, csak két értéke van,\nmultinominális logisztikus regresszió: a függő változónk olyan kategorikus változó, amelynek kettőnél több értéke van,\nordinális logisztikus regresszió: a függő változó ordinális skálán mért.\n\n\nd <- rio::import(file = \"adat/logreg_tanulo.sav\")\n\n\n# summarytools::ctable(x = d$HIVO2, y = d$HIVO01)\nDescTools::Desc(NEME2 ~ HIVO01, data = d, plotit = F)\n#> -------------------------------------------------------------...\n#> NEME2 ~ HIVO01 (d)\n#> \n#> Summary: \n#> n: 1'717, rows: 2, columns: 2\n#> \n#> Pearson's Chi-squared test (cont. adj):\n#>   X-squared = 42.748, df = 1, p-value = 6.225e-11\n#> Fisher's exact test p-value = 5.219e-11\n#> McNemar's chi-squared = 1.8435, df = 1, p-value = 0.1745\n#> \n#>                     estimate lwr.ci upr.ci'\n#>                                           \n#> odds ratio             1.925  1.583  2.341\n#> rel. risk (col1)       1.465  1.308  1.641\n#> rel. risk (col2)       0.761  0.699  0.828\n#> \n#> \n#> Contingency Coeff.     0.157\n#> Cramer's V             0.159\n#> Kendall Tau-b          0.159\n#> \n#>                                    \n#>         HIVO01      0      1    Sum\n#> NEME2                              \n#>                                    \n#> 0       freq      366    370    736\n#>         perc    21.3%  21.5%  42.9%\n#>         p.row   49.7%  50.3%      .\n#>         p.col   52.4%  36.3%      .\n#>                                    \n#> 1       freq      333    648    981\n#>         perc    19.4%  37.7%  57.1%\n#>         p.row   33.9%  66.1%      .\n#>         p.col   47.6%  63.7%      .\n#>                                    \n#> Sum     freq      699  1'018  1'717\n#>         perc    40.7%  59.3% 100.0%\n#>         p.row       .      .      .\n#>         p.col       .      .      .\n#>                                    \n#> \n#> ----------\n#> ' 95% conf. level\n\n\nlm_1 <- lm(HIVO01 ~ NEME2, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = HIVO01 ~ NEME2, data = d)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -0.6605 -0.5027  0.3394  0.3394  0.4973 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  0.50272    0.01789  28.101  < 2e-16 ***\n#> NEME2        0.15783    0.02367   6.669 3.47e-11 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.4853 on 1715 degrees of freedom\n#> Multiple R-squared:  0.02528,    Adjusted R-squared:  0.02471 \n#> F-statistic: 44.47 on 1 and 1715 DF,  p-value: 3.467e-11\n\nMindhárom fenti esetben a független változóink lehetnek kategorikusak és folytonosak is."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#az-mds-algoritmusok-típusai",
    "href": "sec_tobbdimenzios_skalazas.html#az-mds-algoritmusok-típusai",
    "title": "11  Többdimenziós skálázás",
    "section": "11.1 Az MDS algoritmusok típusai",
    "text": "11.1 Az MDS algoritmusok típusai\nKülönféle MDS-algoritmusok léteznek:\n\nKlasszikus többdimenziós skálázás. Ez a módszer a lehető legjobban őrzi az eredeti távolságmértéket a pontok között. Az MDS térképen lévő illesztett távolságok és az eredeti távolságok ugyanabban a mértékegységben vannak kifejezve. A klasszikus MDS az úgynevezett metrikus többdimenziós skálázás kategóriába tartozik. Szokták főtengely-elemzésnek is nevezni, és jellemzően kvantitatív adatokra alkalmazzuk.\nNem metrikus többdimenziós skálázás. Ordinális MDS néven is ismert. Itt nem a távolságérték mérőszáma a fontos vagy értelmes, hanem az, hogy a többi objektumpár közötti távolságokhoz képes ez kisebb vagy nagyobb. Az ordinális MDS olyan illesztett távolságokat konstruál, amelyek az eredeti távolságokkal azonos rangsorrendben helyednek el. Például, ha az 1. és 5. objektumok távolsága az ötödik helyen áll az eredeti távolságadatokban, akkor az MDS-konfigurációban is az ötödik helyen kell szerepelniük. Ezt az algoritmust általában kategorikus adatokra alkalmazzuk."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#példa-svájci-tartományok",
    "href": "sec_tobbdimenzios_skalazas.html#példa-svájci-tartományok",
    "title": "11  Többdimenziós skálázás",
    "section": "11.2 Példa: Svájci tartományok",
    "text": "11.2 Példa: Svájci tartományok\nA swiss adatbázis Svájc 47 francia nyelvű tartományának termékenységi és társadalmi-gazdasági adatait tartalmazza. Az adatbázis a {datasets} csomagból származik, további információ: ?swiss. A példa ötlete innen származik.\n\nd <- rio::import(file = \"adat/mds_swiss.xlsx\")\nstr(d)\n#> 'data.frame':    47 obs. of  7 variables:\n#>  $ Fertility       : num  80.2 83.1 92.5 85.8 76.9 76.1 83.8 ...\n#>  $ Agriculture     : num  17 45.1 39.7 36.5 43.5 35.3 70.2 67...\n#>  $ Examination     : num  15 6 5 12 17 9 16 14 12 16 ...\n#>  $ Education       : num  12 9 5 7 15 7 7 8 7 13 ...\n#>  $ Catholic        : num  9.96 84.84 93.4 33.77 5.16 ...\n#>  $ Infant.Mortality: num  22.2 22.2 20.2 20.3 20.6 26.6 23.6 ...\n#>  $ province        : chr  \"Courtelary\" \"Delemont\" \"Franches-M...\npsych::headTail(d)\n#>     Fertility Agriculture Examination Education Catholic\n#> 1        80.2          17          15        12     9.96\n#> 2        83.1        45.1           6         9    84.84\n#> 3        92.5        39.7           5         5     93.4\n#> 4        85.8        36.5          12         7    33.77\n#> ...       ...         ...         ...       ...      ...\n#> 44       67.6        18.7          25         7     8.65\n#> 45         35         1.2          37        53    42.34\n#> 46       44.7        46.6          16        29    50.43\n#> 47       42.8        27.7          22        29    58.33\n#>     Infant.Mortality     province\n#> 1               22.2   Courtelary\n#> 2               22.2     Delemont\n#> 3               20.2 Franches-Mnt\n#> 4               20.3      Moutier\n#> ...              ...         <NA>\n#> 44              19.5 ValdeTravers\n#> 45                18 V. De Geneve\n#> 46              18.2  Rive Droite\n#> 47              19.3  Rive Gauche\n\nAz R-ben több függvény is rendelkezésre áll:\n\ncmdscale() - Klasszikus (metrikus) többdimenziós skálázás kiszámítása.\nMASS::isoMDS() - A Kruskal nem metrikus többdimenziós skálázásának kiszámítása (a nem metrikus MDS egyik formája).\nMASS::sammon() - Sammon nemlineáris leképezésének kiszámítása (a nem metrikus MDS egyik formája).\n\nA fenti függvények egy távolságobjektumot várnak argumentumként, és k= a kívánt dimenziószámot jelenti. Alapértelmezés szerint kétdimenziós megoldással térnek vissza, de ezt meg tudjuk változtatni.\n\ndist_1 <- dist(x = d, method = \"euclidean\")\nmds_1 <- cmdscale(dist_1, k = 2)\nmds_1 <- as.data.frame(mds_1)\nnames(mds_1) <- c(\"Dim.1\", \"Dim.2\")\n# Plot MDS\nggpubr::ggscatter(mds_1, x = \"Dim.1\", y = \"Dim.2\", label = d$province,\n    size = 1, repel = TRUE)\n\n\n\n\nHozzunk létre 3 csoportot a k-közép eljárással.\n\nlibrary(magrittr)\n# K-közep klaszter\nmds_1$groups <- kmeans(mds_1, 3)$cluster %>%\n    as.factor()\n# Plot and color by groups\nggpubr::ggscatter(mds_1, x = \"Dim.1\", y = \"Dim.2\", label = rownames(swiss),\n    color = \"groups\", palette = \"jco\", size = 1, ellipse = TRUE, ellipse.type = \"convex\",\n    repel = TRUE)\n\n\n\n\nJamovi-ban a fenti lépések végrehajtásáshoz a snowCluster csomagot kell telepíteni, majd a megjelenő snowCluster menüből a Multidimensional Scaling Plot almenüpontot kell kiválasztani.\n\n\n\nTöbbdimenziós skálázás jamovi-ban"
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#korrelációs-mátrix-megjelenítése-többdimenziós-skálázással",
    "href": "sec_tobbdimenzios_skalazas.html#korrelációs-mátrix-megjelenítése-többdimenziós-skálázással",
    "title": "11  Többdimenziós skálázás",
    "section": "11.3 Korrelációs mátrix megjelenítése többdimenziós skálázással",
    "text": "11.3 Korrelációs mátrix megjelenítése többdimenziós skálázással\nAz MDS a korrelációs mátrix vizsgálatára is alkalmas, rejtett mintázat felfedésére is használhatjuk.\nA korreláció valójában a hasonlóságot méri, de könnyen átalakítható az eltérés (távolság) jellegű mértékké. Az objektumok közötti távolság: 1 - res.cor. A példában a faktor_real_human_targyak.xlsx adatbázist használjuk (Münnich és mtsai., 2006) [3.7.1 Probléma].\n\nd <- rio::import(file = \"adat/faktor_real_human_targyak.xlsx\")\nstr(d)\n#> 'data.frame':    30 obs. of  6 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5 5 ...\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5 4 ...\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5 5 ...\n#>  $ irodalom   : num  5 4 2 5 3 5 3 5 4 2 ...\n#>  $ nyelvtan   : num  4 4 2 5 3 5 3 5 5 2 ...\n#>  $ angol      : num  5 5 3 5 3 5 3 5 5 2 ...\npsych::headTail(d)\n#>     matek informatika kemia irodalom nyelvtan angol\n#> 1       5           4     5        5        4     5\n#> 2       4           4     5        4        4     5\n#> 3       3           4     3        2        2     3\n#> 4       2           2     3        5        5     5\n#> ...   ...         ...   ...      ...      ...   ...\n#> 27      5           5     5        2        2     3\n#> 28      5           5     5        4        4     4\n#> 29      2           2     3        4        5     5\n#> 30      5           5     5        4        5     5\n\n\nres.cor <- cor(d, method = \"spearman\")\nmds.cor <- (1 - res.cor) %>%\n    cmdscale() %>%\n    as.data.frame()\ncolnames(mds.cor) <- c(\"Dim.1\", \"Dim.2\")\nggpubr::ggscatter(mds.cor, x = \"Dim.1\", y = \"Dim.2\", size = 1, label = colnames(res.cor),\n    repel = TRUE)\n\n\n\n\nA pozitívan korreláló objektumok közel vannak egymáshoz, ugyanazon oldalon (bal vagy jobb)."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#az-mds-és-a-pca-összehasonlítása",
    "href": "sec_tobbdimenzios_skalazas.html#az-mds-és-a-pca-összehasonlítása",
    "title": "11  Többdimenziós skálázás",
    "section": "11.4 Az MDS és a PCA összehasonlítása",
    "text": "11.4 Az MDS és a PCA összehasonlítása\nAz MDS és a dimenzió-redukciós módszerek (például a főkomponens elemzés és a faktoranalízis) között matematikailag és fogalmilag szoros összefüggés van .\nA PCA inkább magukra a dimenziókra összpontosít, és a megmagyarázott variancia maximalizálására törekszik, míg az MDS inkább a skálázott objektumok közötti kapcsolatokra összpontosít.\nAz MDS n-dimenziós adatpontokat vetít ki egy (általában) 2-dimenziós síkba úgy, hogy az n-dimenziós térben lévő hasonló objektumok közel lesznek egymáshoz a kétdimenziós diagramon is, míg a PCA többdimenziós teret vetít a maximális variancia irányába a korrelációs/kovariancia mátrix elemzésével."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#példa-magyar-városok",
    "href": "sec_tobbdimenzios_skalazas.html#példa-magyar-városok",
    "title": "11  Többdimenziós skálázás",
    "section": "11.5 Példa: Magyar városok",
    "text": "11.5 Példa: Magyar városok\nA példa a magyar városokat elhelyezkedését vizsgálja a térképen (Münnich és mtsai., 2006) [6.1. R-forráskód]. Az adatok már eleve távolságmátrixban vannak reprezentálva (mds_varos_tavolsagmatrix.xlsx), ahol az egyes cellák a városok közti légvonalbeli távolságot listázzák. Mivel a többdimenziós skálázást eredetileg a térképészetben használták térképek rajzolására, ebben a példában Magyarország nagyobb városait jelenítjük meg egy kétdimenziós térképen.\n\nd <- rio::import(file = \"adat/mds_varos_tavolsagmatrix.xlsx\")\nstr(d)\n#> 'data.frame':    10 obs. of  11 variables:\n#>  $ VAROSNEV: chr  \"Budapest\" \"Gyor\" \"Tatab\" \"Szhely\" ...\n#>  $ BUDAPEST: num  0 114 52 185 190 160 157 190 204 135\n#>  $ GYŐR    : num  NA 0 60 95 113 148 248 304 305 233\n#>  $ TATAB   : num  NA NA 0 144 144 140 193 243 251 182\n#>  $ SZHELY  : num  NA NA NA 0 45 126 289 381 392 330\n#>  $ ZALAE   : num  NA NA NA NA 0 90 262 375 391 330\n#>  $ KAPOSVAR: num  NA NA NA NA NA 0 183 322 345 297\n#>  $ SZEGED  : num  NA NA NA NA NA NA 0 179 220 208\n#>  $ DEBRECEN: num  NA NA NA NA NA NA NA 0 44 91\n#>  $ NYHAZA  : num  NA NA NA NA NA NA NA NA 0 72\n#>  $ MISKOLC : num  NA NA NA NA NA NA NA NA NA 0\npsych::headTail(d)\n#>     VAROSNEV BUDAPEST GYŐR TATAB SZHELY ZALAE KAPOSVAR SZEGED\n#> 1   Budapest        0 <NA>  <NA>   <NA>  <NA>     <NA>   <NA>\n#> 2       Gyor      114    0  <NA>   <NA>  <NA>     <NA>   <NA>\n#> 3      Tatab       52   60     0   <NA>  <NA>     <NA>   <NA>\n#> 4     Szhely      185   95   144      0  <NA>     <NA>   <NA>\n#> ...     <NA>      ...  ...   ...    ...   ...      ...    ...\n#> 7     Szeged      157  248   193    289   262      183      0\n#> 8   Debrecen      190  304   243    381   375      322    179\n#> 9     Nyhaza      204  305   251    392   391      345    220\n#> 10   Miskolc      135  233   182    330   330      297    208\n#>     DEBRECEN NYHAZA MISKOLC\n#> 1       <NA>   <NA>    <NA>\n#> 2       <NA>   <NA>    <NA>\n#> 3       <NA>   <NA>    <NA>\n#> 4       <NA>   <NA>    <NA>\n#> ...      ...    ...     ...\n#> 7       <NA>   <NA>    <NA>\n#> 8          0   <NA>    <NA>\n#> 9         44      0    <NA>\n#> 10        91     72       0\n\n\ndist <- as.dist(d[2:11])\ndist\n#>      1   2   3   4   5   6   7   8   9\n#> 2  114                                \n#> 3   52  60                            \n#> 4  185  95 144                        \n#> 5  190 113 144  45                    \n#> 6  160 148 140 126  90                \n#> 7  157 248 193 289 262 183            \n#> 8  190 304 243 381 375 322 179        \n#> 9  204 305 251 392 391 345 220  44    \n#> 10 135 233 182 330 330 297 208  91  72\n\nAz elkészült távolságmátrix ismeretében már lefuttathatjuk a nem metrikus többdimenziós skálázást az R statisztikai program segítségével.\n\nmds_1 <- MASS::isoMDS(dist, k = 2)\n#> initial  value 0.364001 \n#> iter   5 value 0.114745\n#> iter  10 value 0.037146\n#> final  value 0.005866 \n#> converged\nmds_1$points\n#>           [,1]      [,2]\n#> 1     9.578911 -19.29945\n#> 2   -95.520939 -68.48619\n#> 3   -39.393870 -37.74982\n#> 4  -180.860153 -32.75667\n#> 5  -178.931803  11.19081\n#> 6  -121.302621  77.85193\n#> 7    55.462602 130.86356\n#> 8   196.837303  18.00145\n#> 9   210.243678 -22.43017\n#> 10  143.886892 -57.18545\n\nA fenti output mutatja a kapott kétdimenziós megoldást. Az egyes oszlopok az elemek első illetve második dimenzióbeli értékeit mutatja. Mivel a többdimenziós skálázásban fontos cél az adatok grafikus ábrázolása is, ezeket az értékeket kezelhetjük koordinátákként, melyek segítségével rajzolhatunk egy kétdimenziós térképet.\n\nmds_data <- as.data.frame(mds_1$points)\npsych::headTail(mds_data)\n#>          V1     V2\n#> 1      9.58  -19.3\n#> 2    -95.52 -68.49\n#> 3    -39.39 -37.75\n#> 4   -180.86 -32.76\n#> ...     ...    ...\n#> 7     55.46 130.86\n#> 8    196.84     18\n#> 9    210.24 -22.43\n#> 10   143.89 -57.19\n\n\nlibrary(ggplot2)\nlibrary(ggrepel)\nggplot(mds_data, aes(x = V1, y = V2)) + geom_point() + geom_label_repel(label = d$VAROSNEV)\n\n\n\n\nA fenti outputban a magát a térképet kaphatjuk meg. Az egyetlen furcsaság a kapott térképen az, hogy az észak-dél irány fordítva van. Ennek oka, hogy a módszer az egyes objektumok egymáshoz való viszonyát modellezi, ám a koordináta-tengelyek iránya és helye változhat. Természetesen megkaphatjuk a “valódi” Magyarország térképet is.\nEnnek megoldásához csupán meg kell szoroznunk a második dimenziót (-1)-gyel.\n\nmds_data$V2 <- -1 * mds_data$V2\nggplot(mds_data, aes(x = V1, y = V2)) + geom_point() + geom_label_repel(label = d$VAROSNEV)\n\n\n\n\nA kapott geometriai reprezentáció igen jól interpretálható. Ám emellett szükség van objektív mérőszámokra is, melyek információt adnak a kapott távolságok illeszkedésére vonatkozóan. A következőkben ilyen mérőszámokat mutatunk be.\n\nA Stress-érték. Az első illeszkedés jóságát mutató mérőszám a Stress-érték. Az információveszteség mértékét méri. Minél kisebb, annál jobb. Az értéke 0,05 alatt igazán jó.\n\n\nmds_1$stress\n#> [1] 0.005865683\n\n\nShepard-diagram. Grafikus információt adhat a kétdimenziós (vagy bármilyen más) megoldás jóságáról. Ehhez első lépésként elkészítjük a kétdimenziós megoldás távolságmátrixát (delta objektum). Ezután ábrázolhatjuk az eredeti távolságok és a kétdimenziós távolságok kapcsolatát egy pontdiagram segítségével. Minél jobb a kétdimenziós megoldás, annál inkább egy egyenesre illeszkednek az adatok.\n\n\ndelta <- dist(mds_1$points)\nplot(delta, dist)"
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#példa-üdítő-italok",
    "href": "sec_tobbdimenzios_skalazas.html#példa-üdítő-italok",
    "title": "11  Többdimenziós skálázás",
    "section": "11.6 Példa: Üdítő italok",
    "text": "11.6 Példa: Üdítő italok\nEbben a példában különböző üdítőitalokat vizsgálunk meg a többdimenziós skálázás segítségével (Münnich és mtsai., 2006) [6.5.1 probléma]. Az adatbázis a különböző üdítőitalok távolságmátrixát tartalmazza (mds_uditok_tavolsagmatrix.xlsx). Az embereknek azt kellett megítélni, hogy az egyes üdítők mennyire különböznek egymástól. A 0 érték azt jelenti, hogy teljesen egyformák az italok, míg az 1 a lehető legnagyobb mértékű különbözőséget jelzi.\n\nd <- rio::import(file = \"adat/mds_uditok_tavolsagmatrix.xlsx\")\nstr(d)\n#> 'data.frame':    7 obs. of  8 variables:\n#>  $ NEVEK       : chr  \"szorp\" \"hohesC\" \"savm_asv_viz\" \"szobi\"...\n#>  $ szorp       : num  0 0.48 0.66 0.19 0.72 0.94 0.89\n#>  $ hohesC      : num  0.48 0 0.45 0.3 0.32 0.4 0.56\n#>  $ savm_asv_viz: num  0.66 0.45 0 0.44 0.38 0.56 0.38\n#>  $ szobi       : num  0.19 0.3 0.44 0 0.48 0.68 0.67\n#>  $ traubi      : num  0.72 0.32 0.38 0.48 0 0.2 0.3\n#>  $ fantanarancs: num  0.94 0.4 0.56 0.68 0.2 0 0.45\n#>  $ asv_viz     : num  0.89 0.56 0.38 0.67 0.3 0.45 0\npsych::headTail(d)\n#>            NEVEK szorp hohesC savm_asv_viz szobi traubi\n#> 1          szorp     0   0.48         0.66  0.19   0.72\n#> 2         hohesC  0.48      0         0.45   0.3   0.32\n#> 3   savm_asv_viz  0.66   0.45            0  0.44   0.38\n#> 4          szobi  0.19    0.3         0.44     0   0.48\n#> ...         <NA>   ...    ...          ...   ...    ...\n#> 41         szobi  0.19    0.3         0.44     0   0.48\n#> 5         traubi  0.72   0.32         0.38  0.48      0\n#> 6   fantanarancs  0.94    0.4         0.56  0.68    0.2\n#> 7        asv_viz  0.89   0.56         0.38  0.67    0.3\n#>     fantanarancs asv_viz\n#> 1           0.94    0.89\n#> 2            0.4    0.56\n#> 3           0.56    0.38\n#> 4           0.68    0.67\n#> ...          ...     ...\n#> 41          0.68    0.67\n#> 5            0.2     0.3\n#> 6              0    0.45\n#> 7           0.45       0\n\n\ndist <- as.dist(d[2:8])\ndist\n#>      1    2    3    4    5    6\n#> 2 0.48                         \n#> 3 0.66 0.45                    \n#> 4 0.19 0.30 0.44               \n#> 5 0.72 0.32 0.38 0.48          \n#> 6 0.94 0.40 0.56 0.68 0.20     \n#> 7 0.89 0.56 0.38 0.67 0.30 0.45\n\n\nmds_1 <- MASS::isoMDS(dist, k = 2)\n#> initial  value 1.573115 \n#> iter   5 value 0.164954\n#> iter  10 value 0.022263\n#> final  value 0.002023 \n#> converged\nmds_1$points\n#>          [,1]        [,2]\n#> 1 -0.53868137  0.03041114\n#> 2 -0.06571066  0.18616088\n#> 3  0.02345226 -0.25210840\n#> 4 -0.31947272  0.03166493\n#> 5  0.17978098  0.01382719\n#> 6  0.37258175  0.22327908\n#> 7  0.34804977 -0.23323482\n\nA fenti output mutatja a kapott kétdimenziós megoldást. Az egyes oszlopok az elemek első illetve második dimenzióbeli értékeit mutatja. Mivel a többdimenziós skálázásban fontos cél az adatok grafikus ábrázolása is, ezeket az értékeket kezelhetjük koordinátákként, melyek segítségével rajzolhatunk egy kétdimenziós térképet.\n\nmds_data <- as.data.frame(mds_1$points)\npsych::headTail(mds_data)\n#>        V1    V2\n#> 1   -0.54  0.03\n#> 2   -0.07  0.19\n#> 3    0.02 -0.25\n#> 4   -0.32  0.03\n#> ...   ...   ...\n#> 41  -0.32  0.03\n#> 5    0.18  0.01\n#> 6    0.37  0.22\n#> 7    0.35 -0.23\n\n\nlibrary(ggplot2)\nlibrary(ggrepel)\nggplot(mds_data, aes(x = V1, y = V2)) + geom_point() + geom_label_repel(label = d$NEVEK)\n\n\n\n\n\nmds_1$stress\n#> [1] 0.002022712\n\nA Magyarország városait bemutató példában egyértelmű volt az egyes koordinátatengelyek, dimenziók elnevezése. Ám egy ilyen példánál már nagyobb gondot okozhat. A fenti eredmények alapján láthatjuk, hogy az első dimenzióban az ásványvíz és a Fanta Narancs szerepel magas értékekkel, viszonylag kis értéke van a Szobi gyümölcslének és a szörpnek. A második dimenzióiban is magas értékkel szerepel a Fanta és a Hohes C, viszont extrém alacsonnyal az ásványvíz. Ezek alapján az első dimenzió képviselheti a szénsavtartalmat, míg a második a gyümölcstartalmat. A feladatban szereplő emberek fejében ez a két szempont tűnt fontosnak az üdítőitalok különbözőségének megítélése során."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#példa-autómárkák",
    "href": "sec_tobbdimenzios_skalazas.html#példa-autómárkák",
    "title": "11  Többdimenziós skálázás",
    "section": "11.7 Példa: Autómárkák",
    "text": "11.7 Példa: Autómárkák\nEbben a példában autómárkák közötti hasonlóságokat ítéltetünk meg a személyekkel (Münnich és mtsai., 2006) [6.5.2 probléma]. Az 1 érték jelenti a márkák teljes hasonlóságát, míg a 0 a hasonlóság hiányát.\n\nd <- rio::import(file = \"adat/mds_autok_tavolsagmatrix.xlsx\")\nstr(d)\n#> 'data.frame':    8 obs. of  9 variables:\n#>  $ AUTOK   : chr  \"toyota celica\" \"audi a3\" \"seat ibiza\" \"sko...\n#>  $ TOYOTACE: num  1 0.4 0.25 0.12 0.67 0.39 0.26 0.19\n#>  $ AUDIA3  : num  0.4 1 0.31 0.39 0.5 0.24 0.18 0.52\n#>  $ SEATIBIZ: num  0.25 0.31 1 0.46 0.28 0.38 0.42 0.49\n#>  $ SKODAOCT: num  0.12 0.39 0.46 1 0.2 0.14 0.29 0.55\n#>  $ MAZDAMX6: num  0.67 0.5 0.28 0.2 1 0.38 0.26 0.26\n#>  $ NISSANM : num  0.39 0.24 0.38 0.14 0.38 1 0.4 0.22\n#>  $ SEATLEON: num  0.26 0.18 0.42 0.29 0.26 0.4 1 0.25\n#>  $ FORDMOND: num  0.19 0.52 0.49 0.55 0.26 0.22 0.25 1\nd\n#>           AUTOK TOYOTACE AUDIA3 SEATIBIZ SKODAOCT MAZDAMX6 NI...\n#> 1 toyota celica     1.00   0.40     0.25     0.12     0.67   ...\n#> 2       audi a3     0.40   1.00     0.31     0.39     0.50   ...\n#> 3    seat ibiza     0.25   0.31     1.00     0.46     0.28   ...\n#> 4 skoda octavia     0.12   0.39     0.46     1.00     0.20   ...\n#> 5     mazda mx6     0.67   0.50     0.28     0.20     1.00   ...\n#> 6  nissan micra     0.39   0.24     0.38     0.14     0.38   ...\n#> 7     seat leon     0.26   0.18     0.42     0.29     0.26   ...\n#> 8   ford mondeo     0.19   0.52     0.49     0.55     0.26   ...\n#>   SEATLEON FORDMOND\n#> 1     0.26     0.19\n#> 2     0.18     0.52\n#> 3     0.42     0.49\n#> 4     0.29     0.55\n#> 5     0.26     0.26\n#> 6     0.40     0.22\n#> 7     1.00     0.25\n#> 8     0.25     1.00\n\nA fenti outputban egy hasonlósági mátrixot láthatunk. A többdimenziós skálázás előtt a hasonlósági mátrixot távolságmátrixszá kell transzformálni. Ezt egyszerűbben és pontosabban is megtehetjük:\nAz egyszerűbb eset az, hogy minden hasonlósági értéket kivonunk 1-ből, így a kis értékek közeli hasonlóságot jelentenek (kis távolság), a nagy értékek távoli hasonlóságot jelentenek (bagy távolság).\n\nd_1 <- 1 - d[2:9]\nd_1\n#>   TOYOTACE AUDIA3 SEATIBIZ SKODAOCT MAZDAMX6 NISSANM SEATLEON\n#> 1     0.00   0.60     0.75     0.88     0.33    0.61     0.74\n#> 2     0.60   0.00     0.69     0.61     0.50    0.76     0.82\n#> 3     0.75   0.69     0.00     0.54     0.72    0.62     0.58\n#> 4     0.88   0.61     0.54     0.00     0.80    0.86     0.71\n#> 5     0.33   0.50     0.72     0.80     0.00    0.62     0.74\n#> 6     0.61   0.76     0.62     0.86     0.62    0.00     0.60\n#> 7     0.74   0.82     0.58     0.71     0.74    0.60     0.00\n#> 8     0.81   0.48     0.51     0.45     0.74    0.78     0.75\n#>   FORDMOND\n#> 1     0.81\n#> 2     0.48\n#> 3     0.51\n#> 4     0.45\n#> 5     0.74\n#> 6     0.78\n#> 7     0.75\n#> 8     0.00\n\n\ndist_1 <- as.dist(d_1)\ndist_1\n#>      1    2    3    4    5    6    7\n#> 2 0.60                              \n#> 3 0.75 0.69                         \n#> 4 0.88 0.61 0.54                    \n#> 5 0.33 0.50 0.72 0.80               \n#> 6 0.61 0.76 0.62 0.86 0.62          \n#> 7 0.74 0.82 0.58 0.71 0.74 0.60     \n#> 8 0.81 0.48 0.51 0.45 0.74 0.78 0.75\n\n\nmds_1 <- MASS::isoMDS(dist_1, k = 2)\n#> initial  value 5.826508 \n#> iter   5 value 2.950170\n#> final  value 2.891815 \n#> converged\nmds_1$points\n#>           [,1]        [,2]\n#> 1 -0.361055519 -0.17243204\n#> 2  0.006764815 -0.30716195\n#> 3  0.216130743  0.18832931\n#> 4  0.412741547 -0.08945592\n#> 5 -0.324654056 -0.19618092\n#> 6 -0.288487909  0.28343789\n#> 7 -0.007968750  0.43461843\n#> 8  0.346529128 -0.14115478\nmds_1$stress\n#> [1] 2.891815\n\nA távolságmátrix birtokában lefuttattuk a többdimenziós skálázást. Ez alkalommal háromdimenziós megoldást érdemes kérni, mivel a kétdimenziós megoldás Stress-értéke túl nagy.\n\nmds_1 <- MASS::isoMDS(dist_1, k = 3)\n#> initial  value 2.196611 \n#> iter   5 value 0.256820\n#> iter  10 value 0.151733\n#> iter  15 value 0.107927\n#> iter  20 value 0.019342\n#> final  value 0.000000 \n#> converged\nmds_1$points\n#>          [,1]        [,2]        [,3]\n#> 1 -0.46448409 -0.15747133 -0.07985979\n#> 2  0.03707153 -0.40270153 -0.00671623\n#> 3  0.24092363  0.24184414  0.09663242\n#> 4  0.49812765 -0.05451923 -0.12227626\n#> 5 -0.36659549 -0.21506553 -0.04539081\n#> 6 -0.32944563  0.30522587  0.23017071\n#> 7 -0.00870002  0.45983004 -0.21064227\n#> 8  0.39310242 -0.17714243  0.13808223\nmds_1$stress\n#> [1] 4.343565e-14\n\n\nlibrary(plotly)\n# 3D ábrázolás\nd_3d <- as.data.frame(mds_1$points)\nd_3d$AUTOK <- d$AUTOK\nplot_ly(d_3d, x = ~V1, y = ~V2, z = ~V3) %>%\n    add_text(text = ~AUTOK) %>%\n    add_markers(color = ~AUTOK)\n\nA hasonlósági mátrix távolságmátrixszá alakításának pontosabb módja a (Münnich és mtsai., 2006) 6.4 fejezetében olvasható.\n\nd_2 <- sqrt(2 * (1 - d[2:9]))\n\n\ndist_2 <- as.dist(d_2)\ndist_2\n#>           1         2         3         4         5         6\n#> 2 1.0954451                                                  \n#> 3 1.2247449 1.1747340                                        \n#> 4 1.3266499 1.1045361 1.0392305                              \n#> 5 0.8124038 1.0000000 1.2000000 1.2649111                    \n#> 6 1.1045361 1.2328828 1.1135529 1.3114877 1.1135529          \n#> 7 1.2165525 1.2806248 1.0770330 1.1916375 1.2165525 1.0954451\n#> 8 1.2727922 0.9797959 1.0099505 0.9486833 1.2165525 1.2489996\n#>           7\n#> 2          \n#> 3          \n#> 4          \n#> 5          \n#> 6          \n#> 7          \n#> 8 1.2247449\n\n\nmds_2 <- MASS::isoMDS(dist_2, k = 2)\n#> initial  value 6.389472 \n#> iter   5 value 5.192764\n#> iter  10 value 3.416955\n#> iter  15 value 2.949710\n#> final  value 2.891118 \n#> converged\nmds_2$points\n#>         [,1]       [,2]\n#> 1  1.4484081  0.8945686\n#> 2 -0.1610748  1.3129618\n#> 3 -0.8393349 -0.9062232\n#> 4 -1.7845996  0.2177189\n#> 5  1.3049511  0.9653162\n#> 6  1.3352331 -1.0778650\n#> 7  0.2295031 -1.8533287\n#> 8 -1.5330862  0.4468514\nmds_2$stress\n#> [1] 2.891118\n\nA távolságmátrix birtokában lefuttattuk a többdimenziós skálázást. Ez alkalommal háromdimenziós megoldást érdemes kérni, mivel a kétdimenziós megoldás Stress-értéke túl nagy.\n\nmds_2 <- MASS::isoMDS(dist_2, k = 3)\n#> initial  value 5.751803 \n#> iter   5 value 2.166360\n#> iter  10 value 1.472838\n#> iter  15 value 0.710732\n#> iter  20 value 0.271743\n#> final  value 0.008855 \n#> converged\nmds_2$points\n#>          [,1]        [,2]       [,3]\n#> 1  1.13442661  0.31620329  0.2158284\n#> 2 -0.10372721  0.94488131  0.2158065\n#> 3 -0.56639006 -0.51061522 -0.3193788\n#> 4 -1.22334085  0.08201655  0.2935412\n#> 5  0.86269111  0.49684620  0.2687634\n#> 6  0.78134789 -0.62616329 -0.7513363\n#> 7  0.06291958 -1.18359998  0.3083139\n#> 8 -0.94792707  0.48043115 -0.2315383\nmds_2$stress\n#> [1] 0.008855227\n\n\nlibrary(plotly)\n# 3D ábrázolás\nd_3d <- as.data.frame(mds_2$points)\nd_3d$AUTOK <- d$AUTOK\nplot_ly(d_3d, x = ~V1, y = ~V2, z = ~V3) %>%\n    add_text(text = ~AUTOK) %>%\n    add_markers(color = ~AUTOK)\n\n\ndist <- as.dist(d[2:9])\ndist\n#>      1    2    3    4    5    6    7\n#> 2 0.40                              \n#> 3 0.25 0.31                         \n#> 4 0.12 0.39 0.46                    \n#> 5 0.67 0.50 0.28 0.20               \n#> 6 0.39 0.24 0.38 0.14 0.38          \n#> 7 0.26 0.18 0.42 0.29 0.26 0.40     \n#> 8 0.19 0.52 0.49 0.55 0.26 0.22 0.25\n\n\nmds_1 <- MASS::isoMDS(dist, k = 2)\n#> initial  value 33.207938 \n#> iter   5 value 20.383903\n#> iter   5 value 20.375967\n#> iter   5 value 20.375494\n#> final  value 20.375494 \n#> converged\nmds_1$points\n#>          [,1]        [,2]\n#> 1  0.21725475 -0.07057062\n#> 2  0.23169840  0.16729709\n#> 3  0.02516126  0.14398696\n#> 4 -0.07964438  0.22492857\n#> 5 -0.27770841 -0.02595944\n#> 6 -0.07736511 -0.03519537\n#> 7  0.04465412 -0.09341317\n#> 8 -0.08405063 -0.31107402\nmds_1$stress\n#> [1] 20.37549\n\nA távolságmátrix birtokában lefuttattuk a többdimenziós skálázást. Ez alkalommal háromdimenziós megoldást érdemes kérni, mivel a kétdimenziós megoldás Stress-értéke túl nagy.\n\nmds_1 <- MASS::isoMDS(dist, k = 3)\n#> initial  value 20.475699 \n#> iter   5 value 13.683747\n#> iter  10 value 12.173787\n#> iter  15 value 11.582671\n#> iter  20 value 10.623521\n#> iter  25 value 10.205554\n#> final  value 10.087435 \n#> converged\nmds_1$points\n#>          [,1]        [,2]       [,3]\n#> 1  0.13460836  0.12178456 -0.2459601\n#> 2  0.26513691  0.11656555  0.1311542\n#> 3 -0.11581558  0.20541786  0.2225079\n#> 4 -0.07304790  0.17140624 -0.1649379\n#> 5 -0.24115264 -0.20298696  0.1827992\n#> 6 -0.19159160  0.01802297 -0.1309034\n#> 7  0.18865375 -0.07207344  0.1366108\n#> 8  0.03320869 -0.35813678 -0.1312707\nmds_1$stress\n#> [1] 10.08743\n\n\nmds_data <- as.data.frame(mds_1$points)\nmds_data\n#>            V1          V2         V3\n#> 1  0.13460836  0.12178456 -0.2459601\n#> 2  0.26513691  0.11656555  0.1311542\n#> 3 -0.11581558  0.20541786  0.2225079\n#> 4 -0.07304790  0.17140624 -0.1649379\n#> 5 -0.24115264 -0.20298696  0.1827992\n#> 6 -0.19159160  0.01802297 -0.1309034\n#> 7  0.18865375 -0.07207344  0.1366108\n#> 8  0.03320869 -0.35813678 -0.1312707\n\nAz eredmények vizsgálata alapján elnevezhetjük az egyes dimenziókat. A kapott konfigurációban az első dimenziót, vagyis az x-tengelyt nevezhetjük az ár tengelyének. A második tengely, az y, a családbarát jellegre vonatozik, míg az utolsó, z dimenzió a sportosságot képviselheti.\nAz MDS és főkomponens analízis összehasonlításáról itt olvashatunk: MDS using R\nA hasonlósági-távolságmátrix átalakítás két módját egy ábrán is összehasonlíthatjuk.\n\nr_ertekek <- seq(from = 0, to = 1, by = 0.01)\nd_egyszeru <- 1 - r_ertekek\nd_pontos <- sqrt(2 * (1 - r_ertekek))\nd <- data.frame(x = c(r_ertekek, r_ertekek), y = c(d_egyszeru, d_pontos),\n    szamitas = rep(c(\"egyszerű\", \"pontos\"), each = length(r_ertekek)))\nstr(d)\n#> 'data.frame':    202 obs. of  3 variables:\n#>  $ x       : num  0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0...\n#>  $ y       : num  1 0.99 0.98 0.97 0.96 0.95 0.94 0.93 0.92 0...\n#>  $ szamitas: chr  \"egyszerű\" \"egyszerű\" \"egyszerű\" \"egyszerű\"...\npsych::headTail(d)\n#>        x    y szamitas\n#> 1      0    1 egyszerű\n#> 2   0.01 0.99 egyszerű\n#> 3   0.02 0.98 egyszerű\n#> 4   0.03 0.97 egyszerű\n#> ...  ...  ...     <NA>\n#> 199 0.97 0.24   pontos\n#> 200 0.98  0.2   pontos\n#> 201 0.99 0.14   pontos\n#> 202    1    0   pontos\n\n\nlibrary(ggplot2)\nggplot(d, aes(x = x, y = y, color = szamitas, group = szamitas)) + geom_line(linewidth = 1) +\n    labs(x = \"r (korreláció vagy hasonlóság)\", y = \"Távolság\", color = \"Számítás\")"
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html#példa-vállalatok",
    "href": "sec_tobbdimenzios_skalazas.html#példa-vállalatok",
    "title": "11  Többdimenziós skálázás",
    "section": "11.8 Példa: Vállalatok",
    "text": "11.8 Példa: Vállalatok\nA vállalatokat számtalan jellemző mentén mérhetjük, most a vállalat nagyságát, a hatalmi távolságot és a vállalat szemléletében jelen levő konzervativizmus mértékét választottuk.\n\nd <- rio::import(file = \"adat/mds_vallalatok.xlsx\")\nstr(d)\n#> 'data.frame':    10 obs. of  4 variables:\n#>  $ NEV     : chr  \"A vallalat\" \"B vallalat\" \"C vallalat\" \"D v...\n#>  $ MERET   : num  75 1500 2000 21 1000 900 1000 35 120 100\n#>  $ HATALMIT: num  1 10 11 3 10 11 10 4 2 5\n#>  $ KONZERVA: num  2 9 8 4 9 8 11 3 2 4\nd\n#>           NEV MERET HATALMIT KONZERVA\n#> 1  A vallalat    75        1        2\n#> 2  B vallalat  1500       10        9\n#> 3  C vallalat  2000       11        8\n#> 4  D vallalat    21        3        4\n#> 5  E vallalat  1000       10        9\n#> 6  F vallalat   900       11        8\n#> 7  G vallalat  1000       10       11\n#> 8  H vallalat    35        4        3\n#> 9  I vallalat   120        2        2\n#> 10 J vallalat   100        5        4\n\nEbben a példában nem távolságmátrixból indulunk ki.Ez tehát olyan példája a többdimenziós skálázásnak, amikor nyers adatokból indulunk ki. Állítsuk elő a távolságmátrixot.\n\ndist_1 <- dist(d[2:4])\ndist_1\n#>             1          2          3          4          5\n#> 2  1425.04561                                            \n#> 3  1925.03532  500.00200                                 \n#> 4    54.07402 1479.02502 1979.02021                      \n#> 5   925.07027  500.00000 1000.00100  979.03779           \n#> 6   825.08242  600.00167 1100.00000  879.04551  100.01000\n#> 7   925.08756  500.00400 1000.00500  979.05005    2.00000\n#> 8    40.12481 1465.02457 1965.01883   14.07125  965.03730\n#> 9    45.01111 1380.04094 1880.03112   99.02525  880.06420\n#> 10   25.39685 1400.01786 1900.01368   79.02531  900.02778\n#>             6          7          8          9\n#> 2                                             \n#> 3                                             \n#> 4                                             \n#> 5                                             \n#> 6                                             \n#> 7   100.04999                                 \n#> 8   865.04277  965.05181                      \n#> 9   780.07500  880.08238   85.02941           \n#> 10  800.03250  900.04111   65.01538   20.32240\n\n\nmds_1 <- MASS::isoMDS(d = dist_1, k = 2)\n#> initial  value 0.000000 \n#> final  value 0.000000 \n#> converged\nmds_1$points\n#>          [,1]        [,2]\n#> 1    600.1319 -3.12622014\n#> 2   -824.9116 -0.67138875\n#> 3  -1324.9030 -3.78267877\n#> 4    654.1132  0.03765570\n#> 5   -324.9215  2.43526416\n#> 6   -224.9247  3.05195762\n#> 7   -324.9291  3.85407994\n#> 8    640.1123 -0.05396771\n#> 9    555.1277 -2.70104813\n#> 10   575.1048  0.95634608\nmds_1$stress\n#> [1] 7.337118e-14\n\nA Stress-érték megfelelően kicsi, így elfogadhatjuk a kétdimenziós megoldást.\nA fenti output segítségével pedig pontosan megtudhatjuk, hogy az egyes vállalatok milyen értékekkel szerepelnek az egyes dimenziókban.\n\nmds_data <- as.data.frame(mds_1$points)\npsych::headTail(mds_data)\n#>          V1    V2\n#> 1    600.13 -3.13\n#> 2   -824.91 -0.67\n#> 3   -1324.9 -3.78\n#> 4    654.11  0.04\n#> ...     ...   ...\n#> 7   -324.93  3.85\n#> 8    640.11 -0.05\n#> 9    555.13  -2.7\n#> 10    575.1  0.96\n\n\nlibrary(ggplot2)\nlibrary(ggrepel)\nggplot(mds_data, aes(x = V1, y = V2)) + geom_point() + geom_label_repel(label = d$NEV)\n\n\n\n\nA kétdimenziós geometriai reprezentáció megmutatja, hogy az emberek véleménye szerint az egyes vállalatok hogyan helyezkednek el egymáshoz képest.\n\n\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika"
  },
  {
    "objectID": "appendix_linkek.html",
    "href": "appendix_linkek.html",
    "title": "Appendix A — Elérhető videók",
    "section": "",
    "text": "Alapozo jamovi és R videók\n\nJamovi a gyakorlatban\nR a gyakorlatban\n\nMagyar nyelvű ismertető statisztikai eljárásokról: Soltész-Várhelyi Klára\nJamovi tutorial videók az összes tanult eljáráshoz\n\ndatalab.cc\nAlexander Swan\n\nLineáris regresszió\n\nThe linear regression model\nLinear Regression, Clearly Explained\nR-squared, Clearly Explained\nSimple linear regression in Jamovi\n\nFőkomponens elemzés\n\nPrincipal Component Analysis (PCA)\n\nKlaszterelemzés\n\nFlat and Hierarchical Clustering | The Dendrogram Explained\nK Means Clustering: Pros and Cons of K Means Clustering\nHierarchical Cluster analysis in Jamovi\nK Means Cluster analysis in Jamovi\n\nTöbbszempontos varianciaelemzés\n\nOne Way ANOVA Post hoc test in Jamovi\nOne Way Repeated Measure ANOVA Repeated Measure ANOVA Within Subject ANOVA in Jamovi\nTwo Way ANOVA Post hoc test in Jamovi\nThree Way ANOVA Post hoc test in Jamovi"
  },
  {
    "objectID": "appendix_adatbazisok.html#megbízhatóság-elemzés",
    "href": "appendix_adatbazisok.html#megbízhatóság-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.1 Megbízhatóság elemzés",
    "text": "B.1 Megbízhatóság elemzés\n\nmegbizhatosag_tantargyak.xlsx - fiktív adatbázis 9 tanuló iskolai jegyeivel (Münnich és mtsai. (2006), 2.2. táblázat)\n\nAz adatbázis szerkezete:\n\nmatek - matematika érdemjegy (numerikus: 1-5)\nfizika - fizika érdemjegy (numerikus: 1-5)\ninformatika - informatika érdemjegy (numerikus: 1-5)\nkemia - kémia érdemjegy (numerikus: 1-5)\n\nKapcsolódó állományok:\n\nmegbizhatosag_tantargyak.omv - megbízhatóság elemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#többváltozós-varianciaelemzés",
    "href": "appendix_adatbazisok.html#többváltozós-varianciaelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.2 Többváltozós varianciaelemzés",
    "text": "B.2 Többváltozós varianciaelemzés\n\nmanova_vezetesi_program.xlsx - A szervezeti elkötelezettség, a szervezeti kultúra és az elégedettség eltér a vállalat 3 különböző vezetési irányelvét valló egységében? Az adatbázis Sajtos és Mitev (2007, o. 332) könyvéből származik.\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nAz adatbázis szerkezete:\n\nSUE - a három különböző vezetési irányelvet követő stratégiai üzleti egység (nominális: 1-3)\nszelkot - szervezet elkötelezettség mértéke (likert: 1-5)\nelegedett - szervezettel való elégedettség (likert: 1-5)\nrendszer - szervezet tekintélyelvű jellege (likert: 1-5)\n\nKapcsolódó állományok:\n\nmanova_vezetesi_program.omv - Többváltozós varianciaelemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#diszkriminancia-elemzés",
    "href": "appendix_adatbazisok.html#diszkriminancia-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.3 Diszkriminancia elemzés",
    "text": "B.3 Diszkriminancia elemzés\n\ndiszkriminancia_alkalmassag.xlsx - szalagmunkások adatai (Münnich és mtsai. (2006), 4.1. táblázat)\n\nAz adatbázis szerkezete:\n\nbevalt - a munkás beválásával kapcsolatos információ: bevált? (nominális: “igen”, “nem”)\nfigyelem - a munkás figyelmi képessége (likert: 1-7, a magasabb érték jobb képességeket jelent)\nmonotonia_tures - a munkás monotónia tűrése (likert: 1-7, a magasabb érték jobb képességeket jelent)\n\n\ndiszkriminancia_baleset.xlsx - mely tényezők járulnak hozzá a balesetekhez (Münnich és mtsai. (2006), 4.11. R-forráskód)\n\nAz adatbázis szerkezete:\n\nbaleset - volt már balesete a személynek vagy sem (nominális “nem volt balesete”, “volt baleste”)\nmegosztott - megosztott figyelem (intervallum/arány)\npontossag - a figyelem pontossága (intervallum/arány)\nkockazat - kockázatvállalási hajlandóság (intervallum/arány)\neszleles - észlelés gyorsasága (intervallum/arány)\n\n\ndiszkriminancia_depresszio.xlsx - a postpartum depresszió pszichés és szociális háttere (Münnich és mtsai. (2006), 4.16. R-forráskód)\n\nAz adatbázis szerkezete:\n\nppdepresszio - szülés utáni depresszió jelenléte (nominális: “nincs depresszió”, “van depresszió”)\nszeretet - a személyek mennyire érzik, hogy a szüleik szeretik őket (intervallum/arány)\ntulvedes - mennyire hajlamosak arra a személyek, hogy túlságosan is burokban tartsák, túlvédjék gyerekeiket (intervallum/arány)\nkor - életkor (intervallum/arány)\niskola - az elvégzett iskolai osztályok száma (intervallum/arány)\n\n\ndiszkriminancia_pszichoszomatika.xlsx - a pszichoszomatikus megbetegedéseket vizsgálata (Münnich és mtsai. (2006), 4.21. R-forráskód)\n\nAz adatbázis szerkezete:\n\npszichoszomatika - van valamilyen pszichoszomatikus megbetegedése a személynek? (nominális: “szichoszomatikus megbetegedése van”, ” egészséges”)\nstressz - a személyt ért stressz mértéke (intervallum/arány)\nszorongas - a szorongási szintje (intervallum/arány)\ncoping - a megküzdési stratégiáinak hatékonysága (intervallum/arány)\n\n\ndiszkriminancia_bio.xlsx - kik vásárolnak bio termékeket (Münnich és mtsai. (2006), 4.26. R-forráskód)\n\nAz adatbázis szerkezete:\n\nvasarlas - a biotermékek vásárlásának gyakorisága (ordinális: “soha nem vesz”, “időnként vesz”, “gyakran vesz”)\nertek - minél nagyobb pontszámot kap a skálán, annál jobban értékeli a személy a bio termékeket (intervallum/arány)\nattitud - a magasabb értékek kedvezőbb atttitűdöt jelez a biotermékek iránt (intervallum/arány)\nfizetes - a személy fizetésének nagysága (intervallum/arány)\nkor - a személy életkora(intervallum/arány)\n\n\ndiszkriminancia_vezetesi_program.xlsx - A szervezeti elkötelezettség, a szervezeti kultúra és az elégedettség alapján szétválasztható a vállalat 3 különböző vezetési irányelvét valló egysége? Az adatbázis Sajtos és Mitev (2007, o. 332) könyvéből származik.\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nAz adatbázis szerkezete:\n\nSUE - a három különböző vezetési irányelvet követő stratégiai üzleti egység (nominális: 1-3)\nszelkot - szervezet elkötelezettség mértéke (likert: 1-5)\nelegedett - szervezettel való elégedettség (likert: 1-5)\nrendszer - szervezet tekintélyelvű jellege (likert: 1-5)\n\nKapcsolódó állományok:\n\ndiszkriminancia_vezetesi_program.omv - diszkriminancia elemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#lineáris-regresszió",
    "href": "appendix_adatbazisok.html#lineáris-regresszió",
    "title": "Appendix B — Adatbázisok",
    "section": "B.4 Lineáris regresszió",
    "text": "B.4 Lineáris regresszió\n\nlin_reg_fizetes_elegedettseg_01.omv - konstans oszlopokkal nem tudunk számolni (Münnich és mtsai. (2006) 1.1/A táblázat)\nlin_reg_fizetes_elegedettseg_02.omv- az adatpontok szinte tökéletesen az egyenesre illeszkednek (Münnich és mtsai. (2006) 1.1/B táblázat)\nlin_reg_kapcsolatok_01.omv - nem szisztematikus kapcsolat két változó között (Münnich és mtsai. (2006) 1.5. R-forráskód)\nlin_reg_kapcsolatok_02.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.6. R-forráskód)\nlin_reg_kapcsolatok_03.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.7. R-forráskód)\nlin_reg_kapcsolatok_04.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.8. R-forráskód)\nlin_reg_kapcsolatok_05.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.9. R-forráskód)\nlin_reg_elegedttseg.omv - a fizetés és a munkahellyel való elégedettség pontdiagramja, egyszerű lineáris regresszió (Münnich és mtsai. (2006) 1.10 R-forráskód)\nlin_reg_fizetes_eletkor_eledettseg_01.omv - többszörös lineáris regresszió, 2 numerikus magyarázó változó (Münnich és mtsai. (2006) 1.2. táblázat)\nlin_reg_intelligencia_testmagassag_eletkor_01.omv - többszörös lineáris regresszió, 2 numerikus magyarázó változó, parciális korreláció magyarázata\n\nminél magasabb valaki, annál intelligensebb\nha bevonjuk az életkor változót, akkor eltűnik az intelligencia és a testmagasság közötti kapcsolat\n\nlin_tizproba.omv - többszörös lineáris regresszió, a legjobb modell keresése, sok numerikus magyarázó változó\nlin_college_success_02.omv - többszörös lineáris regresszió, sok numerikus magyarázó változó, GPA a függő változó, mi magyarázza az egyetemi teljesítményt\nlin_reg_elegedttseg_02.omv - A férfiak vagy a nők elégedettebbek a munkahelyükkel? (Münnich és mtsai. (2006) 1.6.3 probléma), egyetlen kategorikus magyarázó változó 2 értékkel (nem: férfi, nő)\n\nkapcsolat a kétmintás t-próbával\n\nlin_reg_magassag_hajhossz_nem_01.omv - többszörös lineáris regresszió, parciális korreláció 1 numerikus és 1 kategorikus változóval (Münnich és mtsai. (2006) 1.2. táblázat)\n\na testmagasság és a hajhossz között kapcsolat van\nha a személyek nemét is figyelembe vesszük, egyáltalán nincs kapcsolat a testmagasság és a hajhosszúság között\n\nlin_auction.omv - többszörös lineáris regresszió, Simpson paradoxon, párhuzamos regresszió, majd interakció bevonása."
  },
  {
    "objectID": "appendix_adatbazisok.html#főkomponens-elemzés",
    "href": "appendix_adatbazisok.html#főkomponens-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.5 Főkomponens elemzés",
    "text": "B.5 Főkomponens elemzés\n\nfokomp_elemzes_tantargyak.omv - 1 főkomponens létrehozása (Münnich és mtsai. (2006) 2.2. táblázat)\nfokomp_real_targyak.omv - példa kidolgozása, 1 főkomponens(Münnich és mtsai. (2006) 2.5.1 Probléma)\nfokomp_kerdoivtervezet.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.2 Probléma)\nfokomp_munkahelyi_tolarencia.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.3 Probléma)\nfokomp_munkahelyi_elegedettseg.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.4 Probléma)"
  },
  {
    "objectID": "appendix_adatbazisok.html#faktorelemzés",
    "href": "appendix_adatbazisok.html#faktorelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.6 Faktorelemzés",
    "text": "B.6 Faktorelemzés\n\nfaktor_szorongas.omv - példa (Münnich és mtsai. (2006) 3.1. R-forráskód)\nfaktor_real_human_targyak.omv - példa (Münnich és mtsai. (2006) 3.9. R-forráskód)\nfaktor_bigfive.omv - példa (Münnich és mtsai. (2006) 3.21. R-forráskód)\nfaktor_kockazat.omv - példa (Münnich és mtsai. (2006) 3.7.4 Probléma)\nfaktor_fogkrem.omv - példa (Malhotra és Simon (2008) 617. oldal)"
  },
  {
    "objectID": "appendix_adatbazisok.html#feltáró-faktorelemzés",
    "href": "appendix_adatbazisok.html#feltáró-faktorelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.7 Feltáró faktorelemzés",
    "text": "B.7 Feltáró faktorelemzés\n\nfaktor_fogkrem.xlsx - A kutató arra volt kíváncsi, milyen előnyöket keresnek a fogyasztók a fogrémvásárlásnál. Egy 30 fős mintán a válaszadókat arra kérték, hogy jelezzék, mennyire értenek egyet a következő állításokkal (1 = egyáltalán nem ért egyet; 7 = teljes mértékben egyetért)\n\nAz adatbázis szerkezete:\n\nsorszam: válaszadó sorszáma (id)\nv1: Fontos, hogy olyan fogkrémet vásároljak, amellyel megelőzhető a fogszuvasodás. (likert: 1-7)\nv2: Az olyan fogkrémeket szeretem, amely fényessé teszi a fogaimat. (likert: 1-7)\nv3: Egy fogkrémnek erősítenie kell a fogínyt. (likert: 1-7)\nv4: Az olyan fogkrémeket szeretem, amely friss leheletet biztosít. (likert: 1-7)\nv5: A fog romlásának megelőzése számomra nem fontos elvárás. (likert: 1-7)\nv6: A legfontosabb szempont a fogkrém vásárlásánál a szép fog. (likert: 1-7)\n\nKapcsolódó állományok:\n\nefa_fogkrem.omv - Feltáró faktorelemzés jamovi-ban\n\n\n\n\n\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési kézikönyv. Alinea Kiadó."
  },
  {
    "objectID": "appendix_gyakorlo.html",
    "href": "appendix_gyakorlo.html",
    "title": "Appendix C — Gyakorló feladatok",
    "section": "",
    "text": "D Lineáris regresszió\nA feladat forrása: Malhotra és Simon (2008, o. 579)\nEgy kutatásban, amely háztartások fogyasztói magatartását vizsgálta, a következő életstílus-állításokat értékelték hétfokú skálán (1 = egyetért, 7 = nem ért egyet).\nEgy előtesztben 25 fogyasztót kérdeztek meg, ennek adatai láthatók a faktor_eletstilus.sav adatbázisban.\nA feladat forrása: Statistics By Jim\nA HERTDAQ Bank felméri, hogy az ügyfelei mennyire elégedettek a szolgáltatások gyorsaságával. A következő négy kérdést dolgozza ki:\nA fenti itemekre egy 5 fokozatú Likert-skála segítségével lehetett válaszolni, amelyen 1-től (nagyon nem értek egyet) és 5-ig (nagyon egyetértek) tartó értékek közül lehet választani. Összesen 60 ügyfelet kértek fel a felmérés kitöltésére az előzetes vizsgálati szakaszban, még mielőtt a felmérést szélesebb körben elkezdenék terjeszteni.\nA feladat forrása: Malhotra és Simon (2008, o. 579)\nEgy kutatásban, amely háztartások fogyasztói magatartását vizsgálta, a következő életstílus-állításokat értékelték hétfokú skálán (1 = egyetért, 7 = nem ért egyet).\nEgy előtesztben 25 fogyasztót kérdeztek meg, ennek adatai láthatók a faktor_eletstilus.sav adatbázisban.\nA feladat forrása: Abraham és mtsai. (2020). Az eredeti kérdőív és adatbázis is letölthető.\nA kutatók indonéz fiatalok körében szeretnék vizsgálni a digitális írástudást. Összeállítanak egy kérdőívet, amely összesen 40 kérdést (itemet) tartalmaz. A kutatók szerint az itemek 6 skála (faktor) köré csoportosíthatók. A következő listában először a 6 skálát, majd a hozzá tartozó itemeket nevezzük meg:\nVégezzünk megerősítő faktorelemzést, ellenőrizzük le, hogy az adataink jól illeszkednek a fenti faktorstruktúrára! Az adatok a faktor_digitalis_irastudas.xlsx állományban találhatók.\nA nike.xlsx adatain végezze el a következő elemzéseket. Csak a következő változókat vegye figyelembe: tudatosság, attitúd, preferencia, cél és a Nike iránti hűség.\nA nike.xlsx adatain végezze el a következő elemzéseket. A használt oszlopok a következőek:\nVan különbség a három fogyasztói csoport (termekhasznalat) között a tudatosság, attitűd, preferencia, szándék és a Nike iránti lojalitás szempontjából?"
  },
  {
    "objectID": "appendix_gyakorlo.html#feladat-a-reklám-hatása",
    "href": "appendix_gyakorlo.html#feladat-a-reklám-hatása",
    "title": "Appendix C — Gyakorló feladatok",
    "section": "D.1 Feladat: A reklám hatása",
    "text": "D.1 Feladat: A reklám hatása\nA feladat forrása: Malhotra és Simon (2008, o. 579)\nEgy nagy szupermarketlánc meg akarja határozni a reklám hatását az egymáshoz viszonyított versenyképességre. 15 állam reklámköltség- (versenytárs költsége = 100) és értékesítési adatait (versenytárs értékesítése = 100) kaptuk meg a fő versenytárshoz viszonyítva. Ön azt a feladatot kapta, hogy választ kell adnia a menedzser kérdésére, van-e összefüggés a reklámköltségek és az értékesítés között. Az adatok a lin_reg_reklam_hatasa.sav állományban találhatók.\n\nÁbrázolja pontdiagramon a relatív értékesítést (y tengely) és a relatív reklámköltséget (x tengely), és értelmezze a diagramot!\nMilyen mutatószámot használna annak megállapítására, hogy van-e összefüggés a két változó között? Miért?\nKészítsen egyszerű lineáris regressziót a relatív értékesítés és a relatív reklámköltség között!\nÉrtelmezze a regressziós együtthatókat!\nSzignifikáns a regressziós összefüggés?\nHa a vállalat a versenytárshoz viszonyítva ugyanannyi pénzt költene reklámra (ha a relatív reklámköltség 100 volt), mekkora lenne a vállalat relatív értékesítési szintje?\nÉrtelmezze a kapott \\(R^2\\)-et?"
  },
  {
    "objectID": "appendix_gyakorlo.html#feladat-illatszerboltok",
    "href": "appendix_gyakorlo.html#feladat-illatszerboltok",
    "title": "Appendix C — Gyakorló feladatok",
    "section": "D.2 Feladat: Illatszerboltok",
    "text": "D.2 Feladat: Illatszerboltok\nA feladat forrása: Malhotra és Simon (2008, o. 579)\nAnnak megértése érdekében, hogy a minőség és az ár hogyan befolyásolja az illatszerboltok törzsvásárlóit, a válaszadókat arra kértük, hogy egy nagyváros 14 üzletét értékeljék a következő szempontok szerint:\n\na bolt iránti preferencia\naz áru minősége és az\nelfogadható ár.\n\nMinden értékelést 11 fokozatú skálán végeztek, ahol a magasabb számok pozitívabb értékítéletet jelentettek. Az adatok a lin_reg_illatszerbolt.sav állományban vannak.\n\nFuttasson többváltozós regressziót a bolt iránti preferencia vizsgálatára az áru minősége és ára tekintetében!\nÉrtelmezze a parciális regressziós együtthatót!\nHatározza meg a teljes regresszió szignifikanciáját!\nHatározza meg a parciális regressziós együttható szignifikanciáját!\nA multikollinearitás probléma lehet ebben az esetben? Miért vagy miért nem?\nAz egy vagy a két magyarázó változót tartalmazó modell az optimális? Miért?"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Appendix D — Irodalomjegyzék",
    "section": "",
    "text": "Abraham, J., Ali, M. M., Andangsari, E. W. és Hartanti, L. E. P. (2020).\nConfirmatory factor analysis of celebrity worship, digital literacy, and\nnostalgia: Dataset of Indonesians. Data in Brief, 33,\n106417. https://doi.org/10.1016/j.dib.2020.106417\n\n\nCarver, C. S. és Scheier, M. F. (2006).\nSzemélyiségpszichológia. Osiris Kiadó.\n\n\nCsallner, A. E. (2015). Bevezetés az SPSS statisztikai programcsomag\nhasználatába. http://www.jgypk.hu/tamop15e/tananyag_html/spss/index.html\n\n\nHorn, J. L. (1965). A rationale and test for the number of factors in\nfactor analysis. Psychometrika, 30, 179–185. https://doi.org/10.1007/BF02289447\n\n\nKárász, J. T., Nagy, O. N., Széll, K. és Takács, S. (2022).\nCronbach-alfa: vele vagy nélküle? Magyar Pszichológiai Szemle,\n77, 81–98. https://doi.org/10.1556/0016.2022.00004\n\n\nKetskeméty, L. és Izsó, L. (2005). Bevezetés az SPSS\nprogramrendszerbe - Módszertani útmutató és feladatgyűjtemény\nstatisztikai elemzésekhez. ELTE Eötvös Kiadó.\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás.\nAkadémiai Kiadó.\n\n\nMalkewitz, C. P., Schwall, P., Meesters, C. és Hardt, J. (2023).\nEstimating reliability: A comparison of Cronbach’s α, McDonald’s ωt and\nthe greatest lower bound. Social Sciences & Humanities\nOpen, 7, 100368. https://doi.org/10.1016/j.ssaho.2022.100368\n\n\nMoksony, F. (2006). Gondolatok és adatok. Társadalomtudományi\nelméletek empirikus ellenőrzése. Aula Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika\npszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nNagy, O. N. (2006). A pszichológiai tesztek reliabilitása. In S. Rózsa,\nO. N. Nagy, és A. Oláh (Szerk.), A pszichológiai mérés alapjai.\nElmélet, módszer és gyakorlati alkalmazás. Bölcsész Konzorcium. https://mek.oszk.hu/05500/05536/05536.pdf\n\n\nRózsa, S., Hupuczi, E., Martin, L., Birkás, B., Hartung, I., Hargitai,\nR., Varga, J., Láng, A., Tiringer, I. és Kállai, J. (2019). A Tellegen\nAbszorpciós Skála részletes pszichometriai elemzése. Mentálhigiéné\nés Pszichoszomatika, 20, 35–77. https://doi.org/10.1556/0406.20.2019.003\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési\nkézikönyv. Alinea Kiadó.\n\n\nSzékelyi, M. és Barna, I. (2002). Túlélőkészlet az SPSS-hez.\nTöbbváltozós elemzési technikáról társadalomkutatók számára.\nTypotex Kiadó.\n\n\nTakács, S. (2017). Bevezetés a matematikai statisztikába 2.\nTöbbváltozós statisztikai módszerek. Antarész Kiadó.\n\n\nVarga, A. (2019). Többváltozós statisztika dióhéjban:\nVáltozó-orientált módszerek. Pólya Kiadó.\n\n\nWatkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best\nPractice. Journal of Black Psychology, 44, 219–246. https://doi.org/10.1177/0095798418771807"
  }
]