[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Többváltozós statisztika jamovi-ban és R-ben",
    "section": "",
    "text": "Előszó\nA statisztika alapfogalmai nagyon jól szemléltethetők az egyváltozós statisztikai eljárásokkal. Ezek az eljárások tipikusan egy (vagy két) változó vizsgálatával járulnak hozzá az empirikus vizsgálatok során felmerülő statisztikai jellegű kérdések megválaszolásához.\nA kutatómunka során azonban szükség lehet egyszerre több változó bevonására az elemzésbe, ezeket az eljárásokat többváltozós statisztikai eljárásoknak nevezzük. Ilyen eljárás például:\n\nLineáris regresszió (1)\nFőkomponens elemzés (2)\nMegbízhatóság elemzés (3)\nFeltáró faktorelemzés (4)\nMegerősítő faktorelemzés (5)\nTöbbszempontos varianciaelemzés (6)\nKlaszterelemzés (7)\nDiszkriminancia elemzés (8)\nTöbbváltozós varianciaelemzés (9)\nLogisztikus regresszióelemzés (10)\nTöbbdimenziós skálázás (11)\n\nA jegyzet elkészítéséhez elsősorban a kurzus tankönyvét (Münnich és mtsai., 2006) használtuk fel, de támaszkodtunk egyéb forrásokra is (Csallner, 2015; Ketskeméty és Izsó, 2005; Malhotra és Simon, 2008; Moksony, 2006; Sajtos és Mitev, 2007; Székelyi és Barna, 2002; Takács, 2017; Varga, 2019).\n\n\n\n\nCsallner, A. E. (2015). Bevezetés az SPSS statisztikai programcsomag használatába. http://www.jgypk.hu/tamop15e/tananyag_html/spss/index.html\n\n\nKetskeméty, L. és Izsó, L. (2005). Bevezetés az SPSS programrendszerbe - Módszertani útmutató és feladatgyűjtemény statisztikai elemzésekhez. ELTE Eötvös Kiadó.\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó.\n\n\nMoksony, F. (2006). Gondolatok és adatok. Társadalomtudományi elméletek empirikus ellenőrzése. Aula Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési kézikönyv. Alinea Kiadó.\n\n\nSzékelyi, M. és Barna, I. (2002). Túlélőkészlet az SPSS-hez. Többváltozós elemzési technikáról társadalomkutatók számára. Typotex Kiadó.\n\n\nTakács, S. (2017). Bevezetés a matematikai statisztikába 2. Többváltozós statisztikai módszerek. Antarész Kiadó.\n\n\nVarga, A. (2019). Többváltozós statisztika dióhéjban: Változó-orientált módszerek. Pólya Kiadó."
  },
  {
    "objectID": "sec_linearis_regresszio.html",
    "href": "sec_linearis_regresszio.html",
    "title": "1  Lineáris regresszió",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-menete",
    "href": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-menete",
    "title": "2  Főkomponens elemzés",
    "section": "2.1 A főkomponens elemzés menete",
    "text": "2.1 A főkomponens elemzés menete\nAz eredeti \\(X_1,X_2,\\dots,X_p\\) változókból a \\(Z_i=a_i1 X_1+ a_i2 X_2+\\dots + a_ip X_p\\) lineáris kombinációk segítségével kapjuk meg a főkomponenseket, azzal feltétellel, hogy \\(a_{i1}^2+a_{i2}^2+\\dots+a_{ip}^2=1\\), és az egymás után létrejövő \\(Z_1,Z_2,…,Z_p\\) főkomponensek nem korrelálnak egymással.\nGyakran az \\(X_1,X_2,\\dots,X_p\\) változó standardizált értékeiből indulunk ki, hogy a változók arányosan fejtsék ki hatásukat a főkomponensekre. A jamovi is így végzi az elemzést. Ekkor a változok átlaga nulla, szórása és variancia pedig 1 lesz.\nA részletek ismertetése nélkül a keresett \\(a_{i1},a_{i2},\\dots,a_{ip}\\) együtthatók megtalálása egy sajátérték-sajátvektor keresési feladat az eredeti \\(X_1,X_2,\\dots,X_p\\) változók korrelációs mátrixában. A megtalált \\(p\\) darab sajátérték $_1_2_p>0 $sorrendjét feltételezve, \\(\\lambda_i\\) az \\(i.\\) főkomponens varianciáját adja \\((\\lambda_i=var(Z_i))\\), és a megtalált \\(p\\) darab sajátvektorból az \\(i.\\) egyes elemei lesznek a \\(Z_i=a_{i1} X_1+ a_{i2} X_2+\\dots+ a_{ip} X_p\\) főkomponens \\(a_{i1},a_{i2},\\dots,a_{ip}\\) együtthatói.\nFontos összefüggés, hogy a főkomponensek (\\(Z_i\\)-k) varianciájának az összege egyenlő az eredeti standardizált változók (\\(X_i\\)-k) varianciájának összegével, azaz \\(\\lambda_1+\\lambda_2+\\dots+\\lambda_p=1+1+\\dots+1=p.\\)"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-alkalmazási-feltételei",
    "href": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-alkalmazási-feltételei",
    "title": "2  Főkomponens elemzés",
    "section": "2.2 A főkomponens elemzés alkalmazási feltételei",
    "text": "2.2 A főkomponens elemzés alkalmazási feltételei\n\nA főkomponens elemzés során általában 4-5-ször (egyes szerzőknél 10-szer) nagyobb a mintaelemszám a vizsgált változók számánál.\nA faktoranalízis feltétele, hogy egymással korreláló változókból induljunk ki. A Bartlett-féle szferikus próba nullhipotézise, hogy a változók korrelálatlanok (vagyis a korrelációs mátrixnak a főátlón kívüli elemei csak véletlenül térnek el a nullától). A szignifikáns p-érték a kedvező a főkomponens elemzés számára. (Megjegyezzük, hogy a túlságosan magas egyirányú korrelációk sem jók, ugyanis ez azt okozhatja, hogy a főkomponens elemzésnek nem lesz megoldása, ugyanis minden változó egy faktorba kerül.)\nAz MSA (Measure of Sampling Adequecy) az egyes változók esetében mutatja meg, hogy mennyire van szoros kapcsolatban a többi változóval. Érdemes a 0,5 alatti MSA értékkel rendelkező változókat kizárni az elemzésből. Értéke 0 és 1 közötti lehet.\nA Kaiser-Meyer-Olkin- (KMO) kritérium az MSA értékek átlaga. Míg az MSA érték az egyes változókra vonatkozik, a KMO az összes változóra egyidejűleg. A KMO mutatószám jelentését a következőképpen ítélhetjük meg:\n\nKMO ≥ 0,9 kiváló\nKMO ≥ 0,8 nagyon jó\nKMO ≥ 0,7 megfelelő\nKMO ≥ 0,6 közepes\nKMO ≥ 0,5 gyenge\nKMO < 0,5 elfogadhatatlan."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponensek-forgatása-rotáció",
    "href": "sec_fokomponens_elemzes.html#a-főkomponensek-forgatása-rotáció",
    "title": "2  Főkomponens elemzés",
    "section": "2.3 A főkomponensek forgatása (rotáció)",
    "text": "2.3 A főkomponensek forgatása (rotáció)\nA faktorkiválasztás (extrakció) során az elemzés elsődleges célja, hogy maximalizálja a főkomponensek varianciáját, amely eredményeként megkapjuk a rotálatlan faktorsúly-mátrixot. A faktorsúly az eredeti változó és az adott faktor közötti korrelációt mutatja, amelynek értéke a korrelációs együtthatókhoz hasonlóan -1 és 1 között változhat.\nA faktorkiválasztás során azonban előfordulhat, hogy olyan változók fognak korrelálni egy adott faktorral, amelyeknek semmi közük egymáshoz, ezáltal lehetetlenné téve az értelmezést. Ezen a problémán segít a forgatás, vagy más néven rotáció. A faktor-rotáció azt jelenti, hogy a faktorok tengelyeit elforgatjuk úgy, hogy egyszerűbb és értelmezhetőbb faktormegoldáshoz vezessen.\nA rotáció (forgatás) során nem változnak sem a kommunalitás, sem pedig az összes magyarázott variancia, csak a faktorok sajátértékei/magyarázott varianciái módosulnak.\nA rotáláson belül két típust különböztetünk meg: a derékszögű (ortogonális) (Varimax, Equimax, Quartimax) és a hegyesszögű (nem ortogonális) (Direct Oblimin, Promax) forgatási módszereket.\nA derékszögű esetében a tengelyek merőlegesen állnak egymásra, ezáltal a faktorok nem korrelálnak egymással, míg a hegyesszögű esetében ezek tetszőleges szöget zárnak be egymással, vagyis a faktorok korrelálni fognak egymással."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa",
    "href": "sec_fokomponens_elemzes.html#példa",
    "title": "2  Főkomponens elemzés",
    "section": "2.4 1. Példa",
    "text": "2.4 1. Példa\nA példa Münnich és mtsai. (2006) 2.3.1. alfejezet alapján készült és a Kapcsolódó jamovi állomány: fokomp_elemzes_tantargyak.omv.\n1. Határozzuk meg a korrelációs mátrixot (jamovi-ban: Regression / Correlation matrix)\n\n\n\nKorrelációs mátrix meghatározása\n\n\nA korrelációs mátrix adatai arra utalnak, hogy szoros kapcsolat van a változók között. A korrelációs értékek nullánál nagyobbak, ami azonos irányú tendenciákra utal. E két mátrix is alátámasztja a feltételezésünket, hogy a változók szorosan együtt változnak.\n2. Ellenőrizzük le az adatok alkalmasságát (jamovi-ban: Factor / Principal Component Analysis)\nA változóink eleget tesznek a Bartlett-féle szferikus próbának, a korrelációs mátrix nem egységmátrix \\((p<0,001)\\), az MSA értékek is nagyobban \\(0,5\\)-nél és a KMO érték is megfelelő.\n\n\n\nAlkalmazási feltételek ellenőrzése\n\n\n3. Határozzuk meg a komponensek számát\nElvileg annyi főkomponenst lehet kiszámolni, ahány változónk van, a célunk azonban a komponensek számának minimalizálása.\nTöbb eljárás létezik a főkomponensek számának meghatározására:\n\nHorn-féle párhuzamos analízis (jamovi-ban: Based on parallel analysis): modern eljárás, amely szimuláció segítségével állapítja meg a főkomponensek számát (Horn, 1965).\nA priori meghatározás (jamovi-ban: Fixed number): korábbi ismerete alapján megadjuk a főkomponensek számát.\nSajátértéken alapuló megoldás (jamovi-ban: Based on eigenvalue): tipikusan csak az 1-nél nagyobb sajátértékű faktorokat tartjuk bent a modellben. Az 1-nél kisebb varianciájú faktorok ugyanis nem jobbak mint az eredeti standardizált változók\nSajátértékábrán (scree-plot, kőtörmelék ábra) alapuló meghatározás (jamovi-ban: Scree plot): a sajátérték ábra a sajátértékek ábrázolása a főkomponensek sorrendjében. Az ábra formája alapján lehet következtetni a főkomponensek számára: ahol a görbe meredekségében van egy határozott törés, meredekebb rész után laposabb jön. Ahol tehát a görbe laposodása elkezdődik, az a figyelembe vett főkomponensek megfelelő száma.\nMagyarázott varianciahányadon alapuló meghatározás (jamovi-ban: Component summary): ekkor az előállított főkomponensek számát úgy határozzuk meg, hogy a főkomponensek által magyarázott variancia kumulált százalékos értéke elérjen egy megfelelő szintet. A megfelelő szint (60%-95%-ig) a probléma jellegétől függ.\n\nA Horn-féle párhuzamos elemzés 1 főkomponenst javasol.\n\n\n\nFőkomponensek számának meghatározása\n\n\n4. Válasszunk forgatást (jamovi-ban: Rotation)\nA jamovi alapértelmezés szerint a Varimax forgatást ajánlja, amely derékszögű koordinátatengelyeket eredményez és a legtöbb esetben ez a megfelelő választás. Lehetőségünk van ezen módosítani. Az összes lehetőség:\n\nNone – rotálatlan elemzés\nVarimax\nQartimax\nPromax\nOblimin\nSimplimax\n\nMivel egyetlen főkomponensünk van, így nem változtatunk az alapértelmezett Varimax beállításon.\n5. A főkomponens elemzés eredménye\nKomponens mátrix (jamoviban: Component loadings)\nA főkomponens elemzés eredménye a komponens mátrix (faktormátrix), amelynek soraiban az eredeti változók, oszlopaiban a kinyert főkomponensek vannak. A cellákban a komponens súlyok (faktorsúlyok) szerepelnek, amelyek a főkomponens és a változó közötti korrelációt jelentik. Ezek egyben a főkomponensek azon együtthatói, amelyekkel a standardizált változó a főkomponensekkel kifejezhető.\nA magas abszolút értékű faktorsúly azt jelzi, hogy komponens és a változó szorosan összefügg.\nA változókat tartalmazó sorok rendezhetők a faktorsúlyok csökkenő sorrendjében (jamovi-ban: Sort loading by size)\nAz adott értéknél kisebb faktorsúlyok elrejthetők a táblázatban (jamoviban: Hide loadings below)\nA Uniqueness oszlopban az egyes változók „egyediségét” is láthatjuk. Az egyediség a variancia azon aránya, amely „egyedi” a változóra nézve, és nem magyarázható a komponensekkel. Vegyük figyelembe, hogy minél nagyobb az „egyediség”, annál kisebb a változó relevanciája/hozzájárulása a modellben.\nA kezdő sajátértékek (jamovi-ban: Initial eigenvalues)\nA kezdő sajátértékek táblázat a sajátértékeket adja meg. A komponensek sajátértékei csökkenő nagyságúak, ahogy az 1. komponenstől a 4. komponensig haladunk. A komponens sajátértéke kifejezi a komponens által magyarázott teljes varianciát. A 4 komponens összvarianciája pontosan 4. A további két oszlopban ez alapján számoljuk a százalékos és a kummulált százalékos varianciát.\nA komponensek összegzése (jamovi-ban: Component summary)\nA komponensek összegzése táblázat tartalmazza a megtartott komponenseket, a magyarázott varianciát, illetve utóbbit százalékosan is kifejezve. Vegyük észre, hogy ez a sor teljesen megegyezik a kezdő sajátértékek táblázat első sorával. Az SS Loadings felirat magyarázata, hogy magyarázott variancia a komponenshez tartozó faktorsúlyok négyzetösszege (sum of square).\n\n\n\nKomponensek összegzése\n\n\n6. Főkomponens értékek kiszámítása\nA főkomponens elemzés célja az eredeti változók csökkentése. A főkomponens(ek) az eredeti változók lineáris kombinációjával kifejezhetők. Ez(ek) a főkomponens értékek (jamovi-ban: Component score) az adatbázisban is rögzíthetők, és további elemzések kiindulópontjai lehetnek.\n\n\n\nFőkomponens értékek kiszámítása\n\n\nSikerült tehát az érdemjegyeket egyetlen mérőszámmal kifejezni, a fenti főkomponens érték az, amely a lehető legjobban magában foglalja az egyes tantárgyakból szerzett jegyeket és ezáltal a reál tantárgyak iránti fogékonyság mérőszáma lehet. A legjobban a kilencedik személy teljesít a reál tárgyakból, legrosszabbul pedig a hatodik. Ezek az értékek standardizáltak, vagyis 0 átlagúak és 1 szórásúak.\n\n\n\nFőkomponens értékek leíró statisztikája\n\n\n\n\n\n\nHorn, J. L. (1965). A rationale and test for the number of factors in factor analysis. Psychometrika, 30, 179–185. https://doi.org/10.1007/BF02289447\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika"
  },
  {
    "objectID": "sec_megbizhatosag_elemzes.html#cronbach-alfa-belső-konzisztencia-mérése",
    "href": "sec_megbizhatosag_elemzes.html#cronbach-alfa-belső-konzisztencia-mérése",
    "title": "3  Megbízhatóság elemzés",
    "section": "3.1 Cronbach-alfa – belső konzisztencia mérése",
    "text": "3.1 Cronbach-alfa – belső konzisztencia mérése\nFőkomponens elemzés segítségével könnyen tudunk több változót - viszonylag csekély veszteséggel - egyetlen változóba tömöríteni, ezért gyakran használják kérdőívek itemeinek szelekciójára, valamint megbízhatóság (reliabilitás) vizsgálatra. A klasszikus tesztelmélet keretein belül azonban a tesztek megbízhatóságának (reliabilitásának) több lehetséges mutatója is létezik.\nCronbach 1951-es munkájában publikálta azon nézetét, hogy a korábbi egyszerű tesztfelezéses eljárás helyett egy annál tökéletesebb mutatót kellene használni a tesztek megbízhatóságának indikátoraként. Ha az itemek száma alacsony vagy az itemek közötti átlagos korreláció alacsony, akkor csökkenni fog a Cronbach-féle alfa értéke is. Az is egyértelmű, hogy az itemek közötti alacsony korreláció arra enged következtetni, hogy a teszt itemjei nem egy és ugyanazon dolog vizsgálatára szolgálnak, a belőlük képzendő tesztérték nem alkalmas sem elméleti, sem pedig gyakorlati felhasználásra.\nAz ómega (McDonald \\(\\omega\\)) korrigálja a Cronbach-alfa torzítását, érdemes elvégezni az elemzést ezzel a mutatóval is (Kárász és mtsai., 2022; Malkewitz és mtsai., 2023)."
  },
  {
    "objectID": "sec_megbizhatosag_elemzes.html#példa-real-tárgyak-iránti-fogékonyság",
    "href": "sec_megbizhatosag_elemzes.html#példa-real-tárgyak-iránti-fogékonyság",
    "title": "3  Megbízhatóság elemzés",
    "section": "3.2 Példa: Real tárgyak iránti fogékonyság",
    "text": "3.2 Példa: Real tárgyak iránti fogékonyság\nEgy fiktív adatbázis 9 tanuló iskolai jegyeit tartalamzza reál tantárgyakból (matematika, fizika, kémia, informatika) (megbizhatosag_tantargyak.xlsx). Vizsgáljuk meg, ha a reál tantárgyak iránti fogékonyságot ezzel a 4 érdemjeggyel mérnénk, akkor ez megbízhatóság szempontjából alkalmas mérőeszköz lenne.\n\nreal <- rio::import(file = \"adat/megbizhatosag_tantargyak.xlsx\")\nstr(real)\n#> 'data.frame':    9 obs. of  4 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5\n#>  $ fizika     : num  5 5 3 3 4 2 4 3 5\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5\n\nA Cronbach alfa meghatározását végezhetjük a {psych} csomag alpha() függvényével.\n\npsych::alpha(real)  # Cronbach-alfa\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = real)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.97      0.97    0.98      0.89  33 0.017  3.7 1.4    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.91  0.97  0.99\n#> Duhachek  0.93  0.97  1.00\n#> \n#>  Reliability if an item is dropped:\n#>             raw_alpha std.alpha G6(smc) average_r S/N alpha se\n#> matek            0.94      0.95    0.95      0.86  18    0.032\n#> fizika           0.97      0.98    0.97      0.93  39    0.015\n#> informatika      0.96      0.97    0.97      0.92  33    0.019\n#> kemia            0.94      0.95    0.96      0.86  19    0.029\n#>              var.r med.r\n#> matek       0.0070  0.89\n#> fizika      0.0013  0.95\n#> informatika 0.0016  0.93\n#> kemia       0.0084  0.87\n#> \n#>  Item statistics \n#>             n raw.r std.r r.cor r.drop mean  sd\n#> matek       9  0.99  0.98  0.98   0.97  3.6 1.6\n#> fizika      9  0.92  0.93  0.91   0.88  3.8 1.1\n#> informatika 9  0.95  0.94  0.93   0.90  3.6 1.5\n#> kemia       9  0.98  0.98  0.98   0.96  3.9 1.5\n#> \n#> Non missing response frequency for each item\n#>                1    2    3    4    5 miss\n#> matek       0.11 0.22 0.11 0.11 0.44    0\n#> fizika      0.00 0.11 0.33 0.22 0.33    0\n#> informatika 0.11 0.22 0.00 0.33 0.33    0\n#> kemia       0.11 0.00 0.33 0.00 0.56    0\n\nA McDonald \\(\\omega\\) értékét kiszámolhatjuk a {psych} csomag omega() függvényével.\n\npsych::omega(real, plot = F)  # McDonald-ómega\n#> Omega \n#> Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, ...\n#>     digits = digits, title = title, sl = sl, labels = labels, \n#>     plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, o...\n#>     covar = covar)\n#> Alpha:                 0.97 \n#> G.6:                   0.98 \n#> Omega Hierarchical:    0.95 \n#> Omega H asymptotic:    0.96 \n#> Omega Total            0.99 \n#> \n#> Schmid Leiman Factor loadings greater than  0.2 \n#>                g   F1*   F2*   F3*   h2   u2   p2\n#> matek       0.97        0.28       0.99 0.01 0.94\n#> fizika      0.89  0.29             0.92 0.08 0.86\n#> informatika 0.91        0.28       0.95 0.05 0.87\n#> kemia       0.96  0.29             0.99 0.01 0.94\n#> \n#> With Sums of squares  of:\n#>    g  F1*  F2*  F3* \n#> 3.48 0.17 0.16 0.04 \n#> \n#> general/max  21.07   max/min =   4.03\n#> mean percent general =  0.9    with sd =  0.04 and cv of  0.05 \n#> Explained Common Variance of the general factor =  0.91 \n#> \n#> The degrees of freedom are -3  and the fit is  0 \n#> The number of observations was  9  with Chi Square =  0  with...\n#> The root mean square of the residuals is  0 \n#> The df corrected root mean square of the residuals is  NA\n#> \n#> Compare this with the adequacy of just a general factor and n...\n#> The degrees of freedom for just the general factor are 2  and...\n#> The number of observations was  9  with Chi Square =  5.14  w...\n#> The root mean square of the residuals is  0.05 \n#> The df corrected root mean square of the residuals is  0.08 \n#> \n#> RMSEA index =  0.401  and the 10 % confidence intervals are  ...\n#> BIC =  0.75 \n#> \n#> Measures of factor score adequacy             \n#>                                                  g  F1*  F2* ...\n#> Correlation of scores with factors            0.98 0.89 0.86 ...\n#> Multiple R square of scores with factors      0.95 0.78 0.74 ...\n#> Minimum correlation of factor score estimates 0.90 0.57 0.48 ...\n#> \n#>  Total, General and Subset omega for each subset\n#>                                                  g  F1*  F2* F3*\n#> Omega total for total scores and subscales    0.99 0.98 0.99  NA\n#> Omega general for total scores and subscales  0.95 0.89 0.91  NA\n#> Omega group for total scores and subscales    0.04 0.09 0.08  NA\n\nA fenti elemzéseket jamovi-ban a Factor / Reliability Analysis menüpont segítségével végezhetjük el.\n\n\n\nMegbízhatóság elemzés jamovi-ban\n\n\nA fenti megbízhatósági elemzések azt mutatják, hogy a négy tantárgy alfa értéke 0,966, ami egy igen jó érték, hiszen közel van 1-hez (jamovi-ban: Scale Reliability Statistics). Az Item Reliability Statistics táblázat oszlopában szereplő értékek azt mutatják, mi történik, ha egy változót kiveszünk a modellből. Láthatjuk, hogy egyedül a fizika változó értéke növelné az alfát, de a növekedés mértéke elenyésző lenne, tehát nem éri meg eltávolítani a változót, hiszen minél több információnk van egy személyről, annál jobb.\n\n\n\n\nCarver, C. S. és Scheier, M. F. (2006). Személyiségpszichológia. Osiris Kiadó.\n\n\nKárász, J. T., Nagy, O. N., Széll, K. és Takács, S. (2022). Cronbach-alfa: vele vagy nélküle? Magyar Pszichológiai Szemle, 77, 81–98. https://doi.org/10.1556/0016.2022.00004\n\n\nMalkewitz, C. P., Schwall, P., Meesters, C. és Hardt, J. (2023). Estimating reliability: A comparison of Cronbach’s α, McDonald’s ωt and the greatest lower bound. Social Sciences & Humanities Open, 7, 100368. https://doi.org/10.1016/j.ssaho.2022.100368\n\n\nNagy, O. N. (2006). A pszichológiai tesztek reliabilitása. In S. Rózsa, O. N. Nagy, és A. Oláh (Szerk.), A pszichológiai mérés alapjai. Elmélet, módszer és gyakorlati alkalmazás. Bölcsész Konzorcium. https://mek.oszk.hu/05500/05536/05536.pdf"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html",
    "href": "sec_feltaro_faktorelemzes.html",
    "title": "4  Feltáró faktorelemzés",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "sec_megerosito_faktorelemzes.html",
    "href": "sec_megerosito_faktorelemzes.html",
    "title": "5  Megerősítő faktorelemzés",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "sec_tobbszempontos_variancielemzes.html",
    "href": "sec_tobbszempontos_variancielemzes.html",
    "title": "6  Többszempontos varianciaelemzés",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "sec_klaszter.html#hierarchikus-eljárások",
    "href": "sec_klaszter.html#hierarchikus-eljárások",
    "title": "7  Klaszterelemzés",
    "section": "7.1 Hierarchikus eljárások",
    "text": "7.1 Hierarchikus eljárások\nA hierarchikus eljárások az egyes személyek, objektumok, esetek közötti távolság meghatározásával kezdődnek. A csoportok, klaszterek kialakítása történhet összevonáson vagy felosztáson alapuló módszerekkel. Az összevonó módszerek abból indulnak ki, hogy minden egyes elem egy önálló csoportot alkot, majd fokozatosan vonják össze az egyelemes csoportokat egyetlen nagy csoportba. Ezzel szemben a lebontó módszerben az összes elem egyetlen csoportba tartozik, és ezt a csoportot osztjuk fel kettő, majd egyre több csoportra addig, amíg minden elem egy önálló csoportot nem alkot. Az összevonó módszernél kezdetben minden egyes elem külön klasztert alkot. A klaszterek a megfigyelési egységek egyre nagyobb klaszeterekbe csoportosításával alakulnak ki. A folyamat addig folytatódik, amíg egyetlen klaszter lesz az egész. A következőkben a legelterjedtebb klaszteralkotó módszereket soroljuk fel:\n\nEgyszerű lánc, avagy a legközelebbi szomszéd elve\nTeljes lánc, avagy a legtávolabbi szomszéd elve\nÁtlagos távolság\nVariancia-módszerek\nWard-féle eljárás\nCentroidmódszerek\nSzekvenciális küszöbérték módszer\nPárhuzamos küszöbérték módszer\nOptimális felosztás módszere\n\nJamovi-ban a snowCluster csomag segítségével végethetünk klaszterelemzéseket. A csomag telepítése után a snowCluster / Hiearchical Clustering vagy snowCluster / Clustering Dendogram menüpontokat használjuk.\nA jamovi a következő módszereket ismeri:\n\nward.D\nward.D2\nsingle\ncomplete\naverage"
  },
  {
    "objectID": "sec_klaszter.html#k-középpontú-klaszterelemzés",
    "href": "sec_klaszter.html#k-középpontú-klaszterelemzés",
    "title": "7  Klaszterelemzés",
    "section": "7.2 K-középpontú klaszterelemzés",
    "text": "7.2 K-középpontú klaszterelemzés\nJÖN."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-kikből-lesznek-a-balesetezők",
    "href": "sec_diszkrimninancia.html#példa-kikből-lesznek-a-balesetezők",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.1 Példa: Kikből lesznek a balesetezők?",
    "text": "8.1 Példa: Kikből lesznek a balesetezők?\nEbben a példában azt vizsgáljuk, mely tényezők járulnak hozzá a balesetekhez.\n\nbaleset <- rio::import(file = \"adat/diszkriminancia_baleset.xlsx\")\nbaleset$baleset <- factor(baleset$baleset, labels = c(\"nem volt baleste\",\n    \"volt baleste\"))\nstr(baleset)\n#> 'data.frame':    36 obs. of  5 variables:\n#>  $ baleset   : Factor w/ 2 levels \"nem volt baleste\",..: 1 1 ...\n#>  $ megosztott: num  7 6 5 6 7 3 6 7 5 6 ...\n#>  $ pontossag : num  6 6 5 6 7 3 5 7 5 6 ...\n#>  $ kockazat  : num  2 3 1 2 4 7 2 1 3 2 ...\n#>  $ eszleles  : num  7 6 5 6 7 7 7 6 3 7 ...\npsych::headTail(baleset)\n#>              baleset megosztott pontossag kockazat eszleles\n#> 1   nem volt baleste          7         6        2        7\n#> 2   nem volt baleste          6         6        3        6\n#> 3   nem volt baleste          5         5        1        5\n#> 4   nem volt baleste          6         6        2        6\n#> ...             <NA>        ...       ...      ...      ...\n#> 33      volt baleste          3         3        5        4\n#> 34      volt baleste          2         2        7        1\n#> 35      volt baleste          3         3        4        4\n#> 36      volt baleste          4         4        6        4\n\nAz adatbázisban a baleset változó azt rögzíti, hogy volt-e már balesete a személynek vagy sem. Ez lesz tehát a csoportosító változó. A többi változó, melyek segítségével próbáljuk a csoportok közötti különbséget jellemezni, olyan dolgot mérnek, mint a megosztott figyelem (megosztott változó), a figyelem pontossága (pontossag), kockázatvállalási hajlandóság (kockazat) és az észlelés gyorsasága (eszleles).\nA diszkriminancia-analízisben az első lépés annak megállapítása, vajon valóban szét lehet-e választani a balesetezők és a nem balesetezők csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(megosztott, pontossag, kockazat, eszleles) ~ baleset,\n    data = baleset)\nsummary(man_1, test = \"Wilks\")\n#>           Df   Wilks approx F num Df den Df    Pr(>F)    \n#> baleset    1 0.27605   20.324      4     31 2.645e-08 ***\n#> Residuals 34                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a balesetet szenvedett és a balesetmentes autóvezetők között.\nFuttassuk le a diszkriminancia-analízis.\n\nlda_1 <- MASS::lda(baleset ~ megosztott + pontossag + kockazat + eszleles,\n    data = baleset)\nlda_1\n#> Call:\n#> lda(baleset ~ megosztott + pontossag + kockazat + eszleles, d...\n#> \n#> Prior probabilities of groups:\n#> nem volt baleste     volt baleste \n#>        0.4722222        0.5277778 \n#> \n#> Group means:\n#>                  megosztott pontossag kockazat eszleles\n#> nem volt baleste   5.941176  5.647059 2.588235 5.941176\n#> volt baleste       2.842105  2.684211 5.578947 3.105263\n#> \n#> Coefficients of linear discriminants:\n#>                    LD1\n#> megosztott -0.25764616\n#> pontossag  -0.07708289\n#> kockazat    0.36270659\n#> eszleles   -0.36702363\n\nA fenti output alapján az előzetes valószínűsége annak, hogy valakinek még nem volt balesete 0,472, míg annak a valószínűsége, hogy már volt balesete a személynek 0,528. Ezután vizsgálhatjuk a csoportátlagokat. A balesetmentes vezetők esetében magasabb a megosztott figyelem, a figyelem pontosságának és az észlelés változójának az átlaga, míg a kockázatvállalásé alacsonyabb. Ugyanakkor a másik csoport esetében a kockázatvállalás változójának az átlaga magasabb, míg a másik három képesség változójának átlaga alacsonyabb. Vagyis a balesetmentes vezetők gyorsabban képesek észlelni és jobban meg tudják osztani a figyelmüket, figyelmük pontosabb. A balesetet szenvedett vezetők esetében ezek a képességek gyengébbek, míg jobban szeretnek kockázatot vállalni.\nVégül a kanonikus diszkriminancia együtthatók segítségével felírhatjuk a kanonikus diszkriminancia-függvényt a következő módon:\nZ = 0,3627 * kockázat - 0,367 * észlelés - 0,2567 * megosztott-0,0771 * pontosság\nUtolsó lépésként pedig megnézhetjük, mennyire hatékony a diszkriminancia-analízis vagyis összevethetjük az eredeti csoporttagságokat a modell alapján alkotott besorolásokkal.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, baleset$baleset)\ntab_1\n#>                   \n#>                    nem volt baleste volt baleste\n#>   nem volt baleste               16            2\n#>   volt baleste                    1           17\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 91.66667\n\nA fenti sorok elkészík a predikciót, majd egy táblázatban reprezentálják az eredeti és a becsült csoportba tartozásokat. A legtöbb adat a főátlóban helyezkedik el, ami igen magas helyes besorolási arányra utal. A helyes besorolások aránya 91,7%.\nA példában a gépjárműbalesetek emberi okait vizsgáltuk. Az eredmények alapján a balesetmentes vezetők gyorsabban képesek észlelni és jobban meg tudják osztani a figyelmüket, figyelmük pontosabb is. Ellenben a balesetet szenvedett vezetők esetében ezek a képességek gyengébbek, míg jobban szeretnek kockázatot vállalni."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-a-szülés-utáni-depresszió-vizsgálata",
    "href": "sec_diszkrimninancia.html#példa-a-szülés-utáni-depresszió-vizsgálata",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.2 Példa: A szülés utáni depresszió vizsgálata",
    "text": "8.2 Példa: A szülés utáni depresszió vizsgálata\nEbben a példában a szülés utáni depresszió pszichés és szociális hátterét vizsgáljuk meg a diszkriminancia-analízis segítségével.\n\ndepresszio <- rio::import(file = \"adat/diszkriminancia_depresszio.xlsx\")\ndepresszio$ppdepresszio <- factor(depresszio$ppdepresszio, labels = c(\"nincs depresszió\",\n    \"van depresszió\"))\nstr(depresszio)\n#> 'data.frame':    20 obs. of  5 variables:\n#>  $ ppdepresszio: Factor w/ 2 levels \"nincs depresszió\",..: 1 ...\n#>  $ szeretet    : num  7 6 2 6 7 4 6 7 6 7 ...\n#>  $ tulvedes    : num  4 2 8 3 9 5 3 5 3 5 ...\n#>  $ kor         : num  24 20 19 22 23 25 26 18 19 22 ...\n#>  $ iskola      : num  12 17 8 16 17 17 12 17 16 17 ...\npsych::headTail(depresszio)\n#>         ppdepresszio szeretet tulvedes kor iskola\n#> 1   nincs depresszió        7        4  24     12\n#> 2   nincs depresszió        6        2  20     17\n#> 3   nincs depresszió        2        8  19      8\n#> 4   nincs depresszió        6        3  22     16\n#> ...             <NA>      ...      ... ...    ...\n#> 17    van depresszió        4        7  30      6\n#> 18    van depresszió        4        6  24      8\n#> 19    van depresszió        3        7  21      9\n#> 20    van depresszió        2        8  18     10\n\nAz adatbázisban a ppdepresszio változó mutatja a depresszió jelenlétét, vagy hiányát. A magyarázó változók között a következő változók szerepelnek: a szeretet skála (szeretet változó), amely azt méri, hogy a személyek mennyire érzik, hogy a szüleik szeretik őket; tulvedes-sel jelölt túlvédés iránti tendencia azt mutatja, hogy mennyire hajlamosak arra a személyek, hogy túlságosan is burokban tartsák, túlvédjék gyerekeiket, illetve szeretteiket; ezeken kívül két szociológiai adat is a rendelkezésünkre áll, nevezetesen az életkor (kor változó) és az elvégzett iskolai osztályok száma (iskola).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a depressziósok és a nem depressziósok csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(szeretet, tulvedes, kor, iskola) ~ ppdepresszio,\n    data = depresszio)\nsummary(man_1, test = \"Wilks\")\n#>              Df   Wilks approx F num Df den Df    Pr(>F)    \n#> ppdepresszio  1 0.29985   8.7561      4     15 0.0007461 ***\n#> Residuals    18                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a depressziós és a nem depressziós nők között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést!\n\nlibrary(MASS)\nlda_1 <- lda(ppdepresszio ~ szeretet + tulvedes + kor + iskola, data = depresszio)\nlda_1\n#> Call:\n#> lda(ppdepresszio ~ szeretet + tulvedes + kor + iskola, data =...\n#> \n#> Prior probabilities of groups:\n#> nincs depresszió   van depresszió \n#>              0.5              0.5 \n#> \n#> Group means:\n#>                  szeretet tulvedes  kor iskola\n#> nincs depresszió      5.8      4.7 21.8   14.9\n#> van depresszió        3.3      7.5 24.0    8.3\n#> \n#> Coefficients of linear discriminants:\n#>                  LD1\n#> szeretet -0.21900671\n#> tulvedes  0.18422053\n#> kor       0.03467147\n#> iskola   -0.26661705\n\nAz fenti output alapján az előzetes valószínűségek egyenlőek. A csoportátlagok közötti különbségek azt mutatják, hogy a nem depressziósok átlaga szeretet tekintetében magasabb (5,8), mint a depressziósoké (3,3), az iskolai végzettségük is magasabb (14,9), mint a depressziósoké (8,3). Ellenben a túlvédésnél a depressziósok értek el magasabb átlagot, ők az idősebbek is (24). Vagyis azok, akik postpartum depresszióban szenvednek, úgy érzik, a szüleik kevésbé szeretik őket, túlvédőbbek a gyerekeikkel szemben, idősebbek, és az iskolai végzettségük is alacsonyabb. A kanonikus diszkriminancia egyenlet alakja:\nZ =0,1842 * túlvédés + 0,0347 * kor - 0,2666 * iskola - 0,219 * szeretet\nUtolsó momentumként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, depresszio$ppdepresszio)\ntab_1\n#>                   \n#>                    nincs depresszió van depresszió\n#>   nincs depresszió                9              0\n#>   van depresszió                  1             10\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 95\n\nLáthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit, az arány 95%.\nVagyis azok, akik postpartum depresszióban szenvednek, úgy érzik, a szüleik kevésbé szeretik őket, túlvédőbbek a gyerekeikkel szemben, idősebbek, és az iskolai végzettségük is alacsonyabb."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-pszichoszomatikus-megbetegedésekre-hajlamosító-tényezők",
    "href": "sec_diszkrimninancia.html#példa-pszichoszomatikus-megbetegedésekre-hajlamosító-tényezők",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.3 Példa: Pszichoszomatikus megbetegedésekre hajlamosító tényezők",
    "text": "8.3 Példa: Pszichoszomatikus megbetegedésekre hajlamosító tényezők\nEbben a példában a pszichoszomatikus megbetegedéseket vizsgáljuk a diszkriminancia-analízis segítségével.\n\npszichoszomatikus <- rio::import(file = \"adat/diszkriminancia_pszichoszomatika.xlsx\")\npszichoszomatikus$pszichoszomatika <- factor(pszichoszomatikus$pszichoszomatika,\n    labels = c(\"pszichoszomatikus megbetegedése van\", \"egészséges\"))\nstr(pszichoszomatikus)\n#> 'data.frame':    36 obs. of  4 variables:\n#>  $ pszichoszomatika: Factor w/ 2 levels \"pszichoszomatikus me...\n#>  $ stressz         : num  5 6 5 6 7 3 6 7 5 6 ...\n#>  $ szorongas       : num  6 6 5 6 7 3 3 7 5 6 ...\n#>  $ coping          : num  2 3 1 2 4 7 2 1 3 2 ...\npsych::headTail(pszichoszomatikus)\n#>                        pszichoszomatika stressz szorongas coping\n#> 1   pszichoszomatikus megbetegedése van       5         6      2\n#> 2   pszichoszomatikus megbetegedése van       6         6      3\n#> 3   pszichoszomatikus megbetegedése van       5         5      1\n#> 4   pszichoszomatikus megbetegedése van       6         6      2\n#> ...                                <NA>     ...       ...    ...\n#> 33                           egészséges       3         3      5\n#> 34                           egészséges       2         2      7\n#> 35                           egészséges       3         3      4\n#> 36                           egészséges       4         4      6\n\nAz adatbázisban most a pszichoszomatika változó jelzi, hogy valamilyen pszichoszomatikus megbetegedése van vagy nincs a személynek. A változók közt szerepel a személyt ért stressz mértéke (stressz), a szorongási szintje (szorongás) és a megküzdési stratégiáinak hatékonysága (coping).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a pszichoszomatikusok és a nem pszichoszomatikusok csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(stressz, szorongas, coping) ~ pszichoszomatika, data = pszichoszomatikus)\nsummary(man_1, test = \"Wilks\")\n#>                  Df   Wilks approx F num Df den Df   Pr(>F)    \n#> pszichoszomatika  1 0.37974   17.423      3     32 6.92e-07 ***\n#> Residuals        34                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a két csoport között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést.\n\nlibrary(MASS)\nlda_1 <- lda(pszichoszomatika ~ stressz + coping + szorongas, data = pszichoszomatikus)\nlda_1\n#> Call:\n#> lda(pszichoszomatika ~ stressz + coping + szorongas, data = p...\n#> \n#> Prior probabilities of groups:\n#> pszichoszomatikus megbetegedése van \n#>                           0.4722222 \n#>                          egészséges \n#>                           0.5277778 \n#> \n#> Group means:\n#>                                      stressz   coping szorongas\n#> pszichoszomatikus megbetegedése van 5.764706 2.588235  5.529412\n#> egészséges                          2.842105 5.578947  2.684211\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1\n#> stressz   -0.31309547\n#> coping     0.46637406\n#> szorongas -0.06258674\n\nA fenti outputból láthatjuk, hogy a csoporttagságok előzetes valószínűsége a pszichoszomatikusok esetében kicsit kisebb (0,472). A két csoport összevetésénél azt láthatjuk, hogy a stressz és a szorongás változó átlaga a pszichoszomatikusok esetében, míg a coping változó átlaga az egészségesen esetében magasabb. Vagyis az egészséges személyeket kevesebb stressz éri, és azzal hatékonyabban is tudnak megküzdeni, mint a pszichoszomatikusok, illetve kevesebbet is szoronganak.\nA kanonikus diszkriminancia egyenlet pedig a következő módon alakul:\nZ = 0.4664 * coping - 0,3131 * stressz - 0,0626 * szorongas\nUtolsó lépésként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, pszichoszomatikus$pszichoszomatika)\ntab_1\n#>                                      \n#>                                       pszichoszomatikus megbe...\n#>   pszichoszomatikus megbetegedése van                        ...\n#>   egészséges                                                 ...\n#>                                      \n#>                                       egészséges\n#>   pszichoszomatikus megbetegedése van          2\n#>   egészséges                                  17\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 91.66667\n\nAz eredményen láthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit. Ez az arány 91,7%.\nEbben a példában a pszichoszomatikus megbetegedések lelki okait vizsgáltuk. Az diszkriminancia-analízis eredménye szerint az egészséges személyeket kevesebb stressz éri, és azzal hatékonyabban is tudnak megküzdeni, mint a pszichoszomatikusok, valamint kevesebbet is szoronganak."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-kik-vásárolnak-gyakran-bio-termékeket",
    "href": "sec_diszkrimninancia.html#példa-kik-vásárolnak-gyakran-bio-termékeket",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.4 Példa: Kik vásárolnak gyakran bio termékeket?",
    "text": "8.4 Példa: Kik vásárolnak gyakran bio termékeket?\nUtolsó példánk a marketingkutatás területére kalauzol minket. Azt próbáljuk megvizsgálni, hogy főként kik vásárolnak bio termékeket.\n\nbio <- rio::import(file = \"adat/diszkriminancia_bio.xlsx\")\nbio$vasarlas <- factor(bio$vasarlas, labels = c(\"soha nem vesz\", \"időnként vesz\",\n    \"gyakran vesz\"))\ntable(bio$vasarlas)\n#> \n#> soha nem vesz időnként vesz  gyakran vesz \n#>            10            10            10\nstr(bio)\n#> 'data.frame':    30 obs. of  5 variables:\n#>  $ vasarlas: Factor w/ 3 levels \"soha nem vesz\",..: 1 1 1 1 1...\n#>  $ ertek   : num  2 4 2 3 1 1 2 3 4 6 ...\n#>  $ attitud : num  2 4 2 3 1 3 5 3 1 2 ...\n#>  $ fizetes : num  55 67 89 78 99 112 132 78 95 64 ...\n#>  $ kor     : num  32 56 59 48 44 39 37 40 44 43 ...\npsych::headTail(bio)\n#>          vasarlas ertek attitud fizetes kor\n#> 1   soha nem vesz     2       2      55  32\n#> 2   soha nem vesz     4       4      67  56\n#> 3   soha nem vesz     2       2      89  59\n#> 4   soha nem vesz     3       3      78  48\n#> ...          <NA>   ...     ...     ... ...\n#> 27   gyakran vesz     6       6      62  19\n#> 28   gyakran vesz     9       9      69  27\n#> 29   gyakran vesz     9       9      78  28\n#> 30   gyakran vesz     8       8      73  30\n\nAz adatbázisban a vasarlas változó mutatja a biotermékek vásárlásának gyakoriságát, amely három értéket vehet fel: a személy szinte soha nem vesz ilyen termékeket, időnként vesz, illetve gyakran vesz. A vásárlás gyakoriságát a következő változókkal próbáljuk előre jelezni: milyen értékeket tulajdonít ezeknek a termékeknek (ertek változó, minél nagyobb pontszámot kap a skálán, annál jobban értékeli a személy a bio termékeket); az attitud skála a termékek iránti attitűdöt méri, a magasabb értékek itt is kedvezőbb atttitűdöt jeleznek; ezen túl szerepel még a személy életkora (kor változó) és a fizetése is (fizetes).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a bio termékeket vásárlók három csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(ertek, attitud, fizetes, kor) ~ vasarlas, data = bio)\nsummary(man_1, test = \"Wilks\")\n#>           Df   Wilks approx F num Df den Df    Pr(>F)    \n#> vasarlas   2 0.12109   11.242      8     48 8.599e-09 ***\n#> Residuals 27                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary.aov(man_1)\n#>  Response ertek :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> vasarlas     2 146.07  73.033  27.656 2.915e-07 ***\n#> Residuals   27  71.30   2.641                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response attitud :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> vasarlas     2 211.67 105.833  57.495 1.853e-10 ***\n#> Residuals   27  49.70   1.841                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response fizetes :\n#>             Df  Sum Sq Mean Sq F value  Pr(>F)  \n#> vasarlas     2  6427.5  3213.7  3.1857 0.05726 .\n#> Residuals   27 27237.5  1008.8                  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response kor :\n#>             Df Sum Sq Mean Sq F value   Pr(>F)   \n#> vasarlas     2 1449.3  724.63  7.3001 0.002922 **\n#> Residuals   27 2680.1   99.26                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti elemzés tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a három csoport között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést.\n\nlibrary(MASS)\nlda_1 <- lda(vasarlas ~ ertek + attitud + fizetes + kor, data = bio)\nlda_1\n#> Call:\n#> lda(vasarlas ~ ertek + attitud + fizetes + kor, data = bio)\n#> \n#> Prior probabilities of groups:\n#> soha nem vesz időnként vesz  gyakran vesz \n#>     0.3333333     0.3333333     0.3333333 \n#> \n#> Group means:\n#>               ertek attitud fizetes  kor\n#> soha nem vesz   2.8     2.6    86.9 44.2\n#> időnként vesz   5.3     5.6   106.5 34.9\n#> gyakran vesz    8.2     9.1    70.7 27.2\n#> \n#> Coefficients of linear discriminants:\n#>                  LD1          LD2\n#> ertek    0.278041839 -0.175361797\n#> attitud  0.578431017  0.066376341\n#> fizetes -0.003687657 -0.032311789\n#> kor     -0.019282287  0.003972177\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9687 0.0313\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\nA fenti output alapján az elemzés elején a három vásárlási gyakoriság valószínűsége egyenlő (0,333). Ha a csoportátlagokat vizsgáljuk akkor láthatjuk, hogy mind az értékek, mind az attitűd változójának tekintetében a soha sem vásárolók átlaga a legalacsonyabb (3 mindkét változó esetében), az időnként bio termékeket vásárlók csoport átlaga középen helyezkedik el mind a két változó esetében (5 és 6), és a gyakran vásárlók átlaga a legmagasabb (8 és 9). Életkor tekintetében egy kissé másképpen alakulnak a csoportok. A legidősebbek szinte sohasem vásárolnak bio termékeket, a legfiatalabbak pedig igen gyakran vásárolnak. Fizetés tekintetében nem figyelhető meg jól magyarázható összefüggés: a legalacsonyabb fizetésűek gyakran, míg a közepes fizetésűek szinte soha sem vásárolnak bio termékeket.\nA két kanonikus diszkriminancia-egyenlet a következőképpen alakul:\nZ1 = 0,278 * ertek + 0,578 * attitud - 0,019 * kor - 0,004 *fizetes\nZ2 = -0,175 * ertek + 0,066 * attitud + 0,004 * kor - 0,032 *fizetes\nUtolsó lépésként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, bio$vasarlas)\ntab_1\n#>                \n#>                 soha nem vesz időnként vesz gyakran vesz\n#>   soha nem vesz             9             1            0\n#>   időnként vesz             1             7            1\n#>   gyakran vesz              0             2            9\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 83.33333\n\nA fenti eredményben láthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit. Ez az arány 83%.\nAz utolsó probléma körében a bio termékek vásárlásának gyakoriságát vizsgáltuk. A kapott eredményeink alapján azok, akik gyakran vásárolnak ilyen termékeket, pozitívabbak értékelik és pozitívabb attitűdökkel rendelkeznek a bio termékek irányában, fiatalabbak, fizetésük viszont alacsonyabb."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-vezetési-programok",
    "href": "sec_diszkrimninancia.html#példa-vezetési-programok",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.5 Példa: Vezetési programok",
    "text": "8.5 Példa: Vezetési programok\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nvezetes <- rio::import(file = \"adat/diszkriminancia_vezetesi_program.xlsx\")\nvezetes$SUE <- factor(vezetes$SUE)\nstr(vezetes)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ SUE      : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1...\n#>  $ szelkot  : num  4 4 5 5 3 3 3 5 3 5 ...\n#>  $ elegedett: num  1 3 4 1 2 2 4 2 1 1 ...\n#>  $ rendszer : num  2 1 2 4 4 3 2 3 4 2 ...\npsych::headTail(vezetes)\n#>      SUE szelkot elegedett rendszer\n#> 1      1       4         1        2\n#> 2      1       4         3        1\n#> 3      1       5         4        2\n#> 4      1       5         1        4\n#> ... <NA>     ...       ...      ...\n#> 27     3       1         1        5\n#> 28     3       5         1        4\n#> 29     3       5         1        5\n#> 30     3       5         3        4\n\nVégezzük el a többváltozós variancia elemzést.\n\nman_1 <- manova(cbind(szelkot, elegedett, rendszer) ~ SUE, data = vezetes)\nsummary(man_1, test = \"Wilks\")\n#>           Df  Wilks approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.1894   10.815      6     50 1.102e-07 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary.aov(man_1, test = \"Wilks\")\n#>  Response szelkot :\n#>             Df Sum Sq Mean Sq F value Pr(>F)\n#> SUE          2  2.867  1.4333  1.1057 0.3455\n#> Residuals   27 35.000  1.2963               \n#> \n#>  Response elegedett :\n#>             Df Sum Sq Mean Sq F value   Pr(>F)   \n#> SUE          2 17.267  8.6333  8.4152 0.001444 **\n#> Residuals   27 27.700  1.0259                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response rendszer :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> SUE          2 52.267 26.1333      48 1.287e-09 ***\n#> Residuals   27 14.700  0.5444                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlm_1 <- lm(szelkot ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: szelkot\n#>           Sum Sq Df F value Pr(>F)\n#> SUE        2.867  2  1.1057 0.3455\n#> Residuals 35.000 27\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.9242958\n\nlm_1 <- lm(elegedett ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: elegedett\n#>           Sum Sq Df F value   Pr(>F)   \n#> SUE       17.267  2  8.4152 0.001444 **\n#> Residuals 27.700 27                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.6160119\n\nlm_1 <- lm(rendszer ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: rendszer\n#>           Sum Sq Df F value    Pr(>F)    \n#> SUE       52.267  2      48 1.287e-09 ***\n#> Residuals 14.700 27                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.2195122\n\n\nbiotools::boxM(data = vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")], grouping = vezetes$SUE)\n#> \n#>  Box's M-test for Homogeneity of Covariance Matrices\n#> \n#> data:  vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")]\n#> Chi-Sq (approx.) = 19.607, df = 12, p-value = 0.0749\n\n\nlibrary(MASS)\nlda_1 <- lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\nlda_1\n#> Call:\n#> lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\n#> \n#> Prior probabilities of groups:\n#>         1         2         3 \n#> 0.3333333 0.3333333 0.3333333 \n#> \n#> Group means:\n#>   szelkot elegedett rendszer\n#> 1     4.0       2.1      2.7\n#> 2     4.7       3.4      1.5\n#> 3     4.1       1.6      4.7\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1       LD2\n#> szelkot   -0.07056752 0.4959142\n#> elegedett  0.10193972 0.8596451\n#> rendszer  -1.32360357 0.5392379\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9616 0.0384\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, vezetes$SUE)\ntab_1\n#>    \n#>      1  2  3\n#>   1  4  1  0\n#>   2  3  9  0\n#>   3  3  0 10\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 76.66667"
  },
  {
    "objectID": "sec_diszkrimninancia.html#megjegyzések",
    "href": "sec_diszkrimninancia.html#megjegyzések",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.6 Megjegyzések",
    "text": "8.6 Megjegyzések\nDiszkriminancia analízis esetén az adatokat nem szükséges standardizálni, ennek oka, hogy az analízis eredményét nem befolyásolja jelentős mértékben az egyes változók mértékegysége.\nA függő változónk tehát kategorikus, a függetlenek pedig numerikusak. Arra vagyunk kíváncsiak, hogy a függő változó által meghatározott csoportok mely független változókban különböznek egymástól, melyek különböztetik meg egy egymástól a függő változó kategóriáit.\nHa a kategorikus függő változónk csupán kétértékű, akkor kétváltozós diszkriminancia elemzésről beszélünk, több szint esetén többváltozós diszkiriminancia elemzésről."
  },
  {
    "objectID": "sec_diszkrimninancia.html#az-alkalmazási-feltételek",
    "href": "sec_diszkrimninancia.html#az-alkalmazási-feltételek",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.7 Az alkalmazási feltételek",
    "text": "8.7 Az alkalmazási feltételek\nA fűggő változó kategorikus két vagy több szinttel. A független változók intervallum vagy arány skálájú változók, de használhatunk dichotóm változókat és a legalább 5 fokú likert skálán mért értékeket is. A függő változó csoportjaiban nagyjából azanosnak kell lennie a csoportnagyságnak, minden csoportnak legalább két adatsort tartalmaznia kell. A mintanagyságra is figyelnünk kell, a független változók számának kisebb kell lenni, mint a legkisebb csoport esetszáma, a teljes mintanagyság legalább 10-szer nagyobb a független változók számánál. A diszkriminancia elemzés feltételezi a független változók közötti lineáris kapcsolatot.\nAz egyváltozós normalitás vizsgálatára a kiugró értékek vizsgálata javasolt, illetve megfelelő mérési skála (például nem dichotóm változó esetén) a Shapiro–Wilk-próbát is használhatjuk. A többváltozós normalitás vizsgálatához\nA csoportok szétválasztásának egyik megközelítése a Mahalanobis-féle távolságot használja. Az eljárás lényege, hogy az \\(m\\) csoportot tartalmazó minta átlagvektorával becsüljük a csoportok valódi átlagvektorát. Az egyes személyek csoportközéptől való átlagát számoljuk ki a Mahalanobis-féle távolsággal, és minden személyt abba a csoportba sorolunk be ez alapján, amelyhez közelebb esik. Ez lehet az a csoport, amelybe a személy valóban beletartozik, de lehet másik is. A helyes besorolások aránya világosan megmutatja, hogy mennyire jól lehet a csoportokat szétválasztani a használt változók alapján.\n\n# remotes::install_github('hyunsooseol/snowCluster')\n\n\nlibrary(snowCluster)\nvallalat <- rio::import(file = \"adat/diszkriminancia_vezetesi_program.sav\")\nsnowCluster::disc(\n    data = vallalat,\n    dep = SUE,\n    covs = vars(szelköt, elégedett, rendszer),\n    gm = TRUE,\n    coef = TRUE,\n    prop = TRUE,\n    tes = TRUE,\n    plot = TRUE,\n    plot1 = TRUE,\n    plot2 = TRUE)\n\n\nstr(vallalat)\nvallalat$SUE <- factor(vallalat$SUE)\n\nlda_1 <- MASS::lda(SUE ~ szelköt + elégedett + rendszer, data = vallalat)\nlda_1\n\nman_1 <- stats::manova(cbind(szelköt, elégedett, rendszer)~SUE, data=vallalat)\nman_1\nsummary(man_1, test=\"Wilks\")\nsummary.aov(man_1)\n\nF <- 1.1057 # F próbastatisztika érték\np <- 1 # függő változók száma\nn <- 30 # mintaelemszám\nk <- 3  # a független változó csoportjainak a száma\n  \nWilks_1 <-  1 / (1 + (F * p) / (n - k - 1 - p))\nWilks_1\n\n 1 - (F / (F + 27))\n\nahol F az F-érték, df1 pedig az első szab\nanova(lm(szelköt~SUE, data=vallalat), test=\"Wilks\")\n\n\nman_1 <- manova(cbind(szelköt, elégedett, rendszer)~SUE, data=vallalat)\nsummary(man_1, test=\"Wilks\")\nsummary(man_1)\n\n\ninstall.packages(\"klaR\")\ngw_1 <- klaR::greedy.wilks(SUE ~ szelköt + elégedett + rendszer, data = vallalat, output=T)\nunclass(gw_1)\nplot(gw_1)\n\njmv::mancova(\n    data = vallalat,\n    deps = vars(szelköt, elégedett, rendszer),\n    factors = SUE,\n    multivar = \"wilks\",\n    boxM = TRUE,\n    shapiro = TRUE)\n\n??'Wilk'\nrrcov::Wilks.test(SUE ~ szelköt + elégedett + rendszer, data = vallalat)\nrrcov::Wilks.test(x = vallalat[2:4], grouping=vallalat$SUE)\n\nlibrary(klaR)\ndata(iris)\nlibrary(MASS)\niris.d <- iris[,1:4]  # the data    \niris.c <- iris[,5]    # the classes \nsc_obj <- stepclass(iris.d, iris.c, \"lda\", start.vars = \"Sepal.Width\")\nsc_obj\nplot(sc_obj)\n\n## or using formulas:\nsc_obj <- stepclass(Species ~ ., data = iris, method = \"qda\", \n    start.vars = \"Sepal.Width\", criterion = \"AS\")  # same as above \nsc_obj\n\n\ndata <- rio::import(file = \"adat/diszkriminancia_alkalmassag.xlsx\")\ndata <- rio::import(file = \"adat/diszkriminancia_baleset.xlsx\")\nsnowCluster::disc(data = data, dep = baleset, covs = vars(megosztott, pontossag,\n    kockazat, eszleles), gm = TRUE, coef = TRUE, prop = TRUE, tra = TRUE,\n    plot = TRUE, plot1 = TRUE, plot2 = TRUE)\n\n\niris\n\n\n\n\n\nsnowCluster::disc(data = iris, dep = Species, covs = vars(Sepal.Length,\n    Sepal.Width, Petal.Length, Petal.Width), gm = TRUE, coef = TRUE, prop = TRUE,\n    tra = TRUE, plot = TRUE, plot1 = TRUE, plot2 = TRUE)"
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#elméleti-háttér",
    "href": "sec_tobbvaltozos_variancia.html#elméleti-háttér",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.1 Elméleti háttér",
    "text": "9.1 Elméleti háttér\nA MANOVA a többváltozós varianciaelemzés angol megfelelőjéből képzett betűszó (Multivariate ANOVA vagy Multivariate Analysis of Variance). A szokásos ANOVA kiterjesztésének tekinthető, ahol nem egy, hanem kettő vagy több függő változóval dolgozhatunk, de a cél ugyanaz: a független változó több csoportja közötti különbségek elemzése.\nFelmerülhet bennünk, hogy ha több függő változónk van, akkor mindegyikre végezzünk el külön egy-egy hagyományos ANOVA-t, azonban ez az elsőfajú hiba emelkedéséhez vezet. A MANOVA olyan megoldást kínál, amivel több függő változó kombinált információi alapján képes kimutatni a csoportkülönbségeket.\nMivel a MANOVA egynél több függő változót használ, a null- és az ellenhipotézisek kissé megváltoznak:\n\n\\(H_0\\): A csoportok várható érték vektorai minden csoportban azonosak.\n\\(H_1\\): A csoportok várható érték vektorainak legalább egyike eltér egy másiktól."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#példa-vezetési-programok",
    "href": "sec_tobbvaltozos_variancia.html#példa-vezetési-programok",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.2 Példa: Vezetési programok",
    "text": "9.2 Példa: Vezetési programok\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer). Vizsgáljuk meg, hogy a SÜE három csoportja azonosnak tekinthető-e a vizsgált 3 kérdésre (szelkot, elegedett és rendszer) adott válaszok tekintetében.\n\nvezetes <- rio::import(file = \"adat/manova_vezetesi_program.xlsx\")\nvezetes$SUE <- factor(vezetes$SUE)\nstr(vezetes)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ SUE      : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1...\n#>  $ szelkot  : num  4 4 5 5 3 3 3 5 3 5 ...\n#>  $ elegedett: num  1 3 4 1 2 2 4 2 1 1 ...\n#>  $ rendszer : num  2 1 2 4 4 3 2 3 4 2 ...\npsych::headTail(vezetes)\n#>      SUE szelkot elegedett rendszer\n#> 1      1       4         1        2\n#> 2      1       4         3        1\n#> 3      1       5         4        2\n#> 4      1       5         1        4\n#> ... <NA>     ...       ...      ...\n#> 27     3       1         1        5\n#> 28     3       5         1        4\n#> 29     3       5         1        5\n#> 30     3       5         3        4\n\nMivel a MANOVA a három stratégiai üzleti egységben (SÜE) a kérdőívek pontszámainak (vagyis a függő változók) átlagainak különbségire kérdez rá, így készítsünk dobozdiagramot mindhárom csoportban\n\nlibrary(ggplot2)\np1 <- ggplot(vezetes, aes(x = SUE, y = szelkot, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\np2 <- ggplot(vezetes, aes(x = SUE, y = elegedett, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\np3 <- ggplot(vezetes, aes(x = SUE, y = rendszer, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\ngridExtra::grid.arrange(p1, p2, p3, nrow = 1)\n\n\n\n\nÚgy tűnik, hogy a mindhárom csoport eléggé különbözik egymástól.\nVégezzük el az egyszempontos többváltozós variancia elemzést. A manova() függvény a formula= argumentumában a kettő vagy több numerikus függő változót és legalább egy független változót vár. A függő változókat most a cbind() függvénnyel fűztük egymás mellé, a független változónk pedig a 3 szintű kategorikus SUE.\n\nman_1 <- manova(formula = cbind(szelkot, elegedett, rendszer) ~ SUE, data = vezetes)\nsummary(man_1)\n#>           Df  Pillai approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.90947   7.2278      6     52 1.211e-05 ***\n#> Residuals 27                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAlapértelmezés szerint a MANOVA az R-ben a Pillai-féle tesztstatisztikáit használja. A p-érték gyakorlatilag nulla, ami azt jelenti, hogy nyugodtan elvethetjük a nullhipotézist: legalább egy csoportátlagvektor eltér a többitől.\nHasználhat más teszteket is, mint például a Wilk-lambda, a Roy-féle vagy a Hotelling-Lawley statisztikákat, de a Pillai-féle a legrobusztosabb.\n\nsummary(man_1, test = \"Wilks\")\n#>           Df  Wilks approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.1894   10.815      6     50 1.102e-07 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(man_1, test = \"Hotelling-Lawley\")\n#>           Df Hotelling-Lawley approx F num Df den Df    Pr(>F...\n#> SUE        2           3.7577   15.031      6     48 1.375e-0...\n#> Residuals 27                                                 ...\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(man_1, test = \"Roy\")\n#>           Df    Roy approx F num Df den Df    Pr(>F)    \n#> SUE        2 3.6133   31.315      3     26 8.724e-09 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA hatásnagyság kiszámítására MANOVA esetében a parciális Eta négyzet \\((\\eta_p^2)\\) mutatót használhatjuk. Azt méri, hogy a független változó milyen hatással van a függő változókra. Ha az érték 0,14 vagy nagyobb, akkor azt mondhatjuk, hogy a hatás mérete nagy. Ez most 0,45, ami azt jelenti, hogy a hatás mérete nagy.\n\neffectsize::eta_squared(man_1, partial = T)\n#> # Effect Size for ANOVA (Type I)\n#> \n#> Parameter | Eta2 (partial) |       95% CI\n#> -----------------------------------------\n#> SUE       |           0.45 | [0.24, 1.00]\n#> \n#> - One-sided CIs: upper bound fixed at [1.00].\neffectsize::interpret_eta_squared(0.45, partial = T)\n#> [1] \"large\"\n#> (Rules: field2013)\n\nMivel a MANOVA szignifikáns lett, további kérdés, hogy melyik csoport átlagvektora különbözik a többitől? Post-hoc tesztet kell végeznünk, amely esetünkben a lineáris diszkriminancia elemzés és az egyváltozós ANOVA lesz."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#post-hoc-teszt-lda",
    "href": "sec_tobbvaltozos_variancia.html#post-hoc-teszt-lda",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.3 Post-hoc teszt: LDA",
    "text": "9.3 Post-hoc teszt: LDA\nA lineáris diszkriminancia elemzés (LDA) célja, hogy változók olyan lineáris kombinációját találja meg, amely a legjobban elválaszt két vagy több csoportot. Ezáltal képesek leszünk egy olyan pontdiagramot megjeleníteni, amely az X és Y tengely két lineáris diszkriminánst jeleníti meg, a pontokat pedig a független változónak (SUE) megfelelően fogjuk színezni.\nA lineáris diszkriminancia elemzést R-ben a {MASS} csomag lda() függvényével végzünk.\n\nlibrary(MASS)\nlda_1 <- lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\nlda_1\n#> Call:\n#> lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\n#> \n#> Prior probabilities of groups:\n#>         1         2         3 \n#> 0.3333333 0.3333333 0.3333333 \n#> \n#> Group means:\n#>   szelkot elegedett rendszer\n#> 1     4.0       2.1      2.7\n#> 2     4.7       3.4      1.5\n#> 3     4.1       1.6      4.7\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1       LD2\n#> szelkot   -0.07056752 0.4959142\n#> elegedett  0.10193972 0.8596451\n#> rendszer  -1.32360357 0.5392379\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9616 0.0384\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\nA fenti együtthatókból megtudhatjuk hogyan használják fel a függő változókat az LDA döntési szabályának kialakítására. Az LD1 a következőképpen számítható ki:\nA vezetes adatmátrix numerikus változóira magunk is kiszámolhatjuk az LD1 és LDA2 értékét a predict() függvénnyel:\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\npsych::headTail(lda_1_pred$x)\n#>       LD1   LD2\n#> 1    1.16 -1.83\n#> 2    2.69 -0.65\n#> 3    1.39  1.25\n#> 4   -1.56 -0.25\n#> ...   ...   ...\n#> 27   -2.6  -1.7\n#> 28  -1.56 -0.25\n#> 29  -2.88  0.29\n#> 30  -1.35  1.47\n\nA post-hoc teszt utolsó lépése a fenti a pontdiagram megjelenítése. Ideális esetben egy vagy több csoport kiemelkedik:\n\nd <- data.frame(lda_1_pred$x, SUE = vezetes$SUE)\npsych::headTail(d)\n#>       LD1   LD2  SUE\n#> 1    1.16 -1.83    1\n#> 2    2.69 -0.65    1\n#> 3    1.39  1.25    1\n#> 4   -1.56 -0.25    1\n#> ...   ...   ... <NA>\n#> 27   -2.6  -1.7    3\n#> 28  -1.56 -0.25    3\n#> 29  -2.88  0.29    3\n#> 30  -1.35  1.47    3\n\n\nggplot(d, aes(x = LD1, y = LD2, colour = SUE)) + geom_point(size = 4)\n\n\n\n\nA képen látható, hogy a harmadik SÜE csoport eltér mindkét másik csoporttól, míg a az első két csoport eltérése egymástól nem mondható markánsnak. Könnyen elképzelhető, hogy a SÜE harmadik csoportja volt a legnagyobb hatással a nullhipotézis elutasítására."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#post-hoc-test-egyváltozós-vizsgálatok",
    "href": "sec_tobbvaltozos_variancia.html#post-hoc-test-egyváltozós-vizsgálatok",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.4 Post-hoc test: egyváltozós vizsgálatok",
    "text": "9.4 Post-hoc test: egyváltozós vizsgálatok\nA statisztikailag szignifikáns egyszempontos MANOVA után az egyváltozós egyszempontos ANOVA-val is vizsgálódhatunk, amely minden függő változót külön-külön vizsgál. A cél az, hogy azonosítsuk azokat a konkrét függő változókat, amelyek hozzájárultak a jelentős globális hatáshoz. A klasszikus ANOVA mellett a Welch-féle változat és a Kruskal–Wallis-próba is használható, a feltételek egyre nagyobb csorbulása esetén. Most a nemparaméteres Kruskal–Wallis-próbát használjuk.\n\nkruskal.test(szelkot ~ SUE, data = vezetes)$p.value\n#> [1] 0.2499069\nkruskal.test(elegedett ~ SUE, data = vezetes)$p.value\n#> [1] 0.003003241\nkruskal.test(rendszer ~ SUE, data = vezetes)$p.value\n#> [1] 1.690362e-05\n\nLátjuk, hogy az elegedett és a rendszer függő változókban nem egyeznek a várható értékek a SÜE egyes csoportjaiban. Megjegyezzük, hogy mivel 3 függő változónk van, a Bonferroni-féle többszörös tesztelési korrekciót alkalmaznunk kell, vagyis a statisztikai szignifikancia szintet csökkenteni kell. Ez úgy történik, hogy a klasszikus alfa szintet (0,05) elosztjuk a tesztek (vagy függő változók, itt 3) számával. Ez p < 0,017-es szignifikancia elfogadási kritériumhoz vezet. A fenti próbák szignifikáns voltán ez most nem változtat.\nA statisztikailag szignifikáns egyváltozós ANOVA-t (esetünkben Kruskal–Wallis-próbát) többszörös páronkénti összehasonlítás követi annak meghatározására, hogy mely csoportok különböznek egymástól. Most a Kruskal–Wallis-próba szokásos utóvizsgálatát a Dunn-próbát fogjuk használni.\n\nlibrary(DescTools)\nDunnTest(formula = szelkot ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff   pval    \n#> 2-1            5.6 0.3179    \n#> 3-1            4.0 0.4964    \n#> 3-2           -1.6 0.6442    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDunnTest(formula = elegedett ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff   pval    \n#> 2-1           8.75 0.0410 *  \n#> 3-1          -3.80 0.3143    \n#> 3-2         -12.55 0.0027 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDunnTest(formula = rendszer ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff    pval    \n#> 2-1          -6.95  0.0694 .  \n#> 3-1          10.85  0.0092 ** \n#> 3-2          17.80 9.9e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti utóvizsgálatok világossá teszik, hogy a harmadik SÜE csoport a rendszer változó esetén mindkét másik csoporttól, az elegedett változó esetén pedig a második csoporttól szignifikánsan eltér. Legjelentősebb mértékben tehűt a harmadik csoport különül el a másik két csoporttól, tehát ez okozza a MANOVA nullhipotézisének elvetését."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#elemzés-jamovi-ban",
    "href": "sec_tobbvaltozos_variancia.html#elemzés-jamovi-ban",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.5 Elemzés jamovi-ban",
    "text": "9.5 Elemzés jamovi-ban\nA fenti elemzés jamovi-ban is elvégezhető az ANOVA / MANCOVA menüpontok kiválasztásával.\n\n\n\nMANOVA jamovi-ban"
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#alkalmazási-feltételek-vizsgálata",
    "href": "sec_tobbvaltozos_variancia.html#alkalmazási-feltételek-vizsgálata",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.6 Alkalmazási feltételek vizsgálata",
    "text": "9.6 Alkalmazási feltételek vizsgálata\nA MANOVA statisztikai próbának számos szigorú alkalmazási feltétele van. Néhány az ANOVA-ból jön, például a megfigyelések függetlensége vagy a variancia homogenitása, azonban vannak újdonságok is.\n\nMegfelelő mintanagyság. Ökölszabály: a mintaelemszám mindegyik független változó csoportban nagyobb az függő változók számánál.\n\n\nsummarytools::freq(vezetes$SUE, cumul = FALSE)\n#> Frequencies  \n#> vezetes$SUE  \n#> Type: Factor  \n#> \n#>               Freq   % Valid   % Total\n#> ----------- ------ --------- ---------\n#>           1     10     33.33     33.33\n#>           2     10     33.33     33.33\n#>           3     10     33.33     33.33\n#>        <NA>      0                0.00\n#>       Total     30    100.00    100.00\n\nLátható, hogy a függő változók számát (3) minden csoport elemszáma (10) meghaladja.\n\nA megfigyelések függetlensége. Minden személynek csak egy csoportba kell tartoznia. Az egyes csoportok megfigyelései között nincs kapcsolat. Az ismételt mérések nem megengedettek. A minta kiválasztásának teljesen véletlenszerűnek kell lennie.\nAz egyváltozós vagy többváltozós kiugró értékek hiánya.\n\nAz egydimenziós kiugró értékek dobozdiagramokkal is ellenőrizhetők, ezt korábban elvégeztük, láttuk csak egyetlen részcsoportban van kiugró értékek (a szelkot változó változó esetén a SÜE harmadik csoportjában). Használhatjuk a kényelmes rstatix::identify_outliers() függvényt is.\n\nlibrary(tidyverse)\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(szelkot)\n#> # A tibble: 2 × 6\n#>   SUE   szelkot elegedett rendszer is.outlier is.extreme\n#>   <fct>   <dbl>     <dbl>    <dbl> <lgl>      <lgl>     \n#> 1 3           1         1        5 TRUE       TRUE      \n#> 2 3           1         1        5 TRUE       TRUE\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(elegedett)\n#> [1] SUE        szelkot    elegedett  rendszer   is.outlier\n#> [6] is.extreme\n#> <0 rows> (or 0-length row.names)\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(rendszer)\n#> [1] SUE        szelkot    elegedett  rendszer   is.outlier\n#> [6] is.extreme\n#> <0 rows> (or 0-length row.names)\n\nA többváltozós kiugró értékek olyan adatpontok, amelyek szokatlan értékkombinációt tartalmaznak a kimeneti (vagy függő) változókon. A Mahalanobis távolságot általában a többváltozós kiugró értékek észlelésére használják. A távolság megmondja, milyen messze van egy megfigyelés a felhő középpontjától, figyelembe véve a felhő alakját (kovariancia) is. A rstatix::mahalanobis_distance() függvény könnyen használható a Mahalanobis-távolság kiszámítására és a többváltozós kiugró értékek megjelölésére. A Mahalanobis-távolságot csoportonként kell kiszámítani:\n\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::mahalanobis_distance() %>%\n    filter(is.outlier == TRUE) %>%\n    as.data.frame()\n#> [1] szelkot    elegedett  rendszer   mahal.dist is.outlier\n#> <0 rows> (or 0-length row.names)\n\nLátható, hogy nincs többváltozós kiugró érték az adatbázisban.\n\nTöbbváltozós normalitás.\n\nA többváltozós normalitás Shapiro-Wilk tesztjének végrehajtása:\n\nrstatix::mshapiro_test(vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")])\n#> # A tibble: 1 × 2\n#>   statistic   p.value\n#>       <dbl>     <dbl>\n#> 1     0.772 0.0000214\n\nLátható, hogy ez az alkalmazási feltétel nem teljesül.\nAz egyváltozós normalitásokat is érdemes lehet tesztelni:\n\n# egyváltozós Shapiro–Wilk próba több csoportra\nlibrary(onewaytests)\nnor.test(formula = szelkot ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : szelkot and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.7685823 6.009970e-03      Reject\n#> 2     2 0.5941735 4.713464e-05      Reject\n#> 3     3 0.5876023 3.936679e-05      Reject\n#> --------------------------------------------------\nnor.test(formula = elegedett ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : elegedett and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.8236140 2.802300e-02      Reject\n#> 2     2 0.7172415 1.425861e-03      Reject\n#> 3     3 0.5941735 4.713464e-05      Reject\n#> --------------------------------------------------\nnor.test(formula = rendszer ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : rendszer and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.8737456 1.105101e-01  Not reject\n#> 2     2 0.6552710 2.539627e-04      Reject\n#> 3     3 0.5941735 4.713464e-05      Reject\n#> --------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\nA multikollinearitás hiánya. A függő (eredmény) változók nem korrelálhatnak túlságosan egymással. Egyetlen korreláció sem lehet r = 0,90 feletti.\n\nIdeális esetben az eredményváltozók közötti korreláció mérsékelt, nem túl magas. A 0,9 feletti korreláció a multikollinearitást jelzi, ami a MANOVA esetében problematikus. Másrészt, ha a korreláció túl alacsony, fontolóra kell vennie külön egyszempontos ANOVA futtatását minden függő változóra.\nSzámítsuk ki a páronkénti Pearson-korrelációs együtthatókat a függő változók között.\n\ncor(vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")])\n#>              szelkot  elegedett   rendszer\n#> szelkot    1.0000000  0.1954881 -0.2528624\n#> elegedett  0.1954881  1.0000000 -0.6129079\n#> rendszer  -0.2528624 -0.6129079  1.0000000\n\nLátható, hogy a korrelációs együtthatók nem támogatják a multikollinearitás tényét.\n\nLinearitás az összes függő változó között minden csoportban.\n\nMivel a függő változók közötti páronkénti kapcsolatnak lineárisnak kell lennie minden csoport esetében, ezért érdemes ezt a feltételt vizuálisan ellenőrizni. A {GGally} csomag ggpairs() függvényét használhatjuk.\n\nlibrary(GGally)\nres <- vezetes %>%\n    select(SUE, szelkot, elegedett, rendszer) %>%\n    group_by(SUE) %>%\n    rstatix::doo(~ggpairs(.) + theme_bw(), result = \"plots\")\nres$plots\n#> [[1]]\n#> \n#> [[2]]\n#> \n#> [[3]]\n\n\n\n\n\n\n\n\n\n\nA fenti ábrák megkérdőjelezik a páronkénti lineáris kapcsolatok létezését.\n\nA varianciák homogenitása. A Levene-próba használható a csoportok közötti varianciák egyenlőségének tesztelésére. A Levene-próba nem szignifikáns értékei a varianciák homogenitását támogatják.\n\nAz egyszempontos MANOVA mindegyik függő változó esetében azt feltételezi, hogy a csoportok között egyenlők a varianciák.\n\nDescTools::LeveneTest(szelkot ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  2  0.9755 0.3899\n#>       27\nDescTools::LeveneTest(elegedett ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  2  0.4112  0.667\n#>       27\nDescTools::LeveneTest(rendszer ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value   Pr(>F)   \n#> group  2     5.6 0.009238 **\n#>       27                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLátható, hogy a szóráshomogenitás a rendszer változó kivételével teljesül.\n\nVariancia-kovariancia mátrixok homogenitása. A BoxM-próba használható a csoportok közötti kovariancia egyenlőségének ellenőrzésére. Ez egyenértékű a variancia többváltozós homogenitásával. Ez a teszt rendkívül érzékenynek tekinthető. Ezért ennek a tesztnek a szignifikanciáját alfa = 0,001 értéknél határozzuk meg. A {biotools} csomag megvalósított boxM() függvényét használhatjuk.\n\n\nbiotools::boxM(data = vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")], grouping = vezetes$SUE)\n#> \n#>  Box's M-test for Homogeneity of Covariance Matrices\n#> \n#> data:  vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")]\n#> Chi-Sq (approx.) = 19.607, df = 12, p-value = 0.0749\n\nA teszt statisztikailag nem szignifikáns (azaz p > 0,001), tehát az adatok nem sértették meg a variancia-kovariancia mátrixok homogenitásának feltételezését.\nKiegyensúlyozott a csoportelemszámok esetén nem probléma a variancia-kovariancia mátrixok homogenitásának megsértése miatt, de kiegyensúlyozatlan kialakításnál már problémás lehet."
  },
  {
    "objectID": "sec_logisztikus_regresszio.html",
    "href": "sec_logisztikus_regresszio.html",
    "title": "10  Logisztikus regresszió",
    "section": "",
    "text": "A logisztikus regresszió céljait tekintve megegyezik a diszkriminancia elemzéssel, de sokkal robusztusabb, azaz kevesebb alkalmazási feltétellel rendelkezik. Használható a logisztikus regresszió akkor is, ha a független változók között kategorikus változók is előfordulnak, illetve a normalitásra és homoszkedaszticitásra vonatkozó feltétel megsértésre sem érzékeny a módszer.\nJÖN."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html",
    "href": "sec_tobbdimenzios_skalazas.html",
    "title": "11  Többdimenziós skálázás",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "appendix_linkek.html",
    "href": "appendix_linkek.html",
    "title": "Appendix A — Elérhető videók",
    "section": "",
    "text": "Alapozo jamovi és R videók\n\nJamovi a gyakorlatban\nR a gyakorlatban\n\nJamovi tutorial videók az összes tanult eljáráshoz\n\ndatalab.cc\nAlexander Swan\n\nLineáris regresszió\n\nThe linear regression model\nLinear Regression, Clearly Explained\nR-squared, Clearly Explained\nSimple linear regression in Jamovi\n\nFőkomponens elemzés\n\nPrincipal Component Analysis (PCA)\n\nKlaszterelemzés\n\nFlat and Hierarchical Clustering | The Dendrogram Explained\nK Means Clustering: Pros and Cons of K Means Clustering\nHierarchical Cluster analysis in Jamovi\nK Means Cluster analysis in Jamovi\n\nTöbbszempontos varianciaelemzés\n\nOne Way ANOVA Post hoc test in Jamovi\nOne Way Repeated Measure ANOVA Repeated Measure ANOVA Within Subject ANOVA in Jamovi\nTwo Way ANOVA Post hoc test in Jamovi\nThree Way ANOVA Post hoc test in Jamovi"
  },
  {
    "objectID": "appendix_adatbazisok.html#megbízhatóság-elemzés",
    "href": "appendix_adatbazisok.html#megbízhatóság-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.1 Megbízhatóság elemzés",
    "text": "B.1 Megbízhatóság elemzés\n\nmegbizhatosag_tantargyak.xlsx - fiktív adatbázis 9 tanuló iskolai jegyeivel (Münnich és mtsai. (2006), 2.2. táblázat)\n\nAz adatbázis szerkezete:\n\nmatek - matematika érdemjegy (numerikus: 1-5)\nfizika - fizika érdemjegy (numerikus: 1-5)\ninformatika - informatika érdemjegy (numerikus: 1-5)\nkemia - kémia érdemjegy (numerikus: 1-5)\n\nKapcsolódó állományok:\n\nmegbizhatosag_tantargyak.omv - megbízhatóság elemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#többváltozós-varianciaelemzés",
    "href": "appendix_adatbazisok.html#többváltozós-varianciaelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.2 Többváltozós varianciaelemzés",
    "text": "B.2 Többváltozós varianciaelemzés\n\nmanova_vezetesi_program.xlsx - A szervezeti elkötelezettség, a szervezeti kultúra és az elégedettség eltér a vállalat 3 különböző vezetési irányelvét valló egységében? Az adatbázis Sajtos és Mitev (2007, o. 332) könyvéből származik.\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nAz adatbázis szerkezete:\n\nSUE - a három különböző vezetési irányelvet követő stratégiai üzleti egység (nominális: 1-3)\nszelkot - szervezet elkötelezettség mértéke (likert: 1-5)\nelegedett - szervezettel való elégedettség (likert: 1-5)\nrendszer - szervezet tekintélyelvű jellege (likert: 1-5)\n\nKapcsolódó állományok:\n\nmanova_vezetesi_program.omv - Többváltozós varianciaelemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#diszkriminancia-elemzés",
    "href": "appendix_adatbazisok.html#diszkriminancia-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.3 Diszkriminancia elemzés",
    "text": "B.3 Diszkriminancia elemzés\n\ndiszkriminancia_alkalmassag.xlsx - szalagmunkások adatai (Münnich és mtsai. (2006), 4.1. táblázat)\n\nAz adatbázis szerkezete:\n\nbevalt - a munkás beválásával kapcsolatos információ: bevált? (nominális: “igen”, “nem”)\nfigyelem - a munkás figyelmi képessége (likert: 1-7, a magasabb érték jobb képességeket jelent)\nmonotonia_tures - a munkás monotónia tűrése (likert: 1-7, a magasabb érték jobb képességeket jelent)\n\n\ndiszkriminancia_baleset.xlsx - mely tényezők járulnak hozzá a balesetekhez (Münnich és mtsai. (2006), 4.11. R-forráskód)\n\nAz adatbázis szerkezete:\n\nbaleset - volt már balesete a személynek vagy sem (nominális “nem volt balesete”, “volt baleste”)\nmegosztott - megosztott figyelem (intervallum/arány)\npontossag - a figyelem pontossága (intervallum/arány)\nkockazat - kockázatvállalási hajlandóság (intervallum/arány)\neszleles - észlelés gyorsasága (intervallum/arány)\n\n\ndiszkriminancia_depresszio.xlsx - a postpartum depresszió pszichés és szociális háttere (Münnich és mtsai. (2006), 4.16. R-forráskód)\n\nAz adatbázis szerkezete:\n\nppdepresszio - szülés utáni depresszió jelenléte (nominális: “nincs depresszió”, “van depresszió”)\nszeretet - a személyek mennyire érzik, hogy a szüleik szeretik őket (intervallum/arány)\ntulvedes - mennyire hajlamosak arra a személyek, hogy túlságosan is burokban tartsák, túlvédjék gyerekeiket (intervallum/arány)\nkor - életkor (intervallum/arány)\niskola - az elvégzett iskolai osztályok száma (intervallum/arány)\n\n\ndiszkriminancia_pszichoszomatika.xlsx - a pszichoszomatikus megbetegedéseket vizsgálata (Münnich és mtsai. (2006), 4.21. R-forráskód)\n\nAz adatbázis szerkezete:\n\npszichoszomatika - van valamilyen pszichoszomatikus megbetegedése a személynek? (nominális: “szichoszomatikus megbetegedése van”, ” egészséges”)\nstressz - a személyt ért stressz mértéke (intervallum/arány)\nszorongas - a szorongási szintje (intervallum/arány)\ncoping - a megküzdési stratégiáinak hatékonysága (intervallum/arány)\n\n\ndiszkriminancia_bio.xlsx - kik vásárolnak bio termékeket (Münnich és mtsai. (2006), 4.26. R-forráskód)\n\nAz adatbázis szerkezete:\n\nvasarlas - a biotermékek vásárlásának gyakorisága (ordinális: “soha nem vesz”, “időnként vesz”, “gyakran vesz”)\nertek - minél nagyobb pontszámot kap a skálán, annál jobban értékeli a személy a bio termékeket (intervallum/arány)\nattitud - a magasabb értékek kedvezőbb atttitűdöt jelez a biotermékek iránt (intervallum/arány)\nfizetes - a személy fizetésének nagysága (intervallum/arány)\nkor - a személy életkora(intervallum/arány)\n\n\ndiszkriminancia_vezetesi_program.xlsx - A szervezeti elkötelezettség, a szervezeti kultúra és az elégedettség alapján szétválasztható a vállalat 3 különböző vezetési irányelvét valló egysége? Az adatbázis Sajtos és Mitev (2007, o. 332) könyvéből származik.\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nAz adatbázis szerkezete:\n\nSUE - a három különböző vezetési irányelvet követő stratégiai üzleti egység (nominális: 1-3)\nszelkot - szervezet elkötelezettség mértéke (likert: 1-5)\nelegedett - szervezettel való elégedettség (likert: 1-5)\nrendszer - szervezet tekintélyelvű jellege (likert: 1-5)\n\nKapcsolódó állományok:\n\ndiszkriminancia_vezetesi_program.omv - diszkriminancia elemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#lineáris-regresszió",
    "href": "appendix_adatbazisok.html#lineáris-regresszió",
    "title": "Appendix B — Adatbázisok",
    "section": "B.4 Lineáris regresszió",
    "text": "B.4 Lineáris regresszió\n\nlin_reg_fizetes_elegedettseg_01.omv - konstans oszlopokkal nem tudunk számolni (Münnich és mtsai. (2006) 1.1/A táblázat)\nlin_reg_fizetes_elegedettseg_02.omv- az adatpontok szinte tökéletesen az egyenesre illeszkednek (Münnich és mtsai. (2006) 1.1/B táblázat)\nlin_reg_kapcsolatok_01.omv - nem szisztematikus kapcsolat két változó között (Münnich és mtsai. (2006) 1.5. R-forráskód)\nlin_reg_kapcsolatok_02.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.6. R-forráskód)\nlin_reg_kapcsolatok_03.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.7. R-forráskód)\nlin_reg_kapcsolatok_04.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.8. R-forráskód)\nlin_reg_kapcsolatok_05.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.9. R-forráskód)\nlin_reg_elegedttseg.omv - a fizetés és a munkahellyel való elégedettség pontdiagramja, egyszerű lineáris regresszió (Münnich és mtsai. (2006) 1.10 R-forráskód)\nlin_reg_fizetes_eletkor_eledettseg_01.omv - többszörös lineáris regresszió, 2 numerikus magyarázó változó (Münnich és mtsai. (2006) 1.2. táblázat)\nlin_reg_intelligencia_testmagassag_eletkor_01.omv - többszörös lineáris regresszió, 2 numerikus magyarázó változó, parciális korreláció magyarázata\n\nminél magasabb valaki, annál intelligensebb\nha bevonjuk az életkor változót, akkor eltűnik az intelligencia és a testmagasság közötti kapcsolat\n\nlin_tizproba.omv - többszörös lineáris regresszió, a legjobb modell keresése, sok numerikus magyarázó változó\nlin_college_success_02.omv - többszörös lineáris regresszió, sok numerikus magyarázó változó, GPA a függő változó, mi magyarázza az egyetemi teljesítményt\nlin_reg_elegedttseg_02.omv - A férfiak vagy a nők elégedettebbek a munkahelyükkel? (Münnich és mtsai. (2006) 1.6.3 probléma), egyetlen kategorikus magyarázó változó 2 értékkel (nem: férfi, nő)\n\nkapcsolat a kétmintás t-próbával\n\nlin_reg_magassag_hajhossz_nem_01.omv - többszörös lineáris regresszió, parciális korreláció 1 numerikus és 1 kategorikus változóval (Münnich és mtsai. (2006) 1.2. táblázat)\n\na testmagasság és a hajhossz között kapcsolat van\nha a személyek nemét is figyelembe vesszük, egyáltalán nincs kapcsolat a testmagasság és a hajhosszúság között\n\nlin_auction.omv - többszörös lineáris regresszió, Simpson paradoxon, párhuzamos regresszió, majd interakció bevonása."
  },
  {
    "objectID": "appendix_adatbazisok.html#főkomponens-elemzés",
    "href": "appendix_adatbazisok.html#főkomponens-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.5 Főkomponens elemzés",
    "text": "B.5 Főkomponens elemzés\n\nfokomp_elemzes_tantargyak.omv - 1 főkomponens létrehozása (Münnich és mtsai. (2006) 2.2. táblázat)\nfokomp_real_targyak.omv - példa kidolgozása, 1 főkomponens(Münnich és mtsai. (2006) 2.5.1 Probléma)\nfokomp_kerdoivtervezet.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.2 Probléma)\nfokomp_munkahelyi_tolarencia.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.3 Probléma)\nfokomp_munkahelyi_elegedettseg.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.4 Probléma)"
  },
  {
    "objectID": "appendix_adatbazisok.html#faktorelemzés",
    "href": "appendix_adatbazisok.html#faktorelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.6 Faktorelemzés",
    "text": "B.6 Faktorelemzés\n\nfaktor_szorongas.omv - példa (Münnich és mtsai. (2006) 3.1. R-forráskód)\nfaktor_real_human_targyak.omv - példa (Münnich és mtsai. (2006) 3.9. R-forráskód)\nfaktor_bigfive.omv - példa (Münnich és mtsai. (2006) 3.21. R-forráskód)\nfaktor_kockazat.omv - példa (Münnich és mtsai. (2006) 3.7.4 Probléma)\nfaktor_fogkrem.omv - példa (Malhotra és Simon (2008) 617. oldal)\n\n\n\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési kézikönyv. Alinea Kiadó."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Appendix C — Irodalomjegyzék",
    "section": "",
    "text": "Carver, C. S. és Scheier, M. F. (2006).\nSzemélyiségpszichológia. Osiris Kiadó.\n\n\nCsallner, A. E. (2015). Bevezetés az SPSS statisztikai programcsomag\nhasználatába. http://www.jgypk.hu/tamop15e/tananyag_html/spss/index.html\n\n\nHorn, J. L. (1965). A rationale and test for the number of factors in\nfactor analysis. Psychometrika, 30, 179–185. https://doi.org/10.1007/BF02289447\n\n\nKárász, J. T., Nagy, O. N., Széll, K. és Takács, S. (2022).\nCronbach-alfa: vele vagy nélküle? Magyar Pszichológiai Szemle,\n77, 81–98. https://doi.org/10.1556/0016.2022.00004\n\n\nKetskeméty, L. és Izsó, L. (2005). Bevezetés az SPSS\nprogramrendszerbe - Módszertani útmutató és feladatgyűjtemény\nstatisztikai elemzésekhez. ELTE Eötvös Kiadó.\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás.\nAkadémiai Kiadó.\n\n\nMalkewitz, C. P., Schwall, P., Meesters, C. és Hardt, J. (2023).\nEstimating reliability: A comparison of Cronbach’s α, McDonald’s ωt and\nthe greatest lower bound. Social Sciences & Humanities\nOpen, 7, 100368. https://doi.org/10.1016/j.ssaho.2022.100368\n\n\nMoksony, F. (2006). Gondolatok és adatok. Társadalomtudományi\nelméletek empirikus ellenőrzése. Aula Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika\npszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nNagy, O. N. (2006). A pszichológiai tesztek reliabilitása. In S. Rózsa,\nO. N. Nagy, és A. Oláh (Szerk.), A pszichológiai mérés alapjai.\nElmélet, módszer és gyakorlati alkalmazás. Bölcsész Konzorcium. https://mek.oszk.hu/05500/05536/05536.pdf\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési\nkézikönyv. Alinea Kiadó.\n\n\nSzékelyi, M. és Barna, I. (2002). Túlélőkészlet az SPSS-hez.\nTöbbváltozós elemzési technikáról társadalomkutatók számára.\nTypotex Kiadó.\n\n\nTakács, S. (2017). Bevezetés a matematikai statisztikába 2.\nTöbbváltozós statisztikai módszerek. Antarész Kiadó.\n\n\nVarga, A. (2019). Többváltozós statisztika dióhéjban:\nVáltozó-orientált módszerek. Pólya Kiadó."
  }
]