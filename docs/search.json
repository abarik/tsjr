[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Többváltozós statisztika jamovi-ban és R-ben",
    "section": "",
    "text": "Előszó\nA statisztika alapfogalmai nagyon jól szemléltethetők az egyváltozós statisztikai eljárásokkal. Ezek az eljárások tipikusan egy (vagy két) változó vizsgálatával járulnak hozzá az empirikus vizsgálatok során felmerülő statisztikai jellegű kérdések megválaszolásához.\nA kutatómunka során azonban szükség lehet egyszerre több változó bevonására az elemzésbe, ezeket az eljárásokat többváltozós statisztikai eljárásoknak nevezzük. Ilyen eljárás például:\n\nLineáris regresszió (1)\nFőkomponens elemzés (2)\nMegbízhatóság elemzés (3)\nFeltáró faktorelemzés (4)\nMegerősítő faktorelemzés (5)\nTöbbszempontos varianciaelemzés (6)\nKlaszterelemzés (7)\nDiszkriminancia elemzés (8)\nTöbbváltozós varianciaelemzés (9)\nLogisztikus regresszióelemzés (10)\nTöbbdimenziós skálázás (11)\n\nA jegyzet elkészítéséhez elsősorban a kurzus tankönyvét (Münnich és mtsai., 2006) használtuk fel, de támaszkodtunk egyéb forrásokra is (Csallner, 2015; Ketskeméty és Izsó, 2005; Malhotra és Simon, 2008; Moksony, 2006; Sajtos és Mitev, 2007; Székelyi és Barna, 2002; Takács, 2017; Varga, 2019).\n\n\n\n\nCsallner, A. E. (2015). Bevezetés az SPSS statisztikai programcsomag használatába. http://www.jgypk.hu/tamop15e/tananyag_html/spss/index.html\n\n\nKetskeméty, L. és Izsó, L. (2005). Bevezetés az SPSS programrendszerbe - Módszertani útmutató és feladatgyűjtemény statisztikai elemzésekhez. ELTE Eötvös Kiadó.\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó.\n\n\nMoksony, F. (2006). Gondolatok és adatok. Társadalomtudományi elméletek empirikus ellenőrzése. Aula Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési kézikönyv. Alinea Kiadó.\n\n\nSzékelyi, M. és Barna, I. (2002). Túlélőkészlet az SPSS-hez. Többváltozós elemzési technikáról társadalomkutatók számára. Typotex Kiadó.\n\n\nTakács, S. (2017). Bevezetés a matematikai statisztikába 2. Többváltozós statisztikai módszerek. Antarész Kiadó.\n\n\nVarga, A. (2019). Többváltozós statisztika dióhéjban: Változó-orientált módszerek. Pólya Kiadó."
  },
  {
    "objectID": "sec_linearis_regresszio.html#egyszerű-lineáris-regresszió",
    "href": "sec_linearis_regresszio.html#egyszerű-lineáris-regresszió",
    "title": "1  Lineáris regresszió",
    "section": "1.1 Egyszerű lineáris regresszió",
    "text": "1.1 Egyszerű lineáris regresszió\nAz egyszerű lineáris regressziós modell: \\(Y=\\beta_0+β_1 X+\\epsilon\\), amely egy egyenessel (regressziós egyenes) írja le a két változó függvényszerű kapcsolatát, ahol\n\n\\(\\beta_0\\) – tengelymeszet, a regressziós egyenes itt metszi az y tengelyt\n\\(\\beta_1\\) – meredekség, a regressziós egyenes és az x tengely szögének tangense\n\\(\\epsilon\\) – hibatag, amelyről feltételezzük, hogy normális eloszlású 0 várható értékkel.\n\nA \\(\\beta_0\\) és \\(\\beta_1\\) populációbeli paramétereket a minta alapján becsüljük a legkisebb négyzetek módszere segítségével, így kapjuk a \\(b_0\\) és \\(b_1\\) becsléseket.\nA regressziós egyenes birtokában tetszőleges \\(X\\) értékhez tudunk \\(Y\\) értéket előre jelezni, vagyis jósolni bizonyos hibával: \\(\\hat{Y}=b_0+b_1 X\\).\nPéldául egy fiktív adatbázison vizsgálhatjuk a fizetés és a munkahellyel való elégedettség kapcsolatát (Münnich és mtsai., 2006).\n\nd <- rio::import(file = \"adat/lin_reg_fizetes_elegedettseg_02.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  2 variables:\n#>  $ fizetes     : num  44 66 89 155 130\n#>  $ elegedettseg: num  30 45 60 100 85\nd\n#>   fizetes elegedettseg\n#> 1      44           30\n#> 2      66           45\n#> 3      89           60\n#> 4     155          100\n#> 5     130           85\n\n\nlm_1 <- lm(elegedettseg ~ fizetes, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes, data = d)\n#> \n#> Residuals:\n#>       1       2       3       4       5 \n#> -0.8423  0.3420  0.8983 -0.5488  0.1508 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3.210890   0.931791   3.446   0.0411 *  \n#> fizetes     0.627987   0.008873  70.774 6.22e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8077 on 3 degrees of freedom\n#> Multiple R-squared:  0.9994, Adjusted R-squared:  0.9992 \n#> F-statistic:  5009 on 1 and 3 DF,  p-value: 6.216e-06\n\nJamovi-ban a Regression / Linear Regression menüpontot kell használnunk.\n\n\n\nFizetés és elégedettésg kapcsolata (N=5): együtthatók\n\n\nA fenti elemzés alapján például a \\(\\hat{Y}=b_0+b_1 X\\) konkrét formája:\nbecsült elégedettség = 3,211+ 0,628 * fizetés\n\nA \\(b_0\\) értelmezése: a zérus \\(X\\)-hez tartozó \\(Y\\) érték.\nA \\(b_1\\) értelmezése: az \\(X\\) egy egységnyi növekedéséhez ilyen nagyságú \\(Y\\) változás tartozik.\n\nTudjuk, hogy az \\(r_{XY}\\) Pearson-féle korrelációs együttható, az \\(X\\) és \\(Y\\) változók közötti kapcsolat erősségét és irányát mutatja meg. A \\(b_1\\) és \\(r_{XY}\\) kapcsolatban áll:\n\nazonos az előjelük,\naz \\(X\\) egy szórásnyi növekedéséhez tartozó \\(Y\\) változás megegyezik az \\(Y\\) szórásának \\(r_{XY}\\) szeresével (rövidebben, a populációbeli paraméterekkel megfogalmazva: \\(\\beta_1=\\frac{\\sigma_Y}{\\sigma_X}\\rho_{XY}\\)\n\nA determinációs együttható (\\(R^2\\)) a korrelációs együttható négyzete \\((R^2=r_{XY}^2)\\), amely szimmetrikus mutató, megmutatja, hogy \\(Y\\) varianciájának mekkora hányadát magyarázza \\(X\\) varianciája, vagy fordítva, \\(X\\) varianciájának mekkora hányadát magyarázza \\(Y\\) varianciája.\nA fenti példában látható, hogy 99%-ban lehet a függő változó varianciáját magyarázni a független változóval (az arányt legtöbbször százalékos formában adjuk meg).\n\nsummary(lm_1)$r.squared\n#> [1] 0.9994014\n\n\n\n\nFizetés és elégedettésg kapcsolata (N=5): determinációs együttható\n\n\nA \\(\\beta_0\\) és \\(\\beta_1\\) együtthatók értékét hipotézisvizsgálatokkal vizsgálhatjuk:\n\n\\(H_0\\): \\(\\beta_0=0\\), \\(H_1: \\beta_0 \\neq 0\\) Kérdés: origón átmenő a regresszió? (\\(H_0\\) megtartása esetén igen)\n\\(H_0\\): \\(\\beta_1=0\\), \\(H_1: \\beta_1 \\neq 0\\) Kérdés: \\(Y\\) függ \\(X\\)-től? (\\(H_1\\) elfogadása esetén igen)\n\nA példában látható, hogy nem origón átmenő a regresszió, és az elégedettség függ a fizetéstől.\n\nsummary(lm_1)$coefficients\n#>              Estimate  Std. Error   t value     Pr(>|t|)\n#> (Intercept) 3.2108896 0.931790852  3.445934 4.105805e-02\n#> fizetes     0.6279867 0.008873152 70.773796 6.216433e-06\n\n\n\n\nFizetés és elégedettésg kapcsolata (N=5): hipotézisvizsgálat az együtthatókra"
  },
  {
    "objectID": "sec_linearis_regresszio.html#többszörös-lineáris-regresszió",
    "href": "sec_linearis_regresszio.html#többszörös-lineáris-regresszió",
    "title": "1  Lineáris regresszió",
    "section": "1.2 Többszörös lineáris regresszió",
    "text": "1.2 Többszörös lineáris regresszió\nA többszörös lineáris regressziós modell: \\(Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\dots + \\beta_r X_r+\\epsilon\\).\nMíg az egyszerű lineáris regresszió esetén a regressziós egyenes írta le a két változó kapcsolatát, a többszörös lineáris regresszió esetén a lineáris függvény egy \\(r\\) dimenziós sík az \\(r+1\\) dimenziós térben.\nAz egyes \\(\\beta_i\\) együtthatók becslése itt is a legkisebb négyzetek elve alapján történik, így kapjuk a \\(b_0, b_1, \\dots, b_r\\) becsléseket.\nA lineáris függvény birtokában tetszőleges \\(X_1,X_2,\\dots,X_r\\) értékekhez tudunk \\(Y\\) értéket előre jelezni, vagyis jósolni bizonyos hibával: \\(\\hat{Y}=b_0+b_1 X_1+\\dots+ b_r X_r\\).\n\nd <- rio::import(file = \"adat/lin_reg_fizetes_eletkor_elegedettseg_01.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  3 variables:\n#>  $ fizetes     : num  44 66 89 155 130\n#>  $ eletkor     : num  25 65 21 35 40\n#>  $ elegedettseg: num  37 36 61 92 76\nd\n#>   fizetes eletkor elegedettseg\n#> 1      44      25           37\n#> 2      66      65           36\n#> 3      89      21           61\n#> 4     155      35           92\n#> 5     130      40           76\n\n\nlm_1 <- lm(elegedettseg ~ fizetes + eletkor, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes + eletkor, data = d)\n#> \n#> Residuals:\n#>        1        2        3        4        5 \n#>  0.28596  0.08556 -0.30015  0.71047 -0.78184 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 21.508055   1.292166   16.64  0.00359 ** \n#> fizetes      0.519198   0.008847   58.69  0.00029 ***\n#> eletkor     -0.305549   0.023279  -13.12  0.00575 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8047 on 2 degrees of freedom\n#> Multiple R-squared:  0.9995, Adjusted R-squared:  0.9989 \n#> F-statistic:  1841 on 2 and 2 DF,  p-value: 0.000543\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): együtthatók\n\n\nA fenti példában a lineáris regresszió futtatása után azt mondhatjuk:\nbecsült elégedettség = 21,05 -0,306*életkor + 0,519*fizetés\nMás szavakkal a fizetés tekintetében a magasabb fizetés nagyobb mértékű elégedettséggel jár, addig az életkor esetében az évek számának növekedése a munkahellyel való elégedetlenséget vonja maga után.\n\nA \\(b_0\\) értelmezése: a csupa zérus \\(X_1, X_2,\\dots,X_r\\)-ekhez tartozó \\(Y\\) érték.\nA \\(b_i\\) \\((i=1,\\dots,r)\\) értelmezése: az \\(X_i\\) hatása úgy, hogy a többi független változót is figyelembe vesszük.\n\nA fenti többszörös lineáris regressziós együtthatók nem alkalmasak az egyes magyarázó változóktól való függés erősségének mérésére, ugyanis a nagyságuk függ a változó értékeinek nagyságától is. Ezért a standard lineáris regressziós együtthatókat használjuk, amelyek már mértékegység nélküli, egymással összehasonlítható arányszámok, így abszolút értékeiket összevetve megtudhatjuk, milyen relatív fontossággal bírnak az egyes független változók a függő változó magyarázásában.\n\nlsr::standardCoefs(lm_1)\n#>                  b       beta\n#> fizetes  0.5191980  0.9677518\n#> eletkor -0.3055489 -0.2164358\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): standardizált együtthatók\n\n\nA fenti példában láthatjuk, hogy a fizetés erősebb kapcsolatban van az elégedettséggel, hiszen a standardizált együtthatójának értéke abszolút értékben nagyobb, mint az életkor standardizált együtthatójának abszolút értéke.\nTöbbszörös lineáris regresszió esetén több hipotézisvizsgálat végezhető:\n\nminden együtthatót külön tesztelhetünk t-próbákkal \\((n-r-1)\\) szabadsági fokkal\n\n\\(H_0:\\beta_i=0\\), \\(H_1:\\beta_i\\neq0\\), \\(i=1,\\dots,r\\) Kérdés: \\(Y\\) függ \\(X_i\\)-től? (\\(H_1\\) elfogadása esetén igen)\n\na teljes modellt tesztelhetjük F-próbával \\((r,n-r-1)\\) szabadsági fokkal\n\n\\(H_0: \\text{minden } \\beta_i=0\\), \\(H_1: \\text{van olyan i, melyre } \\beta_i\\neq0\\) Kérdés: a modell bír valamilyen bejósló erővel? (\\(H_1\\) elfogadása esetén igen)\n\n\n\nsummary(lm_1)$coefficients\n#>               Estimate Std. Error   t value     Pr(>|t|)\n#> (Intercept) 21.5080549 1.29216584  16.64496 0.0035899688\n#> fizetes      0.5191980 0.00884672  58.68819 0.0002902081\n#> eletkor     -0.3055489 0.02327903 -13.12550 0.0057544940\nsummary(lm_1)$fstatistic\n#>    value    numdf    dendf \n#> 1840.547    2.000    2.000\npf(q = summary(lm_1)$fstatistic[1], df1 = summary(lm_1)$fstatistic[2],\n    df2 = summary(lm_1)$fstatistic[3], lower.tail = F)\n#>        value \n#> 0.0005430217\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): hipotézisvizsgálatok\n\n\nA lenti példában látható, hogy mindkét magyarázó változótól függ az elégedettség (életkor p-értéke: 0,006, a fizetés p-értéke p < 0,001), és a teljes modell bír magyarázó erővel (p-érték: p < 0,001).\nA függő változó és a független változók közötti korreláció erősségének leírására több mennyiséget használhatunk\n\ntöbbszörös korrelációs együttható: \\(R\\), amely a függő változó és a becsült értékek közötti korrelációs együttható értékével egyezik meg, azaz \\(R(Y,X_1,X_2,…,X_r )=R(Y,\\hat{Y})\\). Valójában a lineáris regresszió ennek a korrelációs együtthatónak az értékét maximalizálja, mikor az \\(\\hat{Y}\\)-t \\(X\\)-ek speciális lineáris kombinációjaként előállítja.\ntöbbszörös determinációs együttható: \\(R^2\\), amely a többszörös korrelációs együttható négyzete, és megmutatja, hogy a magyarázó változók a függő változó ingadozásának hányad részét magyarázzák.\nkorrigált determinációs együttható: \\(R_{adj}^2\\), amely kiküszöböli az \\(R^2\\) azon tulajdonságát, hogy a magyarázó változók számának növekedésével, függetlenül azok hatásától, nő az értéke. Így alkalmas több modell esetén a magyarázó erők összehasonlítására, akkor is, ha azok eltérő számú független változót használnak.\n\n\nsummary(lm_1)$r.squared\n#> [1] 0.999457\nsummary(lm_1)$adj.r.squared\n#> [1] 0.998914\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): magyarázó erő\n\n\nA fenti példában látható mindhárom fenti mutató. Az \\(R_{adj}^2\\) leolvasásával láthatjuk, hogy a két független változó, az életkor és a fizetés a függő változó 99%-át magyarázza."
  },
  {
    "objectID": "sec_linearis_regresszio.html#parciális-korrelációs-együttható",
    "href": "sec_linearis_regresszio.html#parciális-korrelációs-együttható",
    "title": "1  Lineáris regresszió",
    "section": "1.3 Parciális korrelációs együttható",
    "text": "1.3 Parciális korrelációs együttható\nParciális korrelációs együttható: két változó (\\(S_1,S_2\\)) közötti korreláció mértéke, miután változók egy halmazának \\((T_1,T_2,\\dots,T_g)\\) a két változó korrelációjára vonatkozó hatását többszörös lineáris regresszióval kiküszöböljük:\n\n\\(R( S_1,S_2 |T_1,T_2,\\dots,T_g )= R(S_1- \\hat{S_1},S_2- \\hat{S_2})\\), ahol \\(\\hat{S_1}\\) és \\(\\hat{S_2}\\) az \\(S_1\\) és \\(S_2\\) változó többszörös lineáris regresszióból származó becslése a \\(T_1,T_2,\\dots,T_g\\) magyarázó változók esetén.\n\n\nd <- rio::import(file = \"adat/lin_reg_intelligencia_testmagassag_eletkor_01.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  3 variables:\n#>  $ intelligencia: num  81 86 91 101 111\n#>  $ testmagassag : num  138 145 156 163 167\n#>  $ eletkor      : num  9 12 14 18 22\nd\n#>   intelligencia testmagassag eletkor\n#> 1            81          138       9\n#> 2            86          145      12\n#> 3            91          156      14\n#> 4           101          163      18\n#> 5           111          167      22\n\n\ncor.test(d$intelligencia, d$testmagassag)\n#> \n#>  Pearson's product-moment correlation\n#> \n#> data:  d$intelligencia and d$testmagassag\n#> t = 5.4629, df = 3, p-value = 0.01205\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  0.4463631 0.9970093\n#> sample estimates:\n#>      cor \n#> 0.953235\nRcmdrMisc::partial.cor(d, tests = T)\n#> \n#>  Partial correlations:\n#>               intelligencia testmagassag eletkor\n#> intelligencia       0.00000     -0.46317 0.97875\n#> testmagassag       -0.46317      0.00000 0.62856\n#> eletkor             0.97875      0.62856 0.00000\n#> \n#>  Number of observations: 5 \n#> \n#>  Pairwise two-sided p-values:\n#>               intelligencia testmagassag eletkor\n#> intelligencia               0.5368       0.0213 \n#> testmagassag  0.5368                     0.3714 \n#> eletkor       0.0213        0.3714              \n#> \n#>  Adjusted p-values (Holm's method)\n#>               intelligencia testmagassag eletkor\n#> intelligencia               0.7429       0.0638 \n#> testmagassag  0.7429                     0.7429 \n#> eletkor       0.0638        0.7429\n\n A fenti példában látható, hogy míg szignifikáns erős pozitív kapcsolat van az intelligencia és a magasság között (korrelációs együttható: \\(r=0,95; p=0,012\\)), ez a kapcsolat eltűnik, ha figyelembe vesszük az életkor változót is (parciális korreláció: \\(r_{par}=-0,46; p=0,537\\)). Vagyis sikerült az intelligencia és a testmagasság közötti kapcsolat erősségét megállapítani, miközben az életkor hatását erre a kapcsolatra kiküszöböltük.\nA többszörös lineáris regressziós modell \\((Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\dots+\\beta_r X_r+\\epsilon)\\) becsült paraméterei \\((b_1,b_2,…,b_r)\\) nagyban hasonlítanak a parciális korrelációs együtthatókra, mivel minden \\(b_i\\) az \\(Y\\) és \\(X_i\\) közötti kapcsolat erősségét írja le, miközben a többi magyarázó változó (\\(X_1,X_2,\\dots,X_r\\), összesen \\((r-1)\\) db, \\(X_i\\) nincs köztük) hatását kiküszöböljük a két változó korrelációjából.\nA parciális korrelációs együtthatók és a többszörös lineáris regresszió együtthatói között annyira közvetlen a kapcsolat, hogy azonos p-érték tartozik hozzájuk, mint a lenti példában ez látható is lesz.\nA lenti példában két modell szerepel, először az intelligencia és a testmagasság függvényszerű kapcsolatát vizsgáljuk és azt a meglepő dolgot tapasztaljuk, hogy minél magasabb valaki, annál intelligensebb \\((p=0,012)\\), majd ha bevonjuk az életkor változót, akkor azt tapasztalhatjuk, hogy eltűnik az intelligencia és a testmagasság közötti kapcsolat \\((p=0,537)\\).\n\nlm_1 <- lm(intelligencia ~ testmagassag, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = intelligencia ~ testmagassag, data = d)\n#> \n#> Residuals:\n#>       1       2       3       4       5 \n#>  1.9228  0.3114 -5.0779 -1.6892  4.5328 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)  \n#> (Intercept)  -51.2613    26.6569  -1.923   0.1502  \n#> testmagassag   0.9445     0.1729   5.463   0.0121 *\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 4.202 on 3 degrees of freedom\n#> Multiple R-squared:  0.9087, Adjusted R-squared:  0.8782 \n#> F-statistic: 29.84 on 1 and 3 DF,  p-value: 0.01205\nlm_2 <- lm(intelligencia ~ testmagassag + eletkor, data = d)\nsummary(lm_2)\n#> \n#> Call:\n#> lm(formula = intelligencia ~ testmagassag + eletkor, data = d)\n#> \n#> Residuals:\n#>        1        2        3        4        5 \n#>  0.89121 -1.16330 -0.09995  0.21170  0.16034 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)  \n#> (Intercept)   73.1026    19.6042   3.729   0.0650 .\n#> testmagassag  -0.1210     0.1637  -0.739   0.5368  \n#> eletkor        2.6338     0.3902   6.750   0.0213 *\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.055 on 2 degrees of freedom\n#> Multiple R-squared:  0.9962, Adjusted R-squared:  0.9923 \n#> F-statistic: 259.3 on 2 and 2 DF,  p-value: 0.003841\n\n\n\n\nAz intelligencia és a testmagasság kapcsolata (N=5): két modell, életkor nélkül és életkorral"
  },
  {
    "objectID": "sec_linearis_regresszio.html#a-többszörös-lineáris-regresszió-esetei",
    "href": "sec_linearis_regresszio.html#a-többszörös-lineáris-regresszió-esetei",
    "title": "1  Lineáris regresszió",
    "section": "1.4 A többszörös lineáris regresszió esetei",
    "text": "1.4 A többszörös lineáris regresszió esetei\n\n1.4.1 Egyetlen dichotóm magyarázó változó\nA magyarázó változóink eddig kvantitatívak voltak, de kategorikus változók is lehetnek. Ha a kategorikus változónk csupán 2 értékű, akkor a becsült (\\(b_0\\), \\(b_1\\)) együtthatók értelmezése módosul. A tengelymetszet (\\(b_0\\)) a kategorikus változó referencia szintjén a függő változó átlagát tartalmazza, míg a (\\(b_1\\)) a kategorikus változó másik szintjén számolt átlag eltérését a \\(b_0\\)-hoz képest.\n\nd <- rio::import(file = \"adat/lin_reg_magassag_hajhossz_nem_01.xlsx\")\nd$nem <- factor(d$nem, levels = c(\"nő\", \"férfi\"))\nstr(d)\n#> 'data.frame':    6 obs. of  3 variables:\n#>  $ magassag: num  158 159 162 170 182 179\n#>  $ hajhossz: num  28 25 20 1 1.5 3\n#>  $ nem     : Factor w/ 2 levels \"nő\",\"férfi\": 1 1 1 2 2 2\nd\n#>   magassag hajhossz   nem\n#> 1      158     28.0    nő\n#> 2      159     25.0    nő\n#> 3      162     20.0    nő\n#> 4      170      1.0 férfi\n#> 5      182      1.5 férfi\n#> 6      179      3.0 férfi\n\n\nlm_1 <- lm(magassag ~ nem, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = magassag ~ nem, data = d)\n#> \n#> Residuals:\n#>       1       2       3       4       5       6 \n#> -1.6667 -0.6667  2.3333 -7.0000  5.0000  2.0000 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  159.667      2.687  59.413 4.81e-07 ***\n#> nemférfi      17.333      3.801   4.561   0.0103 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 4.655 on 4 degrees of freedom\n#> Multiple R-squared:  0.8387, Adjusted R-squared:  0.7984 \n#> F-statistic:  20.8 on 1 and 4 DF,  p-value: 0.01033\n\n\n\n\nA magasság és a nem kapcsolata\n\n\nA fenti példa a nem hatását vizsgálja testmagasságra. A p-érték alapján ez a hatás szignifikáns, tehát a függés fennáll, a paraméterek pedig a nők átlagáról \\((b_0=159,67)\\) és a férfiak és nők átlagának eltéréséről tájékoztatnak \\((b_1=17,33)\\)."
  },
  {
    "objectID": "sec_linearis_regresszio.html#modellválasztás",
    "href": "sec_linearis_regresszio.html#modellválasztás",
    "title": "1  Lineáris regresszió",
    "section": "1.5 Modellválasztás",
    "text": "1.5 Modellválasztás\nElőfordulhat, hogy egy jelenség vizsgálatakor több lineáris regressziós modellt is meg tudunk fogalmazni, nem csak egyetlen modell létezik. Ez a probléma leggyakrabban úgy jelenik meg, hogy rengeteg független változónk van, és nem tudjuk eldönteni, hogy elég egy kisebb modell, néhány változóval, vagy vegyük inkább a nagyobb modellt több változóval.\nA megfelelő modell megtaláláshoz a modelleket összehasonlíthatjuk F-próba segítségével, szignifikáns eredmény esetén a két modell magyarázó ereje eltér egymástól. Ilyenkor a célunk a legszűkebb (legkevesebb magyarázó változót tartalmazó), de a legbővebbtől szignifikánsan nem különböző modell megtalálása.\nA korrigált determinációs együttható \\((R_{adj}^2)\\) is alkalmas mód a modellek összehasonlítására: az 1-hez legközelebbi értékkel bíró modell rendelkezik a legnagyobb magyarázó erővel. Léteznek már kritériumok is:\n\nAIC (Akaike-kritérium): minél kisebb az AIC értéke, annál nagyobb a modell magyarázó ereje.\nBIC (Bayes-kritérium): minél kisebb a BIC értéke, annál nagyobb a modell magyarázó ereje.\nRMSE (négyzetes középérték, Root Mean Square Error) az a mennyiség, amennyivel a vizsgált értékek eltérnek az előre megbecsült értékektől. Minél kisebb ez az érték, annál jobban becsül a modell.\n\n\nd <- rio::import(file = \"adat/lin_reg_fizetes_eletkor_elegedettseg_01.xlsx\")\nstr(d)\n#> 'data.frame':    5 obs. of  3 variables:\n#>  $ fizetes     : num  44 66 89 155 130\n#>  $ eletkor     : num  25 65 21 35 40\n#>  $ elegedettseg: num  37 36 61 92 76\nd\n#>   fizetes eletkor elegedettseg\n#> 1      44      25           37\n#> 2      66      65           36\n#> 3      89      21           61\n#> 4     155      35           92\n#> 5     130      40           76\n\n\nlm_1 <- lm(elegedettseg ~ fizetes, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes, data = d)\n#> \n#> Residuals:\n#>      1      2      3      4      5 \n#>  4.249 -8.272  4.684  1.123 -1.785 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)   \n#> (Intercept)  9.71048    7.07562   1.372  0.26355   \n#> fizetes      0.52365    0.06738   7.772  0.00443 **\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 6.134 on 3 degrees of freedom\n#> Multiple R-squared:  0.9527, Adjusted R-squared:  0.9369 \n#> F-statistic:  60.4 on 1 and 3 DF,  p-value: 0.004432\nlm_2 <- lm(elegedettseg ~ fizetes + eletkor, data = d)\nsummary(lm_2)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes + eletkor, data = d)\n#> \n#> Residuals:\n#>        1        2        3        4        5 \n#>  0.28596  0.08556 -0.30015  0.71047 -0.78184 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 21.508055   1.292166   16.64  0.00359 ** \n#> fizetes      0.519198   0.008847   58.69  0.00029 ***\n#> eletkor     -0.305549   0.023279  -13.12  0.00575 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.8047 on 2 degrees of freedom\n#> Multiple R-squared:  0.9995, Adjusted R-squared:  0.9989 \n#> F-statistic:  1841 on 2 and 2 DF,  p-value: 0.000543\nanova(lm_1, lm_2)\n#> Analysis of Variance Table\n#> \n#> Model 1: elegedettseg ~ fizetes\n#> Model 2: elegedettseg ~ fizetes + eletkor\n#>   Res.Df     RSS Df Sum of Sq      F   Pr(>F)   \n#> 1      3 112.864                                \n#> 2      2   1.295  1    111.57 172.28 0.005754 **\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nperformance::model_performance(lm_1)\n#> # Indices of model performance\n#> \n#> AIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n#> ------------------------------------------------------------\n#> 35.773 | 59.773 | 34.601 | 0.953 |     0.937 | 4.751 | 6.134\nperformance::model_performance(lm_2)\n#> # Indices of model performance\n#> \n#> AIC    | AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n#> ----------------------------------------------------------\n#> 15.436 |  Inf | 13.873 | 0.999 |     0.999 | 0.509 | 0.805\n\n\n\n\nElégedettség kapcsolata a fizetéssel és az élekorral (N=5): modellek összehasonlítása\n\n\nA fenti példán látható, hogy két modellt építettünk. Az 1. modell az elégedettséget a fizetés segítségével próbálja jósolni. A 2. modell az elégedettséget a fizetéssel és az életkorral. Láthatjuk a 2. modell szignifikánsan eltér magyarázó erőben a az 1. modelltől, valamint a modell “jóságát” leíró mutatók mindegyike kedvezőbb a 2. modell esetén: \\(R_{adj}^2\\), \\(AIC\\), \\(BIC\\), \\(RMSE\\)."
  },
  {
    "objectID": "sec_linearis_regresszio.html#alkalmazási-feltételek",
    "href": "sec_linearis_regresszio.html#alkalmazási-feltételek",
    "title": "1  Lineáris regresszió",
    "section": "1.6 Alkalmazási feltételek",
    "text": "1.6 Alkalmazási feltételek\nA regressziós modellt ne használjuk, ha az alkalmazási feltételek valamelyike nem teljesül. Melyek ezek?\n\nMultikollinearitás: a független változók közötti korreláció. Multikollinearitás esetén elképzelhető, hogy a regressziós számítást el sem lehet végezni. Van mérőszám, amelynek a segítségével ki lehet szűrni az érintett változókat:\n\nVIF (variancia infláció faktor): a nagy érték kollinearitást jelez az érintett változókat kihagyhatjuk, vagy származtatott adatokkal dolgozunk tovább (például főkomponenselemzéssel nyert adatokat)\n\nAutokorreláció: a hibatagok együttmozgása szignifikáns."
  },
  {
    "objectID": "sec_linearis_regresszio.html#példa",
    "href": "sec_linearis_regresszio.html#példa",
    "title": "1  Lineáris regresszió",
    "section": "1.7 1. Példa",
    "text": "1.7 1. Példa\nBefolyásolja-e a munkahellyel való elégedettséget a fizetés nagysága és az életkor? (Münnich és mtsai., 2006) [1.6.1 probléma]\n\nd <- rio::import(file = \"adat/lin_reg_elegedettseg.xlsx\")\nstr(d)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ fizetes     : num  109 125 98 124 115 132 124 99 165 187 ...\n#>  $ elegedettseg: num  69.2 90.8 71 90.1 77.8 ...\n#>  $ kor         : num  20 46.3 36.2 46 31 ...\n#>  $ nem         : chr  \"nő\" \"férfi\" \"nő\" \"férfi\" ...\npsych::headTail(d)\n#>     fizetes elegedettseg   kor   nem\n#> 1       109        69.15    20    nő\n#> 2       125        90.85 46.33 férfi\n#> 3        98        71.04  36.2    nő\n#> 4       124        90.12 45.95 férfi\n#> ...     ...          ...   ...  <NA>\n#> 27      129        96.32    53 férfi\n#> 28      135        97.86  49.4 férfi\n#> 29      145          100  46.9 férfi\n#> 30      120        81.08    32 férfi\n\n\nlm_1 <- lm(elegedettseg ~ fizetes + kor, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = elegedettseg ~ fizetes + kor, data = d)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -10.248  -1.543   1.188   2.437   4.333 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  8.13712    3.26797   2.490   0.0192 *  \n#> fizetes      0.44404    0.02321  19.128  < 2e-16 ***\n#> kor          0.53361    0.07127   7.487 4.71e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 3.59 on 27 degrees of freedom\n#> Multiple R-squared:  0.953,  Adjusted R-squared:  0.9496 \n#> F-statistic: 273.9 on 2 and 27 DF,  p-value: < 2.2e-16\nlsr::standardCoefs(lm_1)\n#>                 b      beta\n#> fizetes 0.4440418 0.8322319\n#> kor     0.5336111 0.3257287\n\n\n\n\nElégedettség kapcsolata a fizetéssel és lektkorra (N=30)\n\n\nA fenti outputból láthatjuk, hogy a fizetés és a kor változó is szignifikánsan befolyásolja az elégedettséget, hiszen a hozzájuk tartozó szignifikanciaszint \\(p<0,05\\). A teljes modell vonatkozó F-próba is szignifikáns. A fizetés változó együtthatója \\((b_1)\\) 0,44, a kor változó együtthatója \\((b_2)\\) pedig 0,53, ami arra utal, hogy pozitív kapcsolat van a változó között: minél magasabb a fizetés, és minél idősebbek az emberek, annál elégedettebbek a munkahelyükkel.\nA pontos becslés a regressziós egyenlet alapján a következőképpen fest:\nelégedettség = 8,14 + 0,44 * fizetés + 0,53 * kor\nMivel a többszörös regresszió esetében a független változók hatása csak a standardizált együtthatók mentén hasonlítható össze, így kiszámoltuk a standardizált együtthatókat is. Az adatok jól példázzák, hogy miért fontos a standardizált együtthatókat is vizsgálni, hiszen a nem standardizált együtthatók esetén a kor változó együtthatójának értéke a magasabb, míg a standardizált értékeknél fordítva. Vagyis, ha az egyes változók relatív fontosságának vizsgálatakor nem nézzük a dimenziómentes értékeket, akkor könnyen téves következtetésre juthatunk.\nA négyzetes korrelációs együttható értéke 0,9, ami arra utal, hogy a független változók igen jól magyarázzák a függő változót."
  },
  {
    "objectID": "sec_linearis_regresszio.html#példa-1",
    "href": "sec_linearis_regresszio.html#példa-1",
    "title": "1  Lineáris regresszió",
    "section": "1.8 2. Példa",
    "text": "1.8 2. Példa\nBefolyásolja-e a kalandvágy a hivatásos katonai szolgálatnál eltöltött időt? (Münnich és mtsai., 2006) [1.6.2 probléma]\n\nd <- rio::import(file = \"adat/lin_reg_katonasag.xlsx\")\nstr(d)\n#> 'data.frame':    156 obs. of  4 variables:\n#>  $ kaland  : num  3 3 5 1 3 4 2 2 3 5 ...\n#>  $ egyhangu: num  3 2 4 1 3 1 2 1 2 3 ...\n#>  $ sport   : num  1 1 2 1 2 2 2 1 2 2 ...\n#>  $ evek    : num  4 7 10 3 6 15 5 6 9 13 ...\npsych::headTail(d)\n#>     kaland egyhangu sport evek\n#> 1        3        3     1    4\n#> 2        3        2     1    7\n#> 3        5        4     2   10\n#> 4        1        1     1    3\n#> ...    ...      ...   ...  ...\n#> 153      2        4     2    1\n#> 154      3        5     3    2\n#> 155      1        3     2    2\n#> 156      3        2     4   12\n\n\nlm_1 <- lm(evek ~ egyhangu + sport + kaland, data = d)\nsummary(lm_1)\n#> \n#> Call:\n#> lm(formula = evek ~ egyhangu + sport + kaland, data = d)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -1.6611 -0.5925 -0.0798  0.2726  9.7833 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  0.63951    0.33263   1.923   0.0564 .  \n#> egyhangu    -2.28197    0.09160 -24.912   <2e-16 ***\n#> sport        1.52987    0.09447  16.194   <2e-16 ***\n#> kaland       3.17525    0.09884  32.125   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.213 on 152 degrees of freedom\n#> Multiple R-squared:  0.9195, Adjusted R-squared:  0.9179 \n#> F-statistic: 578.4 on 3 and 152 DF,  p-value: < 2.2e-16\nlsr::standardCoefs(lm_1)\n#>                  b       beta\n#> egyhangu -2.281974 -0.5927751\n#> sport     1.529871  0.3821476\n#> kaland    3.175249  0.7676009\n\n\n\n\nBefolyásolja-e a kalandvágy a hivatásos katonai szolgálatnál eltöltött időt? (N=156)\n\n\nA fenti output a többszörös lineáris regresszió eredményét mutatja:\n\nA lineáris regressziós modellt megtarthatjuk, hiszen az F-statisztika értékét tekintve a modell szignifikáns, a változók együtthatóinak az értéke nem nulla.\nA modell magyarázóértéke igen jó, hiszen a korrigált determinációs együttható értéke 0,92, vagyis a független változók a függő változó varianciájának kb. 92%-át magyarázzák.\nMinden egyes független változó hatással van a függő változóra, vagyis mind a kalandvágy, az extrém sportok szeretete és a nyugalom utáni vágy is befolyásolja azt, hogy mennyi időt tölt valaki a hivatásos katonai szolgálatban.\nEllenben a \\(b_0\\) vagyis a konstans értéke most nulla, hiszen a táblázatban szereplő érték nem szignifikáns.\nMaga a regressziós egyenlet a pontos együtthatók ismeretében a következőképpen alakul:\n\n    evek=3,18*kaland+1,53*sport-2,28*egyhangu\n\nVagyis minél jobban kedveli valaki a kalandos életet és az extrém sportokat, és minél jobban irtózik a szürke hétköznapoktól, annál több időt tölt a katonaság kötelékében.\nA standardizált változók alapján a kaland szeretetének a hatása a legerősebb (0,768), a második legerősebb hatás az egyhangúság kedvelése, ám hatásának iránya negatív (-0,593), leggyengébb hatása pedig az extrém sportok szeretetének van (0,382).\n\n\n\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-menete",
    "href": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-menete",
    "title": "2  Főkomponens elemzés",
    "section": "2.1 A főkomponens elemzés menete",
    "text": "2.1 A főkomponens elemzés menete\nAz eredeti \\(X_1,X_2,\\dots,X_p\\) változókból a \\(Z_i=a_i1 X_1+ a_i2 X_2+\\dots + a_ip X_p\\) lineáris kombinációk segítségével kapjuk meg a főkomponenseket, azzal feltétellel, hogy \\(a_{i1}^2+a_{i2}^2+\\dots+a_{ip}^2=1\\), és az egymás után létrejövő \\(Z_1,Z_2,…,Z_p\\) főkomponensek nem korrelálnak egymással.\nGyakran az \\(X_1,X_2,\\dots,X_p\\) változó standardizált értékeiből indulunk ki, hogy a változók arányosan fejtsék ki hatásukat a főkomponensekre. A jamovi is így végzi az elemzést. Ekkor a változok átlaga nulla, szórása és variancia pedig 1 lesz.\nA részletek ismertetése nélkül a keresett \\(a_{i1},a_{i2},\\dots,a_{ip}\\) együtthatók megtalálása egy sajátérték-sajátvektor keresési feladat az eredeti \\(X_1,X_2,\\dots,X_p\\) változók korrelációs mátrixában. A megtalált \\(p\\) darab sajátérték $_1_2_p>0 $sorrendjét feltételezve, \\(\\lambda_i\\) az \\(i.\\) főkomponens varianciáját adja \\((\\lambda_i=var(Z_i))\\), és a megtalált \\(p\\) darab sajátvektorból az \\(i.\\) egyes elemei lesznek a \\(Z_i=a_{i1} X_1+ a_{i2} X_2+\\dots+ a_{ip} X_p\\) főkomponens \\(a_{i1},a_{i2},\\dots,a_{ip}\\) együtthatói.\nFontos összefüggés, hogy a főkomponensek (\\(Z_i\\)-k) varianciájának az összege egyenlő az eredeti standardizált változók (\\(X_i\\)-k) varianciájának összegével, azaz \\(\\lambda_1+\\lambda_2+\\dots+\\lambda_p=1+1+\\dots+1=p.\\)"
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-alkalmazási-feltételei",
    "href": "sec_fokomponens_elemzes.html#a-főkomponens-elemzés-alkalmazási-feltételei",
    "title": "2  Főkomponens elemzés",
    "section": "2.2 A főkomponens elemzés alkalmazási feltételei",
    "text": "2.2 A főkomponens elemzés alkalmazási feltételei\n\nA főkomponens elemzés során általában 4-5-ször (egyes szerzőknél 10-szer) nagyobb a mintaelemszám a vizsgált változók számánál.\nA faktoranalízis feltétele, hogy egymással korreláló változókból induljunk ki. A Bartlett-féle szferikus próba nullhipotézise, hogy a változók korrelálatlanok (vagyis a korrelációs mátrixnak a főátlón kívüli elemei csak véletlenül térnek el a nullától). A szignifikáns p-érték a kedvező a főkomponens elemzés számára. (Megjegyezzük, hogy a túlságosan magas egyirányú korrelációk sem jók, ugyanis ez azt okozhatja, hogy a főkomponens elemzésnek nem lesz megoldása, ugyanis minden változó egy faktorba kerül.)\nAz MSA (Measure of Sampling Adequecy) az egyes változók esetében mutatja meg, hogy mennyire van szoros kapcsolatban a többi változóval. Érdemes a 0,5 alatti MSA értékkel rendelkező változókat kizárni az elemzésből. Értéke 0 és 1 közötti lehet.\nA Kaiser-Meyer-Olkin- (KMO) kritérium az MSA értékek átlaga. Míg az MSA érték az egyes változókra vonatkozik, a KMO az összes változóra egyidejűleg. A KMO mutatószám jelentését a következőképpen ítélhetjük meg:\n\nKMO ≥ 0,9 kiváló\nKMO ≥ 0,8 nagyon jó\nKMO ≥ 0,7 megfelelő\nKMO ≥ 0,6 közepes\nKMO ≥ 0,5 gyenge\nKMO < 0,5 elfogadhatatlan."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#a-főkomponensek-forgatása-rotáció",
    "href": "sec_fokomponens_elemzes.html#a-főkomponensek-forgatása-rotáció",
    "title": "2  Főkomponens elemzés",
    "section": "2.3 A főkomponensek forgatása (rotáció)",
    "text": "2.3 A főkomponensek forgatása (rotáció)\nA faktorkiválasztás (extrakció) során az elemzés elsődleges célja, hogy maximalizálja a főkomponensek varianciáját, amely eredményeként megkapjuk a rotálatlan faktorsúly-mátrixot. A faktorsúly az eredeti változó és az adott faktor közötti korrelációt mutatja, amelynek értéke a korrelációs együtthatókhoz hasonlóan -1 és 1 között változhat.\nA faktorkiválasztás során azonban előfordulhat, hogy olyan változók fognak korrelálni egy adott faktorral, amelyeknek semmi közük egymáshoz, ezáltal lehetetlenné téve az értelmezést. Ezen a problémán segít a forgatás, vagy más néven rotáció. A faktor-rotáció azt jelenti, hogy a faktorok tengelyeit elforgatjuk úgy, hogy egyszerűbb és értelmezhetőbb faktormegoldáshoz vezessen.\nA rotáció (forgatás) során nem változnak sem a kommunalitás, sem pedig az összes magyarázott variancia, csak a faktorok sajátértékei/magyarázott varianciái módosulnak.\nA rotáláson belül két típust különböztetünk meg: a derékszögű (ortogonális) (Varimax, Equimax, Quartimax) és a hegyesszögű (nem ortogonális) (Direct Oblimin, Promax) forgatási módszereket.\nA derékszögű esetében a tengelyek merőlegesen állnak egymásra, ezáltal a faktorok nem korrelálnak egymással, míg a hegyesszögű esetében ezek tetszőleges szöget zárnak be egymással, vagyis a faktorok korrelálni fognak egymással."
  },
  {
    "objectID": "sec_fokomponens_elemzes.html#példa",
    "href": "sec_fokomponens_elemzes.html#példa",
    "title": "2  Főkomponens elemzés",
    "section": "2.4 1. Példa",
    "text": "2.4 1. Példa\nA példa Münnich és mtsai. (2006) 2.3.1. alfejezet alapján készült és a kapcsolódó jamovi állomány: fokomp_elemzes_tantargyak.omv.\n1. Határozzuk meg a korrelációs mátrixot (jamovi-ban: Regression / Correlation matrix)\n\nd <- rio::import(file = \"adat/fokomp_elemzes_tantargyak.xlsx\")\nstr(d)\n#> 'data.frame':    9 obs. of  4 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5\n#>  $ fizika     : num  5 5 3 3 4 2 4 3 5\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5\nd\n#>   matek fizika informatika kemia\n#> 1     5      5           4     5\n#> 2     4      5           4     5\n#> 3     3      3           4     3\n#> 4     2      3           2     3\n#> 5     5      4           5     5\n#> 6     1      2           1     1\n#> 7     5      4           5     5\n#> 8     2      3           2     3\n#> 9     5      5           5     5\n\n\ncor(d)\n#>                 matek    fizika informatika     kemia\n#> matek       1.0000000 0.8712476   0.9492623 0.9499475\n#> fizika      0.8712476 1.0000000   0.7662496 0.9271176\n#> informatika 0.9492623 0.7662496   1.0000000 0.8867155\n#> kemia       0.9499475 0.9271176   0.8867155 1.0000000\n\n\n\n\nKorrelációs mátrix meghatározása\n\n\nA korrelációs mátrix adatai arra utalnak, hogy szoros kapcsolat van a változók között. A korrelációs értékek nullánál nagyobbak, ami azonos irányú tendenciákra utal. E két mátrix is alátámasztja a feltételezésünket, hogy a változók szorosan együtt változnak.\n2. Ellenőrizzük le az adatok alkalmasságát (jamovi-ban: Factor / Principal Component Analysis)\nA változóink eleget tesznek a Bartlett-féle szferikus próbának, a korrelációs mátrix nem egységmátrix \\((p<0,001)\\), az MSA értékek is nagyobban \\(0,5\\)-nél és a KMO érték is megfelelő.\n\n\n\nAlkalmazási feltételek ellenőrzése\n\n\n3. Határozzuk meg a komponensek számát\nElvileg annyi főkomponenst lehet kiszámolni, ahány változónk van, a célunk azonban a komponensek számának minimalizálása.\nTöbb eljárás létezik a főkomponensek számának meghatározására:\n\nHorn-féle párhuzamos analízis (jamovi-ban: Based on parallel analysis): modern eljárás, amely szimuláció segítségével állapítja meg a főkomponensek számát (Horn, 1965).\nA priori meghatározás (jamovi-ban: Fixed number): korábbi ismerete alapján megadjuk a főkomponensek számát.\nSajátértéken alapuló megoldás (jamovi-ban: Based on eigenvalue): tipikusan csak az 1-nél nagyobb sajátértékű faktorokat tartjuk bent a modellben. Az 1-nél kisebb varianciájú faktorok ugyanis nem jobbak mint az eredeti standardizált változók\nSajátértékábrán (scree-plot, kőtörmelék ábra) alapuló meghatározás (jamovi-ban: Scree plot): a sajátérték ábra a sajátértékek ábrázolása a főkomponensek sorrendjében. Az ábra formája alapján lehet következtetni a főkomponensek számára: ahol a görbe meredekségében van egy határozott törés, meredekebb rész után laposabb jön. Ahol tehát a görbe laposodása elkezdődik, az a figyelembe vett főkomponensek megfelelő száma.\nMagyarázott varianciahányadon alapuló meghatározás (jamovi-ban: Component summary): ekkor az előállított főkomponensek számát úgy határozzuk meg, hogy a főkomponensek által magyarázott variancia kumulált százalékos értéke elérjen egy megfelelő szintet. A megfelelő szint (60%-95%-ig) a probléma jellegétől függ.\n\nA Horn-féle párhuzamos elemzés 1 főkomponenst javasol.\n\n\n\nFőkomponensek számának meghatározása\n\n\n4. Válasszunk forgatást (jamovi-ban: Rotation)\nA jamovi alapértelmezés szerint a Varimax forgatást ajánlja, amely derékszögű koordinátatengelyeket eredményez és a legtöbb esetben ez a megfelelő választás. Lehetőségünk van ezen módosítani. Az összes lehetőség:\n\nNone – rotálatlan elemzés\nVarimax\nQartimax\nPromax\nOblimin\nSimplimax\n\nMivel egyetlen főkomponensünk van, így nem változtatunk az alapértelmezett Varimax beállításon.\n5. A főkomponens elemzés eredménye\nKomponens mátrix (jamoviban: Component loadings)\nA főkomponens elemzés eredménye a komponens mátrix (faktormátrix), amelynek soraiban az eredeti változók, oszlopaiban a kinyert főkomponensek vannak. A cellákban a komponens súlyok (faktorsúlyok) szerepelnek, amelyek a főkomponens és a változó közötti korrelációt jelentik. Ezek egyben a főkomponensek azon együtthatói, amelyekkel a standardizált változó a főkomponensekkel kifejezhető.\nA magas abszolút értékű faktorsúly azt jelzi, hogy komponens és a változó szorosan összefügg.\nA változókat tartalmazó sorok rendezhetők a faktorsúlyok csökkenő sorrendjében (jamovi-ban: Sort loading by size)\nAz adott értéknél kisebb faktorsúlyok elrejthetők a táblázatban (jamoviban: Hide loadings below)\nA Uniqueness oszlopban az egyes változók „egyediségét” is láthatjuk. Az egyediség a variancia azon aránya, amely „egyedi” a változóra nézve, és nem magyarázható a komponensekkel. Vegyük figyelembe, hogy minél nagyobb az „egyediség”, annál kisebb a változó relevanciája/hozzájárulása a modellben.\nA kezdő sajátértékek (jamovi-ban: Initial eigenvalues)\nA kezdő sajátértékek táblázat a sajátértékeket adja meg. A komponensek sajátértékei csökkenő nagyságúak, ahogy az 1. komponenstől a 4. komponensig haladunk. A komponens sajátértéke kifejezi a komponens által magyarázott teljes varianciát. A 4 komponens összvarianciája pontosan 4. A további két oszlopban ez alapján számoljuk a százalékos és a kummulált százalékos varianciát.\nA komponensek összegzése (jamovi-ban: Component summary)\nA komponensek összegzése táblázat tartalmazza a megtartott komponenseket, a magyarázott varianciát, illetve utóbbit százalékosan is kifejezve. Vegyük észre, hogy ez a sor teljesen megegyezik a kezdő sajátértékek táblázat első sorával. Az SS Loadings felirat magyarázata, hogy magyarázott variancia a komponenshez tartozó faktorsúlyok négyzetösszege (sum of square).\n\n\n\nKomponensek összegzése\n\n\n6. Főkomponens értékek kiszámítása\nA főkomponens elemzés célja az eredeti változók csökkentése. A főkomponens(ek) az eredeti változók lineáris kombinációjával kifejezhetők. Ez(ek) a főkomponens értékek (jamovi-ban: Component score) az adatbázisban is rögzíthetők, és további elemzések kiindulópontjai lehetnek.\n\n\n\nFőkomponens értékek kiszámítása\n\n\nSikerült tehát az érdemjegyeket egyetlen mérőszámmal kifejezni, a fenti főkomponens érték az, amely a lehető legjobban magában foglalja az egyes tantárgyakból szerzett jegyeket és ezáltal a reál tantárgyak iránti fogékonyság mérőszáma lehet. A legjobban a kilencedik személy teljesít a reál tárgyakból, legrosszabbul pedig a hatodik. Ezek az értékek standardizáltak, vagyis 0 átlagúak és 1 szórásúak.\n\n\n\nFőkomponens értékek leíró statisztikája\n\n\nR-ben több lehetőségünk van a főlomponenselemzés elvégzésére.\n\npca_1 <- prcomp(d, scale. = TRUE)\npca_1\n#> Standard deviations (1, .., p=4):\n#> [1] 1.9177188 0.5017701 0.2045278 0.1695572\n#> \n#> Rotation (n x k) = (4 x 4):\n#>                    PC1        PC2         PC3         PC4\n#> matek       -0.5129614  0.2231620 -0.02972158 -0.82836339\n#> fizika      -0.4843985 -0.7077528  0.50610146  0.09113404\n#> informatika -0.4900124  0.6474152  0.35260295  0.46520167\n#> kemia       -0.5119731 -0.1736040 -0.78654250  0.29848968\n\n\npca_1 <- princomp(d, cor = TRUE)\npca_1\n#> Call:\n#> princomp(x = d, cor = TRUE)\n#> \n#> Standard deviations:\n#>    Comp.1    Comp.2    Comp.3    Comp.4 \n#> 1.9177188 0.5017701 0.2045278 0.1695572 \n#> \n#>  4  variables and  9 observations.\n\n\npsych::pca(d, rotate = \"varimax\")\n#> Principal Components Analysis\n#> Call: principal(r = r, nfactors = nfactors, residuals = resid...\n#>     rotate = rotate, n.obs = n.obs, covar = covar, scores = s...\n#>     missing = missing, impute = impute, oblique.scores = obli...\n#>     method = method, use = use, cor = cor, correct = 0.5, wei...\n#> Standardized loadings (pattern matrix) based upon correlation...\n#>              PC1   h2    u2 com\n#> matek       0.98 0.97 0.032   1\n#> fizika      0.93 0.86 0.137   1\n#> informatika 0.94 0.88 0.117   1\n#> kemia       0.98 0.96 0.036   1\n#> \n#>                 PC1\n#> SS loadings    3.68\n#> Proportion Var 0.92\n#> \n#> Mean item complexity =  1\n#> Test of the hypothesis that 1 component is sufficient.\n#> \n#> The root mean square of the residuals (RMSR) is  0.05 \n#>  with the empirical chi square  0.28  with prob <  0.87 \n#> \n#> Fit based upon off diagonal values = 1\n\n\npca_1 <- FactoMineR::PCA(d, graph = FALSE)\npca_1$eig\n#>        eigenvalue percentage of variance\n#> comp 1 3.67764553             91.9411383\n#> comp 2 0.25177321              6.2943303\n#> comp 3 0.04183160              1.0457901\n#> comp 4 0.02874965              0.7187414\n#>        cumulative percentage of variance\n#> comp 1                          91.94114\n#> comp 2                          98.23547\n#> comp 3                          99.28126\n#> comp 4                         100.00000\npca_1$var\n#> $coord\n#>                 Dim.1      Dim.2        Dim.3       Dim.4\n#> matek       0.9837158 -0.1119760 -0.006078888 -0.14045500\n#> fizika      0.9289402  0.3551292  0.103511795  0.01545243\n#> informatika 0.9397061 -0.3248536  0.072117091  0.07887831\n#> kemia       0.9818205  0.0871093 -0.160869772  0.05061108\n#> \n#> $cor\n#>                 Dim.1      Dim.2        Dim.3       Dim.4\n#> matek       0.9837158 -0.1119760 -0.006078888 -0.14045500\n#> fizika      0.9289402  0.3551292  0.103511795  0.01545243\n#> informatika 0.9397061 -0.3248536  0.072117091  0.07887831\n#> kemia       0.9818205  0.0871093 -0.160869772  0.05061108\n#> \n#> $cos2\n#>                 Dim.1       Dim.2        Dim.3        Dim.4\n#> matek       0.9676968 0.012538628 3.695288e-05 0.0197276074\n#> fizika      0.8629298 0.126116721 1.071469e-02 0.0002387777\n#> informatika 0.8830475 0.105529830 5.200875e-03 0.0062217871\n#> kemia       0.9639714 0.007588031 2.587908e-02 0.0025614817\n#> \n#> $contrib\n#>                Dim.1     Dim.2       Dim.3      Dim.4\n#> matek       26.31294  4.980128  0.08833723 68.6185908\n#> fizika      23.46419 50.091398 25.61386842  0.8305413\n#> informatika 24.01122 41.914638 12.43288421 21.6412590\n#> kemia       26.21165  3.013836 61.86491013  8.9096089\nfactoextra::fviz_eig(pca_1, addlabels = TRUE, ylim = c(0, 110))\nfactoextra::get_eigenvalue(pca_1)\n#>       eigenvalue variance.percent cumulative.variance.percent\n#> Dim.1 3.67764553       91.9411383                    91.94114\n#> Dim.2 0.25177321        6.2943303                    98.23547\n#> Dim.3 0.04183160        1.0457901                    99.28126\n#> Dim.4 0.02874965        0.7187414                   100.00000\nfactoextra::get_pca_ind(pca_1)\n#> Principal Component Analysis Results for individuals\n#>  ===================================================\n#>   Name       Description                       \n#> 1 \"$coord\"   \"Coordinates for the individuals\" \n#> 2 \"$cos2\"    \"Cos2 for the individuals\"        \n#> 3 \"$contrib\" \"contributions of the individuals\"\nfactoextra::get_pca_var(pca_1)\n#> Principal Component Analysis Results for variables\n#>  ===================================================\n#>   Name       Description                                    \n#> 1 \"$coord\"   \"Coordinates for the variables\"                \n#> 2 \"$cor\"     \"Correlations between variables and dimensions\"\n#> 3 \"$cos2\"    \"Cos2 for the variables\"                       \n#> 4 \"$contrib\" \"contributions of the variables\"\nfactoextra::fviz_pca_ind(pca_1)\nfactoextra::fviz_pca_var(pca_1)\nfactoextra::fviz_pca_biplot(pca_1)\ncorrplot::corrplot(pca_1$var$cos2, is.corr = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPélda\n\nLétezik a reál tárgyak iránti fogékonyság?\nKorábban már foglalkoztunk azzal a felvetéssel, hogy néhány tantárgy eredményeit egyetlen mérőszámmal reprezentáljuk. Korábbi példánkban a matematika, fizika, informatika és kémia jegyek közötti összefüggéseket vizsgáltuk egy kisebb adatbázison, most egy sokkal nagyobb adatbázis segítségével mutatjuk be, hogyan végezhetünk főkomponens-analízist.\nÖsszességében az adatok jól sűríthetők egyetlen mérőszámba, minimális információveszteséggel, ezt a mutatót pedig hívhatjuk a reál tárgyak iránti fogékonyság mutatójának.\n\nPélda\n\nEgy kérdőív szerkesztésének problémái\nA kapott eredmények alapján az itemszelekciót ennél a lépésnél befejezhetjük. Az így kapott hat itemünk a statisztikai eredmények alapján egészen jól lefednek egy dimenziót, ezáltal használhatóak egy jelenség kérdőíves vizsgálatára.\n\n\n\n\nHorn, J. L. (1965). A rationale and test for the number of factors in factor analysis. Psychometrika, 30, 179–185. https://doi.org/10.1007/BF02289447\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika"
  },
  {
    "objectID": "sec_megbizhatosag_elemzes.html#cronbach-alfa-belső-konzisztencia-mérése",
    "href": "sec_megbizhatosag_elemzes.html#cronbach-alfa-belső-konzisztencia-mérése",
    "title": "3  Megbízhatóság elemzés",
    "section": "3.1 Cronbach-alfa – belső konzisztencia mérése",
    "text": "3.1 Cronbach-alfa – belső konzisztencia mérése\nFőkomponens elemzés segítségével könnyen tudunk több változót - viszonylag csekély veszteséggel - egyetlen változóba tömöríteni, ezért gyakran használják kérdőívek itemeinek szelekciójára, valamint megbízhatóság (reliabilitás) vizsgálatra. A klasszikus tesztelmélet keretein belül azonban a tesztek megbízhatóságának (reliabilitásának) több lehetséges mutatója is létezik.\nCronbach 1951-es munkájában publikálta azon nézetét, hogy a korábbi egyszerű tesztfelezéses eljárás helyett egy annál tökéletesebb mutatót kellene használni a tesztek megbízhatóságának indikátoraként. Ha az itemek száma alacsony vagy az itemek közötti átlagos korreláció alacsony, akkor csökkenni fog a Cronbach-féle alfa értéke is. Az is egyértelmű, hogy az itemek közötti alacsony korreláció arra enged következtetni, hogy a teszt itemjei nem egy és ugyanazon dolog vizsgálatára szolgálnak, a belőlük képzendő tesztérték nem alkalmas sem elméleti, sem pedig gyakorlati felhasználásra.\nAz ómega (McDonald \\(\\omega\\)) korrigálja a Cronbach-alfa torzítását, érdemes elvégezni az elemzést ezzel a mutatóval is (Kárász és mtsai., 2022; Malkewitz és mtsai., 2023)."
  },
  {
    "objectID": "sec_megbizhatosag_elemzes.html#példa-real-tárgyak-iránti-fogékonyság",
    "href": "sec_megbizhatosag_elemzes.html#példa-real-tárgyak-iránti-fogékonyság",
    "title": "3  Megbízhatóság elemzés",
    "section": "3.2 Példa: Real tárgyak iránti fogékonyság",
    "text": "3.2 Példa: Real tárgyak iránti fogékonyság\nEgy fiktív adatbázis 9 tanuló iskolai jegyeit tartalamzza reál tantárgyakból (matematika, fizika, kémia, informatika) (megbizhatosag_tantargyak.xlsx). Vizsgáljuk meg, ha a reál tantárgyak iránti fogékonyságot ezzel a 4 érdemjeggyel mérnénk, akkor ez megbízhatóság szempontjából alkalmas mérőeszköz lenne.\n\nreal <- rio::import(file = \"adat/megbizhatosag_tantargyak.xlsx\")\nstr(real)\n#> 'data.frame':    9 obs. of  4 variables:\n#>  $ matek      : num  5 4 3 2 5 1 5 2 5\n#>  $ fizika     : num  5 5 3 3 4 2 4 3 5\n#>  $ informatika: num  4 4 4 2 5 1 5 2 5\n#>  $ kemia      : num  5 5 3 3 5 1 5 3 5\n\nA Cronbach alfa meghatározását végezhetjük a {psych} csomag alpha() függvényével.\n\npsych::alpha(real)  # Cronbach-alfa\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = real)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd me...\n#>       0.97      0.97    0.98      0.89  33 0.017  3.7 1.4    ...\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.91  0.97  0.99\n#> Duhachek  0.93  0.97  1.00\n#> \n#>  Reliability if an item is dropped:\n#>             raw_alpha std.alpha G6(smc) average_r S/N alpha se\n#> matek            0.94      0.95    0.95      0.86  18    0.032\n#> fizika           0.97      0.98    0.97      0.93  39    0.015\n#> informatika      0.96      0.97    0.97      0.92  33    0.019\n#> kemia            0.94      0.95    0.96      0.86  19    0.029\n#>              var.r med.r\n#> matek       0.0070  0.89\n#> fizika      0.0013  0.95\n#> informatika 0.0016  0.93\n#> kemia       0.0084  0.87\n#> \n#>  Item statistics \n#>             n raw.r std.r r.cor r.drop mean  sd\n#> matek       9  0.99  0.98  0.98   0.97  3.6 1.6\n#> fizika      9  0.92  0.93  0.91   0.88  3.8 1.1\n#> informatika 9  0.95  0.94  0.93   0.90  3.6 1.5\n#> kemia       9  0.98  0.98  0.98   0.96  3.9 1.5\n#> \n#> Non missing response frequency for each item\n#>                1    2    3    4    5 miss\n#> matek       0.11 0.22 0.11 0.11 0.44    0\n#> fizika      0.00 0.11 0.33 0.22 0.33    0\n#> informatika 0.11 0.22 0.00 0.33 0.33    0\n#> kemia       0.11 0.00 0.33 0.00 0.56    0\n\nA McDonald \\(\\omega\\) értékét kiszámolhatjuk a {psych} csomag omega() függvényével.\n\npsych::omega(real, plot = F)  # McDonald-ómega\n#> Omega \n#> Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, ...\n#>     digits = digits, title = title, sl = sl, labels = labels, \n#>     plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, o...\n#>     covar = covar)\n#> Alpha:                 0.97 \n#> G.6:                   0.98 \n#> Omega Hierarchical:    0.95 \n#> Omega H asymptotic:    0.96 \n#> Omega Total            0.99 \n#> \n#> Schmid Leiman Factor loadings greater than  0.2 \n#>                g   F1*   F2*   F3*   h2   u2   p2\n#> matek       0.97        0.28       0.99 0.01 0.94\n#> fizika      0.89  0.29             0.92 0.08 0.86\n#> informatika 0.91        0.28       0.95 0.05 0.87\n#> kemia       0.96  0.29             0.99 0.01 0.94\n#> \n#> With Sums of squares  of:\n#>    g  F1*  F2*  F3* \n#> 3.48 0.17 0.16 0.04 \n#> \n#> general/max  21.07   max/min =   4.03\n#> mean percent general =  0.9    with sd =  0.04 and cv of  0.05 \n#> Explained Common Variance of the general factor =  0.91 \n#> \n#> The degrees of freedom are -3  and the fit is  0 \n#> The number of observations was  9  with Chi Square =  0  with...\n#> The root mean square of the residuals is  0 \n#> The df corrected root mean square of the residuals is  NA\n#> \n#> Compare this with the adequacy of just a general factor and n...\n#> The degrees of freedom for just the general factor are 2  and...\n#> The number of observations was  9  with Chi Square =  5.14  w...\n#> The root mean square of the residuals is  0.05 \n#> The df corrected root mean square of the residuals is  0.08 \n#> \n#> RMSEA index =  0.401  and the 10 % confidence intervals are  ...\n#> BIC =  0.75 \n#> \n#> Measures of factor score adequacy             \n#>                                                  g  F1*  F2* ...\n#> Correlation of scores with factors            0.98 0.89 0.86 ...\n#> Multiple R square of scores with factors      0.95 0.78 0.74 ...\n#> Minimum correlation of factor score estimates 0.90 0.57 0.48 ...\n#> \n#>  Total, General and Subset omega for each subset\n#>                                                  g  F1*  F2* F3*\n#> Omega total for total scores and subscales    0.99 0.98 0.99  NA\n#> Omega general for total scores and subscales  0.95 0.89 0.91  NA\n#> Omega group for total scores and subscales    0.04 0.09 0.08  NA\n\nA fenti elemzéseket jamovi-ban a Factor / Reliability Analysis menüpont segítségével végezhetjük el.\n\n\n\nMegbízhatóság elemzés jamovi-ban\n\n\nA fenti megbízhatósági elemzések azt mutatják, hogy a négy tantárgy alfa értéke 0,966, ami egy igen jó érték, hiszen közel van 1-hez (jamovi-ban: Scale Reliability Statistics). Az Item Reliability Statistics táblázat oszlopában szereplő értékek azt mutatják, mi történik, ha egy változót kiveszünk a modellből. Láthatjuk, hogy egyedül a fizika változó értéke növelné az alfát, de a növekedés mértéke elenyésző lenne, tehát nem éri meg eltávolítani a változót, hiszen minél több információnk van egy személyről, annál jobb.\n\n\n\n\nCarver, C. S. és Scheier, M. F. (2006). Személyiségpszichológia. Osiris Kiadó.\n\n\nKárász, J. T., Nagy, O. N., Széll, K. és Takács, S. (2022). Cronbach-alfa: vele vagy nélküle? Magyar Pszichológiai Szemle, 77, 81–98. https://doi.org/10.1556/0016.2022.00004\n\n\nMalkewitz, C. P., Schwall, P., Meesters, C. és Hardt, J. (2023). Estimating reliability: A comparison of Cronbach’s α, McDonald’s ωt and the greatest lower bound. Social Sciences & Humanities Open, 7, 100368. https://doi.org/10.1016/j.ssaho.2022.100368\n\n\nNagy, O. N. (2006). A pszichológiai tesztek reliabilitása. In S. Rózsa, O. N. Nagy, és A. Oláh (Szerk.), A pszichológiai mérés alapjai. Elmélet, módszer és gyakorlati alkalmazás. Bölcsész Konzorcium. https://mek.oszk.hu/05500/05536/05536.pdf"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#a-főkomponens-elemzés-és-a-faktorelemzés-összehasonlítása",
    "href": "sec_feltaro_faktorelemzes.html#a-főkomponens-elemzés-és-a-faktorelemzés-összehasonlítása",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.1 A főkomponens elemzés és a faktorelemzés összehasonlítása",
    "text": "4.1 A főkomponens elemzés és a faktorelemzés összehasonlítása\n\nA főkomponens elemzés során az adatok teljes varianciáját vesszük figyelembe, míg faktorelemzés során a faktorokat csak a közös variancia alapján becsüljük. A két eljárás egyébként nagyon hasonló elvekre épül.\n\nFőkomponens elemzés során a korrelációs mátrix átlójában lévő 1-esek összege adja teljes varianciát, ami teljes egészében bekerül a faktormodellbe. Ezért ez az eljárás akkor javasolt, ha a fő cél, hogy meghatározzuk azon főkomponensek (faktorok) legkisebb számát, amelyek a legtöbb varianciát magyarázzák. Ezek a faktorok később jól alkalmazhatók többváltozós elemzésekben. Összegezve: a főkomponens elemzésnél részinformációkat próbálunk összegezni a lehető legkisebb információveszteséggel (vagyis a variancia maximalizálásával).\nAz ún. közös faktorelemzésnél a faktorokat csak a közös variancia alapján becsüljük, vagyis a kommunalitások kerülnek a korrelációs mátrix átlójába (ezek 1-nél kisebb számok). Összegezve a faktorelemzés általános célja egy látens, lineáris struktúra feltárása manifeszt változók segítségével."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#fogalmak",
    "href": "sec_feltaro_faktorelemzes.html#fogalmak",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.2 Fogalmak",
    "text": "4.2 Fogalmak\nA főkomponens- és fakorelemzésben a következő fogalmak fordulnak elő (a komponens és a faktor szavak felcserélhetők, attól függően, hogy főkomponens- vagy fakorelemzésről van szó).\n\nKommuninalitás: a variancia azon hányada, amelyen egy változó osztozik a többi elemzésbe vont változóval. Ez egyben a közös faktorok által magyarázott variancia aránya.\nSajátérték: Az egyes faktorok által magyarázott teljes varianciát fejezi ki.\nFaktorsúly: A változók és a faktorok közötti közönséges korreláció.\nFaktormátrix: Valamennyi változónak az összes előállított faktorra vonatkozó faktorsúlyát tartalmazza.\nFaktorértékek: Az előállított faktoroknak az egyes megkérdezettekre vonatkozóan becsült értékei.\nSajátértékábra (scree-plot, kőtörmelék ábra): A sajátértékek ábrázolása az előállított faktorok sorszámának függvényében.\nVarianciahányad: A teljes variancia egy adott faktornak tulajdonított része százalékban kifejezve."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#a-faktormodell",
    "href": "sec_feltaro_faktorelemzes.html#a-faktormodell",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.3 A faktormodell",
    "text": "4.3 A faktormodell\nA főkomponens és faktorelemzés annyiban hasonlít a többszörös regressziószámításhoz, hogy minden változót kifejezhető a háttérben meghúzódó faktorok lineáris kombinációjaként. Minden egyes változó kifejezhető kisszámú közös faktor és egy egyedi faktor segítségével. Ezek a faktorok nem figyelhetők meg közvetlenül. Standardizált kiinduló változók esetén a faktormodell így írható fel:\n\n\\(X_i=A_{i1} F_1+A_{i2} F_2+\\dots+ A_{im} F_m+V_i U_i\\), ahol\n\n\\(X_i\\) az \\(i.\\) standardizált változó\n\\(A_{i1}\\) az \\(i.\\) változó \\(j.\\) közös faktorra vonatkozó többszörös standardizált parciális regressziós együtthatója\n\\(F_j\\) a \\(j.\\) közös faktor\n\\(V_i\\) az \\(i.\\) változó \\(j.\\) egyedi faktorra vonatkozó többszörös standardizált parciális regressziós együtthatója\n\\(U_i\\) az \\(i.\\) változó egyedi faktora\n\\(m\\) a közös faktorok száma.\n\n\nAz egyedi faktorok egymással és a közös faktorokkal is korrelálatlanok. A közös faktorok kifejezhetők a megfigyelt változók lineáris kombinációiként:\n\n\\(F_i=W_{i1} X_1+W_i2 X_2+\\dots+ W_im X_m+\\dots+ W_ik X_k\\), ahol\n\n\\(F_i\\) az \\(i.\\) faktor becslése\n\\(W_i\\) súly vagy a faktorérték együtthatója\n\\(k\\) a változók száma\n\n\nA súlyokat vagy faktorérték együtthatókat úgy is meg lehet választani, hogy az első faktor magyarázza a teljes variancia legnagyobb részét, a második faktor a második legnagyobb részét és így tovább, valamint, hogy a faktorok korrelálatlanok legyenek egymással. Ez történik főkomponens elemzés esetén."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#a-faktorelmzés-menete",
    "href": "sec_feltaro_faktorelemzes.html#a-faktorelmzés-menete",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.4 A faktorelmzés menete",
    "text": "4.4 A faktorelmzés menete\n1. A probléma megfogalmazása\nA kutató arra volt kíváncsi, milyen előnyöket keresnek a fogyasztók a fogrémvásárlásnál. Egy 30 fős mintán a válaszadókat arra kérték, hogy jelezzék, mennyire értenek egyet a következő állításokkal (1 = egyáltalán nem ért egyet; 7 = teljes mértékben egyetért)\n\nv1: Fontos, hogy olyan fogkrémet vásároljak, amellyel megelőzhető a fogszuvasodás.\nv2: Az olyan fogkrémeket szeretem, amely fényessé teszi a fogaimat.\nv3: Egy fogkrémnek erősítenie kell a fogínyt.\nv4: Az olyan fogkrémeket szeretem, amely friss leheletet biztosít.\nv5: A fog romlásának megelőzése számomra nem fontos elvárás.\nv6: A legfontosabb szempont a fogkrém vásárlásánál a szép fog.\n\n2. A korrelációs mátrix előállítása\nA korrelációs mátrix előállítása során arra számítunk, hogy azok a változók, amelyek között magas a korreláció, ugyanazzal a faktorral fognak korrelálni.\n\n\n\nKorrelációs mátrix\n\n\nA fogkrémvásárlás során keresett előnyök korrelációs mátrix tanulmányozásával látható:\n\nviszonylag magas a korreláció a v1 (fogszuvasodás megelőzése), v3 (erős fogíny) és v5 (a fog romlásának megelőzése) között. Arra számítunk, hogy ezek a változók ugyanazokkal a faktorokkal fognak korrelálni.\nviszonylag magas a korreláció a v2 (fényes fogak), v4 (friss lehelet) és v6 (szép fogak) változók között, ezek is feltehetőleg ugyanazokkal a faktorokkal fognak korrelálni.\n\n3. Az alkalmazási feltételek ellenőrzése\nAhhoz, hogy a faktorelemzés alkalmazható legyen, a változóknak korrelálniuk kell egymással. Erről meggyőződhetünk kétféle objektív módszerrel is:\n\nBartlett-féle szferikus próba: nullhipotézise szerint a korrelációs mátrix egységmátrix (a változók korrelálatlanok), azaz az átlón kívül minden elem nulla. Amennyiben a nullhipotézis nem vethető el, a faktorelemzés alkalmazhatósága megkérdőjelezhető.\nKaiser-Meyer-Olkin-féle megfelelőségi mutató: a megfigyelt korrelációs együtthatók nagyságát viszonyítja a parciális korrelációs együtthatók nagyságához. Az alacsony KMO-mutató azt jelzi, hogy a változópárok közötti korreláció nem magyarázható más változókkal, így a faktorelemzés nem megfelelő módszer. Általában 0,5 fölött érték kívánatos.\n\nJamovi-ban a Factor / Exploratory Factor Analysis menüpontban tudjuk a fenti vizsgálatokat elvégezni.\n A Bartlett-féle szferikus próba szerint a pupulációban a korrelációs mátrix nem egységmátrix (ez számunkra kedvező), valamint a KMO-érték 0,66, ameéy elég magas (>0,5), így megállapíthatjuk, hogy a faktorelemzés alkalmas módszer a korrelációs mátrix elemzésére.\n4. A faktorelemzés módszerének meghatározása\nA faktorelemzés egyes módszerei abban különböznek egymástól, hogy milyen módon határozzák meg a súlyokat vagy faktorérték együtthatókat.\nA jamovi 3 módszert ismer a közös faktorok becslésére:\n\nPrincipal axis – főtengelyelemzés\nMinimum residuals\nMaximum likelihood\n\n5. A faktorok számának meghatározása\nA faktorelemzés akkor ér célt, ha a változók számánál kevesebb számú közös faktort hozunk létre. De mi legyen ez a szám. Több eljárás létezik. Ezeket részletesen a főkomponens elemzés során bemutattuk. Itt csak felsoroljuk őket:\n\nHorn-féle párhuzamos analízis (jamovi-ban: Based on parallel analysis)\nA priori meghatározás (jamovi-ban: Fixed number)\nSajátértéken alapuló megoldás (jamovi-ban: Based on eigenvalue)\nSajátértékábrán (scree-plot, kőtörmelék ábra) alapuló meghatározás (jamovi-ban: Scree plot)\nMagyarázott varianciahányadon alapuló meghatározás (jamovi-ban: Component summary)\n\n6. A faktorok forgatása\nA faktorelemzés fontos eredménye a faktormátrix (jamovi-ban: Factor Loadings).\n\n\n\nA faktormátrix\n\n\nA faktormátrix tartalmazza azokat az együtthatókat, amelyekkel a standardizált változókat ki lehet fejezni a faktorokkal. Ezeket az együtthatókat faktorsúlyoknak nevezzük, a faktorok és a faktorsúlyok közötti korrelációt mutatják. A magas abszolút értékű együttható azt jelzi, hogy a faktor és a változó szorosan összefügg. A faktormátrix együttható alapján lehet a faktorokat értelmezni.\nA kiinduló vagy rotálatlan faktormátrix jelzi ugyan az egyes változók és a faktorok kapcsolatát, de ritkán eredményez könnyen értelmezhető faktorokat. Ennek főképp az az oka, hogy a faktorok túl sok változóval korrelálnak. (A rotálatlan faktormátrix beállításához jamovi-ban a Rotation: None beállítást használjuk.)\nA faktorok forgatásával a faktormátrix egyszerűbbé, könnyebben értelmezhetővé válik. A faktorok forgatásával szeretnénk elérni:\n\nminden faktor csak néhány vátozóra rendelkezzen szignifikánsan nem nulla súllyal\nminden változónak lehetőleg egy faktorral legyen nem nulla, azaz szignifikáns faktorsúlya.\n\nA forgatás nem érinti a kommunalitásokat és a magyarázott varianciahányadot, azonban az egy faktor által magyarázott varianciahányad változik (és természetesen a faktorsúlyok is).\nA forgatási módszereket érdemes jól megválasztani, mert más-más faktorok azonosításához vezetnek.\nAz ortogonális (derékszögű) forgatási eljárások egymással nem korreláló faktorokat eredményeznek.\n\nEzek közül az egyik legnépszerűbb a Varimax eljárás, amely minimalizálja a nagy faktorsúllyal rendelkező változók számát, így segíti a faktorok értelmezését. A magyarázott variancia egyenletesen próbálja elosztani a faktorok között.\nA Quartimax eljárás első faktorként egy általános faktort faktort hoz létre, amellyel szinte mindegyik változó magasan korrelál.\n\nA ferdeszögű forgatási eljárások során a tengelyek hegyeszöget zárnak be egymással, és a kapott faktorok korrelálni fognak egymással. Ferdeszögű forgatást akkor kell használni, ha feltételezhető, hogy a sokaságban a faktorok erősen összefüggenek.\n\nA Promax eljárás gyorsan lefuttatható, amely főképp nagy adatbázisoknál jelent előnyt.\nA Simplimax a Promax egy módosított formája.\nAz Oblimin eljárás a tengelyek egymással bezárt szögét fokozatosan változtatja, ami egyben a faktorok korreláltságát is meghatározza.\n\n7. A faktorok értelmezése\nAz értelmezést megkönnyíti, ha meghatározzuk azokat a változókat, amelyeknek ugyanazon a faktorra nagy a súlyuk. A faktort a magas faktorsúlyú változók alapján lehet értelmezni.\nAz 1. faktornak magasabb az együtthatói a v1 (fugszuvasodás megelőzése), v3 (erős fogíny) változókkal, negatív az együttható a v5 (a fog romlásának megeleőzése nem fontos) változó esetében. Ezt a faktort az “egészséggel kapcsolatos előnyöknek” nevezhetjük. A 2. faktor a v2 (fényes fogak), a v4 (friss lehelet), v6 (szép fogak) változókkal függ össze. Ezt a 2. faktort “társadalmi előnyök”-nek nevezhetjük.\nÖsszegezve, a fogyasztók feltehetőleg két fő előnyt keresnek a fogkrémvásárlás során: egészséggel kapcsolatos és társadalmi előnyöket.\n8. A faktorértékek kiszámítása\nA faktorelemzésnek önmagában is van értelme, hiszen látens változók azonosításához vezet, azonban hasznos lehet a későbbi elemzések számára a faktorértékek kiszámítása minden egyes megkérdezettre. A faktor az eredeti változók lineáris kombinációja. A standardizált változó értékeinek és a megfelelő faktorérték-együtthatónak a szorzata adja a faktorétéket, amely jelen példában minden válaszadóra két faktorértéket jelent. A faktorérték csak főkomponens elemzés esetében lehet pontosan kiszámítani, egyébként csak közelítő értékeket kapunk.\n\n\n\nFaktorértékek kiszámítása"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#illeszkedési-mutatók",
    "href": "sec_feltaro_faktorelemzes.html#illeszkedési-mutatók",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.5 Illeszkedési mutatók",
    "text": "4.5 Illeszkedési mutatók\n\nCFI - összehasonlító illeszkedési mutató (Comparative Fit Index) - A CFI azt méri fel, hogy egy feltételezett hipotetikus modell milyen mértékben reprodukálja a valós adatokon nyugvó kovarianciamátrixot egy független modellhez képest.\nTLI - Tucker–Lewis-féle Illeszkedési mutató - A TLI a CFI-hez hasonló módon méri az illeszkedést, annyi különbséggel, hogy ez a mutató a modellben használt szabadságfokot is figyelembe veszi, így kiküszöböli a vizsgálati minta méretének befolyásoló szerepét\n\nA CFI és TLI mutatók értéke 0 és 1 közötti tartományba eshet, ahol az 1-hez közeli érték jelzi a szoros illeszkedést. Kezdetben a mutatók elfogadhatósági kritériumának 0,90-et adtak meg, de az utóbbi időkben inkább a 0,95-ot tekintik az elfogadhatóság alsó határának.\n\nRMSEA - a becslési hiba négyzetes átlagának gyöke (Root-Mean-Square Error of Approximation) - A Steiger-féle RMSEA mutatót a modell populációs kovariancia mátrixhoz viszonyított illeszkedésének becsléséhez használjuk. Az RMSEA az elemszámtól függetlenül hasonlítja össze, hogy a valós és az optimális paraméterekkel rendelkező hipotetikus modell kovarianciamátrixa milyen mértékben illeszkedik. Az RMSEA a modell takarékosságának megbízható jelzője, a komplex modellek hibás specifikálásának hatékony mutatója. Az RMSEA értéke is 0 és 1 közé eshet, itt azonban a kisebb, 0-hoz közel eső érték jelzi a jobb illeszkedést. Browne és Cudeck (1993) szerint az RMSEA értékei 0,05-ig szoros illeszkedést jeleznek; 0,08-os értékig pedig megfelelő illeszkedést, elfogadható populáción belüli becslési hibákkal.\n\nModel Test\nAz adatok és a teoretikus modell egybeesésének vizsgálata. Az egyik leggyakrabban használt illeszkedési mutató a \\(\\chi^2\\)-próba mértéke, amelyet általában akkor tekinthetünk elfogadhatónak, ha a szabadságfokhoz viszonyított értéke alacsony (pl. kisebb, mint a szabadságfok kétszerese) és nem szignifikáns (p > 0,05). Ennek a mutatónak azonban több korlátja létezik. A legjellemzőbbek a többváltozós normalitás sérülésére és a mintanagyságra való érzékenység. Számos empirikus eredmény és szimulációs vizsgálat támasztja alá, hogy a normalitás sérülésekor vagy nagy elemszámú minta esetében a \\(\\chi^2\\)-próba kevésbé informatív, és a legtöbb esetben a modell elvetését jelzi. A mintanagyságból fakadó korlátot gyakran a \\(\\chi^2\\)-próba szabadságfokhoz mért arányával próbálják kompenzálni (\\(\\chi^2\\)/szabadságfok), amelynek ugyan nincs pontos kritériuma, de az ajánlások általában 2-től 5-ig terjednek, és a határérték alatti érték jelez megfelelő illeszkedést.\n\n\n\nIlleszkedési mutatók"
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa",
    "href": "sec_feltaro_faktorelemzes.html#példa",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.6 1. Példa",
    "text": "4.6 1. Példa\nValóban szétválasztható a reál és a humán tárgyakhoz szükséges tudás?\nÖsszefoglalva, az adatokra jól illeszkedik a kétfaktoros modell, vagyis azonosíthatjuk a humán és a reál tárgyakat az egyes tantárgyakból nyújtott eredmények alapján. Az egyes tárgyak faktorba történő besorolása összhangban van „hétköznapi”, előzetes tudásunkkal: a matek, informatika és a kémia sorolható a reál, míg az irodalom, nyelvtan és angol tárgyak a humán tárgyakhoz."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-1",
    "href": "sec_feltaro_faktorelemzes.html#példa-1",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.7 2. Példa",
    "text": "4.7 2. Példa\nMilyen dimenziói vannak a kockázatvállalásnak és változik-e a korral a kockázatvállalás?\nA példák is mutatják, hogy a kockázatvállalásokat csoportosíthatjuk a kockázatot jelentő tényezők alapján, ahol az egyik csoportban az emberek saját testi épségüket teszik kockára (mint az autóversenyzés esetében), de kockáztathatnak pénzt vagy valamilyen becsületbeli dolgot is (mint a kártyázás és a blöffölés esetében). Példánkban megnézzük, hogy a faktoranalízis alátámasztja-e feltevésünket, majd a faktoranalízis eredményeit felhasználva megnézzük, hogy a kockázatvállaló viselkedésre hatással van-e a kor.\nAz adatbázisban szereplő adatokat úgy kaptuk, hogy a vizsgálati személyeknek különböző foglalkozású, illetve különböző tevékenységet végző embereket kellett megítélniük, hogy mennyire tartják őket szimpatikusnak egy 1-7 skálán, ahol a 7 jelentette azt, hogy nagyon szimpatikus. Ily módon megkaptuk a személyek kockázat iránti attitűdjét. A változók között olyan személyek szerepelnek, mint kártyajátékosok, autóversenyzők, üzletemberek (akik sok pénzt kockáztatnak), veszélyes sportot űző emberek, nagy pénzekben fogadó emberek, blöffölők és hivatásos katonák.\nEzen kívül két adat szerepel az adatbázisban: a nem és a kor.\nÖsszefoglalva, sikerült a faktoranalízissel alátámasztanunk a kockázatvállalás két faktorát. Azt is megállapítottuk, hogy mindkét faktor függ a kortól: az anyagi/erkölcsi téren vállalt kockázat iránti attitűd az évek múlásával egyre kedvezőbbé válik, míg a testi épség terén vállalt kockázat iránti attitűd idővel egyre elutasítóbbá válik."
  },
  {
    "objectID": "sec_feltaro_faktorelemzes.html#példa-2",
    "href": "sec_feltaro_faktorelemzes.html#példa-2",
    "title": "4  Feltáró faktorelemzés",
    "section": "4.8 3. Példa",
    "text": "4.8 3. Példa\nEgy kérdőív szerkesztésének problémái\nEgy jó kérdőív kialakítása hosszas és nagyon alapos munkát igényel. Egyik lépése, hogy megnézzük, az itemek valóban egy dimenzióra illeszkednek-e. A nem odaillő itemeket pedig kivesszük a kérdőívből (itemszelekció). Ennek módszerei lehetnek a korábban már tárgyalt Cronbach-alfa, illetve ha főkomponens-analízist végzünk az itemekkel, akkor a Theta is. A következőkben egy főkomponens-analízisen és Cronbach-alfán alapuló itemszelekcióra nézünk példát.\n\n\n\n\nRózsa, S., Hupuczi, E., Martin, L., Birkás, B., Hartung, I., Hargitai, R., Varga, J., Láng, A., Tiringer, I. és Kállai, J. (2019). A Tellegen Abszorpciós Skála részletes pszichometriai elemzése. Mentálhigiéné és Pszichoszomatika, 20, 35–77. https://doi.org/10.1556/0406.20.2019.003\n\n\nWatkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best Practice. Journal of Black Psychology, 44, 219–246. https://doi.org/10.1177/0095798418771807"
  },
  {
    "objectID": "sec_megerosito_faktorelemzes.html",
    "href": "sec_megerosito_faktorelemzes.html",
    "title": "5  Megerősítő faktorelemzés",
    "section": "",
    "text": "Tehát az a kísérletünk, hogy az EFA segítségével azonosítsuk a mögöttes látens tényezőket a személyiségi elemkészletből gondosan kiválasztott kérdésekkel, meglehetősen sikeresnek tűnt. A személyiség hasznos mérőszámának kidolgozására irányuló törekvésünk következő lépése az eredeti EFA-ban azonosított látens tényezők ellenőrzése egy másik mintán. Azt akarjuk látni, hogy a tényezők helytállóak-e, meg tudjuk-e igazolni létezésüket különböző adatokkal. Ez egy szigorúbb ellenőrzés, mint látni fogjuk. És ezt Confirmatory Factor Analysisnek (CFA) hívják, mivel nem meglepő módon egy előre meghatározott látens faktorstruktúra megerősítésére törekszünk.\nA CFA-ban ahelyett, hogy olyan elemzést végzünk, amelyben az adatok feltáró értelemben vett együttállását látjuk, ehelyett struktúrát írunk elő, mint a 15.13. ábrán, és megnézzük, hogy az adatok mennyire illeszkednek az előre megadott struktúránkhoz. Ebben az értelemben egy megerősítő elemzést végzünk, hogy megnézzük, mennyire erősítik meg a megfigyelt adatok egy előre meghatározott modellt.\nA személyiségelemek egyszerű megerősítő faktoranalízise (CFA) ezért öt látens faktort határoz meg, amint azt a 15.13. ábra mutatja, mindegyiket öt megfigyelt változóval mérve. Mindegyik változó egy mögöttes látens tényező mértéke. Például az A1-et a mögöttes látens egyetértési tényező előrejelzi. És mivel A1 nem tökéletes mértéke az elfogadhatósági tényezőnek, van egy hibatag, , kapcsolódik hozzá. Más szavakkal, az A1 eltérését jelenti, amelyet az egyetértési tényező nem vesz figyelembe. Ezt néha mérési hibának nevezik."
  },
  {
    "objectID": "sec_tobbszempontos_variancielemzes.html",
    "href": "sec_tobbszempontos_variancielemzes.html",
    "title": "6  Többszempontos varianciaelemzés",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "sec_klaszter.html#hierarchikus-eljárások",
    "href": "sec_klaszter.html#hierarchikus-eljárások",
    "title": "7  Klaszterelemzés",
    "section": "7.1 Hierarchikus eljárások",
    "text": "7.1 Hierarchikus eljárások\nA hierarchikus eljárások az egyes személyek, objektumok, esetek közötti távolság meghatározásával kezdődnek. A csoportok, klaszterek kialakítása történhet összevonáson vagy felosztáson alapuló módszerekkel. Az összevonó módszerek abból indulnak ki, hogy minden egyes elem egy önálló csoportot alkot, majd fokozatosan vonják össze az egyelemes csoportokat egyetlen nagy csoportba. Ezzel szemben a lebontó módszerben az összes elem egyetlen csoportba tartozik, és ezt a csoportot osztjuk fel kettő, majd egyre több csoportra addig, amíg minden elem egy önálló csoportot nem alkot. Az összevonó módszernél kezdetben minden egyes elem külön klasztert alkot. A klaszterek a megfigyelési egységek egyre nagyobb klaszeterekbe csoportosításával alakulnak ki. A folyamat addig folytatódik, amíg egyetlen klaszter lesz az egész. A következőkben a legelterjedtebb klaszteralkotó módszereket soroljuk fel:\n\nEgyszerű lánc, avagy a legközelebbi szomszéd elve\nTeljes lánc, avagy a legtávolabbi szomszéd elve\nÁtlagos távolság\nVariancia-módszerek\nWard-féle eljárás\nCentroidmódszerek\nSzekvenciális küszöbérték módszer\nPárhuzamos küszöbérték módszer\nOptimális felosztás módszere\n\nJamovi-ban a snowCluster csomag segítségével végethetünk klaszterelemzéseket. A csomag telepítése után a snowCluster / Hiearchical Clustering vagy snowCluster / Clustering Dendogram menüpontokat használjuk.\nA jamovi a következő módszereket ismeri:\n\nward.D\nward.D2\nsingle\ncomplete\naverage"
  },
  {
    "objectID": "sec_klaszter.html#k-középpontú-klaszterelemzés",
    "href": "sec_klaszter.html#k-középpontú-klaszterelemzés",
    "title": "7  Klaszterelemzés",
    "section": "7.2 K-középpontú klaszterelemzés",
    "text": "7.2 K-középpontú klaszterelemzés\nJÖN."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-kikből-lesznek-a-balesetezők",
    "href": "sec_diszkrimninancia.html#példa-kikből-lesznek-a-balesetezők",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.1 Példa: Kikből lesznek a balesetezők?",
    "text": "8.1 Példa: Kikből lesznek a balesetezők?\nEbben a példában azt vizsgáljuk, mely tényezők járulnak hozzá a balesetekhez.\n\nbaleset <- rio::import(file = \"adat/diszkriminancia_baleset.xlsx\")\nbaleset$baleset <- factor(baleset$baleset, labels = c(\"nem volt baleste\",\n    \"volt baleste\"))\nstr(baleset)\n#> 'data.frame':    36 obs. of  5 variables:\n#>  $ baleset   : Factor w/ 2 levels \"nem volt baleste\",..: 1 1 ...\n#>  $ megosztott: num  7 6 5 6 7 3 6 7 5 6 ...\n#>  $ pontossag : num  6 6 5 6 7 3 5 7 5 6 ...\n#>  $ kockazat  : num  2 3 1 2 4 7 2 1 3 2 ...\n#>  $ eszleles  : num  7 6 5 6 7 7 7 6 3 7 ...\npsych::headTail(baleset)\n#>              baleset megosztott pontossag kockazat eszleles\n#> 1   nem volt baleste          7         6        2        7\n#> 2   nem volt baleste          6         6        3        6\n#> 3   nem volt baleste          5         5        1        5\n#> 4   nem volt baleste          6         6        2        6\n#> ...             <NA>        ...       ...      ...      ...\n#> 33      volt baleste          3         3        5        4\n#> 34      volt baleste          2         2        7        1\n#> 35      volt baleste          3         3        4        4\n#> 36      volt baleste          4         4        6        4\n\nAz adatbázisban a baleset változó azt rögzíti, hogy volt-e már balesete a személynek vagy sem. Ez lesz tehát a csoportosító változó. A többi változó, melyek segítségével próbáljuk a csoportok közötti különbséget jellemezni, olyan dolgot mérnek, mint a megosztott figyelem (megosztott változó), a figyelem pontossága (pontossag), kockázatvállalási hajlandóság (kockazat) és az észlelés gyorsasága (eszleles).\nA diszkriminancia-analízisben az első lépés annak megállapítása, vajon valóban szét lehet-e választani a balesetezők és a nem balesetezők csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(megosztott, pontossag, kockazat, eszleles) ~ baleset,\n    data = baleset)\nsummary(man_1, test = \"Wilks\")\n#>           Df   Wilks approx F num Df den Df    Pr(>F)    \n#> baleset    1 0.27605   20.324      4     31 2.645e-08 ***\n#> Residuals 34                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a balesetet szenvedett és a balesetmentes autóvezetők között.\nFuttassuk le a diszkriminancia-analízis.\n\nlda_1 <- MASS::lda(baleset ~ megosztott + pontossag + kockazat + eszleles,\n    data = baleset)\nlda_1\n#> Call:\n#> lda(baleset ~ megosztott + pontossag + kockazat + eszleles, d...\n#> \n#> Prior probabilities of groups:\n#> nem volt baleste     volt baleste \n#>        0.4722222        0.5277778 \n#> \n#> Group means:\n#>                  megosztott pontossag kockazat eszleles\n#> nem volt baleste   5.941176  5.647059 2.588235 5.941176\n#> volt baleste       2.842105  2.684211 5.578947 3.105263\n#> \n#> Coefficients of linear discriminants:\n#>                    LD1\n#> megosztott -0.25764616\n#> pontossag  -0.07708289\n#> kockazat    0.36270659\n#> eszleles   -0.36702363\n\nA fenti output alapján az előzetes valószínűsége annak, hogy valakinek még nem volt balesete 0,472, míg annak a valószínűsége, hogy már volt balesete a személynek 0,528. Ezután vizsgálhatjuk a csoportátlagokat. A balesetmentes vezetők esetében magasabb a megosztott figyelem, a figyelem pontosságának és az észlelés változójának az átlaga, míg a kockázatvállalásé alacsonyabb. Ugyanakkor a másik csoport esetében a kockázatvállalás változójának az átlaga magasabb, míg a másik három képesség változójának átlaga alacsonyabb. Vagyis a balesetmentes vezetők gyorsabban képesek észlelni és jobban meg tudják osztani a figyelmüket, figyelmük pontosabb. A balesetet szenvedett vezetők esetében ezek a képességek gyengébbek, míg jobban szeretnek kockázatot vállalni.\nVégül a kanonikus diszkriminancia együtthatók segítségével felírhatjuk a kanonikus diszkriminancia-függvényt a következő módon:\nZ = 0,3627 * kockázat - 0,367 * észlelés - 0,2567 * megosztott-0,0771 * pontosság\nUtolsó lépésként pedig megnézhetjük, mennyire hatékony a diszkriminancia-analízis vagyis összevethetjük az eredeti csoporttagságokat a modell alapján alkotott besorolásokkal.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, baleset$baleset)\ntab_1\n#>                   \n#>                    nem volt baleste volt baleste\n#>   nem volt baleste               16            2\n#>   volt baleste                    1           17\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 91.66667\n\nA fenti sorok elkészík a predikciót, majd egy táblázatban reprezentálják az eredeti és a becsült csoportba tartozásokat. A legtöbb adat a főátlóban helyezkedik el, ami igen magas helyes besorolási arányra utal. A helyes besorolások aránya 91,7%.\nA példában a gépjárműbalesetek emberi okait vizsgáltuk. Az eredmények alapján a balesetmentes vezetők gyorsabban képesek észlelni és jobban meg tudják osztani a figyelmüket, figyelmük pontosabb is. Ellenben a balesetet szenvedett vezetők esetében ezek a képességek gyengébbek, míg jobban szeretnek kockázatot vállalni."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-a-szülés-utáni-depresszió-vizsgálata",
    "href": "sec_diszkrimninancia.html#példa-a-szülés-utáni-depresszió-vizsgálata",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.2 Példa: A szülés utáni depresszió vizsgálata",
    "text": "8.2 Példa: A szülés utáni depresszió vizsgálata\nEbben a példában a szülés utáni depresszió pszichés és szociális hátterét vizsgáljuk meg a diszkriminancia-analízis segítségével.\n\ndepresszio <- rio::import(file = \"adat/diszkriminancia_depresszio.xlsx\")\ndepresszio$ppdepresszio <- factor(depresszio$ppdepresszio, labels = c(\"nincs depresszió\",\n    \"van depresszió\"))\nstr(depresszio)\n#> 'data.frame':    20 obs. of  5 variables:\n#>  $ ppdepresszio: Factor w/ 2 levels \"nincs depresszió\",..: 1 ...\n#>  $ szeretet    : num  7 6 2 6 7 4 6 7 6 7 ...\n#>  $ tulvedes    : num  4 2 8 3 9 5 3 5 3 5 ...\n#>  $ kor         : num  24 20 19 22 23 25 26 18 19 22 ...\n#>  $ iskola      : num  12 17 8 16 17 17 12 17 16 17 ...\npsych::headTail(depresszio)\n#>         ppdepresszio szeretet tulvedes kor iskola\n#> 1   nincs depresszió        7        4  24     12\n#> 2   nincs depresszió        6        2  20     17\n#> 3   nincs depresszió        2        8  19      8\n#> 4   nincs depresszió        6        3  22     16\n#> ...             <NA>      ...      ... ...    ...\n#> 17    van depresszió        4        7  30      6\n#> 18    van depresszió        4        6  24      8\n#> 19    van depresszió        3        7  21      9\n#> 20    van depresszió        2        8  18     10\n\nAz adatbázisban a ppdepresszio változó mutatja a depresszió jelenlétét, vagy hiányát. A magyarázó változók között a következő változók szerepelnek: a szeretet skála (szeretet változó), amely azt méri, hogy a személyek mennyire érzik, hogy a szüleik szeretik őket; tulvedes-sel jelölt túlvédés iránti tendencia azt mutatja, hogy mennyire hajlamosak arra a személyek, hogy túlságosan is burokban tartsák, túlvédjék gyerekeiket, illetve szeretteiket; ezeken kívül két szociológiai adat is a rendelkezésünkre áll, nevezetesen az életkor (kor változó) és az elvégzett iskolai osztályok száma (iskola).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a depressziósok és a nem depressziósok csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(szeretet, tulvedes, kor, iskola) ~ ppdepresszio,\n    data = depresszio)\nsummary(man_1, test = \"Wilks\")\n#>              Df   Wilks approx F num Df den Df    Pr(>F)    \n#> ppdepresszio  1 0.29985   8.7561      4     15 0.0007461 ***\n#> Residuals    18                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a depressziós és a nem depressziós nők között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést!\n\nlibrary(MASS)\nlda_1 <- lda(ppdepresszio ~ szeretet + tulvedes + kor + iskola, data = depresszio)\nlda_1\n#> Call:\n#> lda(ppdepresszio ~ szeretet + tulvedes + kor + iskola, data =...\n#> \n#> Prior probabilities of groups:\n#> nincs depresszió   van depresszió \n#>              0.5              0.5 \n#> \n#> Group means:\n#>                  szeretet tulvedes  kor iskola\n#> nincs depresszió      5.8      4.7 21.8   14.9\n#> van depresszió        3.3      7.5 24.0    8.3\n#> \n#> Coefficients of linear discriminants:\n#>                  LD1\n#> szeretet -0.21900671\n#> tulvedes  0.18422053\n#> kor       0.03467147\n#> iskola   -0.26661705\n\nAz fenti output alapján az előzetes valószínűségek egyenlőek. A csoportátlagok közötti különbségek azt mutatják, hogy a nem depressziósok átlaga szeretet tekintetében magasabb (5,8), mint a depressziósoké (3,3), az iskolai végzettségük is magasabb (14,9), mint a depressziósoké (8,3). Ellenben a túlvédésnél a depressziósok értek el magasabb átlagot, ők az idősebbek is (24). Vagyis azok, akik postpartum depresszióban szenvednek, úgy érzik, a szüleik kevésbé szeretik őket, túlvédőbbek a gyerekeikkel szemben, idősebbek, és az iskolai végzettségük is alacsonyabb. A kanonikus diszkriminancia egyenlet alakja:\nZ =0,1842 * túlvédés + 0,0347 * kor - 0,2666 * iskola - 0,219 * szeretet\nUtolsó momentumként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, depresszio$ppdepresszio)\ntab_1\n#>                   \n#>                    nincs depresszió van depresszió\n#>   nincs depresszió                9              0\n#>   van depresszió                  1             10\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 95\n\nLáthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit, az arány 95%.\nVagyis azok, akik postpartum depresszióban szenvednek, úgy érzik, a szüleik kevésbé szeretik őket, túlvédőbbek a gyerekeikkel szemben, idősebbek, és az iskolai végzettségük is alacsonyabb."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-pszichoszomatikus-megbetegedésekre-hajlamosító-tényezők",
    "href": "sec_diszkrimninancia.html#példa-pszichoszomatikus-megbetegedésekre-hajlamosító-tényezők",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.3 Példa: Pszichoszomatikus megbetegedésekre hajlamosító tényezők",
    "text": "8.3 Példa: Pszichoszomatikus megbetegedésekre hajlamosító tényezők\nEbben a példában a pszichoszomatikus megbetegedéseket vizsgáljuk a diszkriminancia-analízis segítségével.\n\npszichoszomatikus <- rio::import(file = \"adat/diszkriminancia_pszichoszomatika.xlsx\")\npszichoszomatikus$pszichoszomatika <- factor(pszichoszomatikus$pszichoszomatika,\n    labels = c(\"pszichoszomatikus megbetegedése van\", \"egészséges\"))\nstr(pszichoszomatikus)\n#> 'data.frame':    36 obs. of  4 variables:\n#>  $ pszichoszomatika: Factor w/ 2 levels \"pszichoszomatikus me...\n#>  $ stressz         : num  5 6 5 6 7 3 6 7 5 6 ...\n#>  $ szorongas       : num  6 6 5 6 7 3 3 7 5 6 ...\n#>  $ coping          : num  2 3 1 2 4 7 2 1 3 2 ...\npsych::headTail(pszichoszomatikus)\n#>                        pszichoszomatika stressz szorongas coping\n#> 1   pszichoszomatikus megbetegedése van       5         6      2\n#> 2   pszichoszomatikus megbetegedése van       6         6      3\n#> 3   pszichoszomatikus megbetegedése van       5         5      1\n#> 4   pszichoszomatikus megbetegedése van       6         6      2\n#> ...                                <NA>     ...       ...    ...\n#> 33                           egészséges       3         3      5\n#> 34                           egészséges       2         2      7\n#> 35                           egészséges       3         3      4\n#> 36                           egészséges       4         4      6\n\nAz adatbázisban most a pszichoszomatika változó jelzi, hogy valamilyen pszichoszomatikus megbetegedése van vagy nincs a személynek. A változók közt szerepel a személyt ért stressz mértéke (stressz), a szorongási szintje (szorongás) és a megküzdési stratégiáinak hatékonysága (coping).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a pszichoszomatikusok és a nem pszichoszomatikusok csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(stressz, szorongas, coping) ~ pszichoszomatika, data = pszichoszomatikus)\nsummary(man_1, test = \"Wilks\")\n#>                  Df   Wilks approx F num Df den Df   Pr(>F)    \n#> pszichoszomatika  1 0.37974   17.423      3     32 6.92e-07 ***\n#> Residuals        34                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti output tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a két csoport között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést.\n\nlibrary(MASS)\nlda_1 <- lda(pszichoszomatika ~ stressz + coping + szorongas, data = pszichoszomatikus)\nlda_1\n#> Call:\n#> lda(pszichoszomatika ~ stressz + coping + szorongas, data = p...\n#> \n#> Prior probabilities of groups:\n#> pszichoszomatikus megbetegedése van \n#>                           0.4722222 \n#>                          egészséges \n#>                           0.5277778 \n#> \n#> Group means:\n#>                                      stressz   coping szorongas\n#> pszichoszomatikus megbetegedése van 5.764706 2.588235  5.529412\n#> egészséges                          2.842105 5.578947  2.684211\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1\n#> stressz   -0.31309547\n#> coping     0.46637406\n#> szorongas -0.06258674\n\nA fenti outputból láthatjuk, hogy a csoporttagságok előzetes valószínűsége a pszichoszomatikusok esetében kicsit kisebb (0,472). A két csoport összevetésénél azt láthatjuk, hogy a stressz és a szorongás változó átlaga a pszichoszomatikusok esetében, míg a coping változó átlaga az egészségesen esetében magasabb. Vagyis az egészséges személyeket kevesebb stressz éri, és azzal hatékonyabban is tudnak megküzdeni, mint a pszichoszomatikusok, illetve kevesebbet is szoronganak.\nA kanonikus diszkriminancia egyenlet pedig a következő módon alakul:\nZ = 0.4664 * coping - 0,3131 * stressz - 0,0626 * szorongas\nUtolsó lépésként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, pszichoszomatikus$pszichoszomatika)\ntab_1\n#>                                      \n#>                                       pszichoszomatikus megbe...\n#>   pszichoszomatikus megbetegedése van                        ...\n#>   egészséges                                                 ...\n#>                                      \n#>                                       egészséges\n#>   pszichoszomatikus megbetegedése van          2\n#>   egészséges                                  17\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 91.66667\n\nAz eredményen láthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit. Ez az arány 91,7%.\nEbben a példában a pszichoszomatikus megbetegedések lelki okait vizsgáltuk. Az diszkriminancia-analízis eredménye szerint az egészséges személyeket kevesebb stressz éri, és azzal hatékonyabban is tudnak megküzdeni, mint a pszichoszomatikusok, valamint kevesebbet is szoronganak."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-kik-vásárolnak-gyakran-bio-termékeket",
    "href": "sec_diszkrimninancia.html#példa-kik-vásárolnak-gyakran-bio-termékeket",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.4 Példa: Kik vásárolnak gyakran bio termékeket?",
    "text": "8.4 Példa: Kik vásárolnak gyakran bio termékeket?\nUtolsó példánk a marketingkutatás területére kalauzol minket. Azt próbáljuk megvizsgálni, hogy főként kik vásárolnak bio termékeket.\n\nbio <- rio::import(file = \"adat/diszkriminancia_bio.xlsx\")\nbio$vasarlas <- factor(bio$vasarlas, labels = c(\"soha nem vesz\", \"időnként vesz\",\n    \"gyakran vesz\"))\ntable(bio$vasarlas)\n#> \n#> soha nem vesz időnként vesz  gyakran vesz \n#>            10            10            10\nstr(bio)\n#> 'data.frame':    30 obs. of  5 variables:\n#>  $ vasarlas: Factor w/ 3 levels \"soha nem vesz\",..: 1 1 1 1 1...\n#>  $ ertek   : num  2 4 2 3 1 1 2 3 4 6 ...\n#>  $ attitud : num  2 4 2 3 1 3 5 3 1 2 ...\n#>  $ fizetes : num  55 67 89 78 99 112 132 78 95 64 ...\n#>  $ kor     : num  32 56 59 48 44 39 37 40 44 43 ...\npsych::headTail(bio)\n#>          vasarlas ertek attitud fizetes kor\n#> 1   soha nem vesz     2       2      55  32\n#> 2   soha nem vesz     4       4      67  56\n#> 3   soha nem vesz     2       2      89  59\n#> 4   soha nem vesz     3       3      78  48\n#> ...          <NA>   ...     ...     ... ...\n#> 27   gyakran vesz     6       6      62  19\n#> 28   gyakran vesz     9       9      69  27\n#> 29   gyakran vesz     9       9      78  28\n#> 30   gyakran vesz     8       8      73  30\n\nAz adatbázisban a vasarlas változó mutatja a biotermékek vásárlásának gyakoriságát, amely három értéket vehet fel: a személy szinte soha nem vesz ilyen termékeket, időnként vesz, illetve gyakran vesz. A vásárlás gyakoriságát a következő változókkal próbáljuk előre jelezni: milyen értékeket tulajdonít ezeknek a termékeknek (ertek változó, minél nagyobb pontszámot kap a skálán, annál jobban értékeli a személy a bio termékeket); az attitud skála a termékek iránti attitűdöt méri, a magasabb értékek itt is kedvezőbb atttitűdöt jeleznek; ezen túl szerepel még a személy életkora (kor változó) és a fizetése is (fizetes).\nA diszkriminancia-analízisben az első lépésében megvizsgáljuk, vajon valóban szét lehet-e választani a bio termékeket vásárlók három csoportját az adott változók alapján. Ehhez a Wilks-lambda tesztet használjuk a többváltozós variancia-analízis keretein belül.\n\nman_1 <- manova(cbind(ertek, attitud, fizetes, kor) ~ vasarlas, data = bio)\nsummary(man_1, test = \"Wilks\")\n#>           Df   Wilks approx F num Df den Df    Pr(>F)    \n#> vasarlas   2 0.12109   11.242      8     48 8.599e-09 ***\n#> Residuals 27                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary.aov(man_1)\n#>  Response ertek :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> vasarlas     2 146.07  73.033  27.656 2.915e-07 ***\n#> Residuals   27  71.30   2.641                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response attitud :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> vasarlas     2 211.67 105.833  57.495 1.853e-10 ***\n#> Residuals   27  49.70   1.841                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response fizetes :\n#>             Df  Sum Sq Mean Sq F value  Pr(>F)  \n#> vasarlas     2  6427.5  3213.7  3.1857 0.05726 .\n#> Residuals   27 27237.5  1008.8                  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response kor :\n#>             Df Sum Sq Mean Sq F value   Pr(>F)   \n#> vasarlas     2 1449.3  724.63  7.3001 0.002922 **\n#> Residuals   27 2680.1   99.26                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti elemzés tesztstatisztikájának szignifikanciaszintje azt mutatja, hogy a csoportok közötti különbségek szignifikánsak, vagyis valóban van különbség a három csoport között az adott változókat vizsgálva.\nVégezzük el a diszkriminancia elemzést.\n\nlibrary(MASS)\nlda_1 <- lda(vasarlas ~ ertek + attitud + fizetes + kor, data = bio)\nlda_1\n#> Call:\n#> lda(vasarlas ~ ertek + attitud + fizetes + kor, data = bio)\n#> \n#> Prior probabilities of groups:\n#> soha nem vesz időnként vesz  gyakran vesz \n#>     0.3333333     0.3333333     0.3333333 \n#> \n#> Group means:\n#>               ertek attitud fizetes  kor\n#> soha nem vesz   2.8     2.6    86.9 44.2\n#> időnként vesz   5.3     5.6   106.5 34.9\n#> gyakran vesz    8.2     9.1    70.7 27.2\n#> \n#> Coefficients of linear discriminants:\n#>                  LD1          LD2\n#> ertek    0.278041839 -0.175361797\n#> attitud  0.578431017  0.066376341\n#> fizetes -0.003687657 -0.032311789\n#> kor     -0.019282287  0.003972177\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9687 0.0313\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\nA fenti output alapján az elemzés elején a három vásárlási gyakoriság valószínűsége egyenlő (0,333). Ha a csoportátlagokat vizsgáljuk akkor láthatjuk, hogy mind az értékek, mind az attitűd változójának tekintetében a soha sem vásárolók átlaga a legalacsonyabb (3 mindkét változó esetében), az időnként bio termékeket vásárlók csoport átlaga középen helyezkedik el mind a két változó esetében (5 és 6), és a gyakran vásárlók átlaga a legmagasabb (8 és 9). Életkor tekintetében egy kissé másképpen alakulnak a csoportok. A legidősebbek szinte sohasem vásárolnak bio termékeket, a legfiatalabbak pedig igen gyakran vásárolnak. Fizetés tekintetében nem figyelhető meg jól magyarázható összefüggés: a legalacsonyabb fizetésűek gyakran, míg a közepes fizetésűek szinte soha sem vásárolnak bio termékeket.\nA két kanonikus diszkriminancia-egyenlet a következőképpen alakul:\nZ1 = 0,278 * ertek + 0,578 * attitud - 0,019 * kor - 0,004 *fizetes\nZ2 = -0,175 * ertek + 0,066 * attitud + 0,004 * kor - 0,032 *fizetes\nUtolsó lépésként az analízis értékelésére van még szükség.\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, bio$vasarlas)\ntab_1\n#>                \n#>                 soha nem vesz időnként vesz gyakran vesz\n#>   soha nem vesz             9             1            0\n#>   időnként vesz             1             7            1\n#>   gyakran vesz              0             2            9\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 83.33333\n\nA fenti eredményben láthatjuk, hogy a valódi és a modell alapján becsült csoporttagságok mátrixában a legtöbb adat a főátlóban helyezkedik el. Ez arra utal, hogy a becsült csoporttagságok nagyjából lefedik az eredetit. Ez az arány 83%.\nAz utolsó probléma körében a bio termékek vásárlásának gyakoriságát vizsgáltuk. A kapott eredményeink alapján azok, akik gyakran vásárolnak ilyen termékeket, pozitívabbak értékelik és pozitívabb attitűdökkel rendelkeznek a bio termékek irányában, fiatalabbak, fizetésük viszont alacsonyabb."
  },
  {
    "objectID": "sec_diszkrimninancia.html#példa-vezetési-programok",
    "href": "sec_diszkrimninancia.html#példa-vezetési-programok",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.5 Példa: Vezetési programok",
    "text": "8.5 Példa: Vezetési programok\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nvezetes <- rio::import(file = \"adat/diszkriminancia_vezetesi_program.xlsx\")\nvezetes$SUE <- factor(vezetes$SUE)\nstr(vezetes)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ SUE      : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1...\n#>  $ szelkot  : num  4 4 5 5 3 3 3 5 3 5 ...\n#>  $ elegedett: num  1 3 4 1 2 2 4 2 1 1 ...\n#>  $ rendszer : num  2 1 2 4 4 3 2 3 4 2 ...\npsych::headTail(vezetes)\n#>      SUE szelkot elegedett rendszer\n#> 1      1       4         1        2\n#> 2      1       4         3        1\n#> 3      1       5         4        2\n#> 4      1       5         1        4\n#> ... <NA>     ...       ...      ...\n#> 27     3       1         1        5\n#> 28     3       5         1        4\n#> 29     3       5         1        5\n#> 30     3       5         3        4\n\nVégezzük el a többváltozós variancia elemzést.\n\nman_1 <- manova(cbind(szelkot, elegedett, rendszer) ~ SUE, data = vezetes)\nsummary(man_1, test = \"Wilks\")\n#>           Df  Wilks approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.1894   10.815      6     50 1.102e-07 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary.aov(man_1, test = \"Wilks\")\n#>  Response szelkot :\n#>             Df Sum Sq Mean Sq F value Pr(>F)\n#> SUE          2  2.867  1.4333  1.1057 0.3455\n#> Residuals   27 35.000  1.2963               \n#> \n#>  Response elegedett :\n#>             Df Sum Sq Mean Sq F value   Pr(>F)   \n#> SUE          2 17.267  8.6333  8.4152 0.001444 **\n#> Residuals   27 27.700  1.0259                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#>  Response rendszer :\n#>             Df Sum Sq Mean Sq F value    Pr(>F)    \n#> SUE          2 52.267 26.1333      48 1.287e-09 ***\n#> Residuals   27 14.700  0.5444                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlm_1 <- lm(szelkot ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: szelkot\n#>           Sum Sq Df F value Pr(>F)\n#> SUE        2.867  2  1.1057 0.3455\n#> Residuals 35.000 27\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.9242958\n\nlm_1 <- lm(elegedett ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: elegedett\n#>           Sum Sq Df F value   Pr(>F)   \n#> SUE       17.267  2  8.4152 0.001444 **\n#> Residuals 27.700 27                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.6160119\n\nlm_1 <- lm(rendszer ~ SUE, data = vezetes)\ncar::Anova(lm_1, test.statistic = c(\"Wilks\"))\n#> Anova Table (Type II tests)\n#> \n#> Response: rendszer\n#>           Sum Sq Df F value    Pr(>F)    \n#> SUE       52.267  2      48 1.287e-09 ***\n#> Residuals 14.700 27                      \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 - summary(lm_1)$r.squared  # Wilks lambda\n#> [1] 0.2195122\n\n\nbiotools::boxM(data = vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")], grouping = vezetes$SUE)\n#> \n#>  Box's M-test for Homogeneity of Covariance Matrices\n#> \n#> data:  vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")]\n#> Chi-Sq (approx.) = 19.607, df = 12, p-value = 0.0749\n\n\nlibrary(MASS)\nlda_1 <- lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\nlda_1\n#> Call:\n#> lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\n#> \n#> Prior probabilities of groups:\n#>         1         2         3 \n#> 0.3333333 0.3333333 0.3333333 \n#> \n#> Group means:\n#>   szelkot elegedett rendszer\n#> 1     4.0       2.1      2.7\n#> 2     4.7       3.4      1.5\n#> 3     4.1       1.6      4.7\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1       LD2\n#> szelkot   -0.07056752 0.4959142\n#> elegedett  0.10193972 0.8596451\n#> rendszer  -1.32360357 0.5392379\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9616 0.0384\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\ntab_1 <- table(lda_1_pred$class, vezetes$SUE)\ntab_1\n#>    \n#>      1  2  3\n#>   1  4  1  0\n#>   2  3  9  0\n#>   3  3  0 10\n100 * sum(diag(tab_1))/sum(tab_1)\n#> [1] 76.66667"
  },
  {
    "objectID": "sec_diszkrimninancia.html#megjegyzések",
    "href": "sec_diszkrimninancia.html#megjegyzések",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.6 Megjegyzések",
    "text": "8.6 Megjegyzések\nDiszkriminancia analízis esetén az adatokat nem szükséges standardizálni, ennek oka, hogy az analízis eredményét nem befolyásolja jelentős mértékben az egyes változók mértékegysége.\nA függő változónk tehát kategorikus, a függetlenek pedig numerikusak. Arra vagyunk kíváncsiak, hogy a függő változó által meghatározott csoportok mely független változókban különböznek egymástól, melyek különböztetik meg egy egymástól a függő változó kategóriáit.\nHa a kategorikus függő változónk csupán kétértékű, akkor kétváltozós diszkriminancia elemzésről beszélünk, több szint esetén többváltozós diszkiriminancia elemzésről."
  },
  {
    "objectID": "sec_diszkrimninancia.html#az-alkalmazási-feltételek",
    "href": "sec_diszkrimninancia.html#az-alkalmazási-feltételek",
    "title": "8  Diszkriminancia elemzés",
    "section": "8.7 Az alkalmazási feltételek",
    "text": "8.7 Az alkalmazási feltételek\nA fűggő változó kategorikus két vagy több szinttel. A független változók intervallum vagy arány skálájú változók, de használhatunk dichotóm változókat és a legalább 5 fokú likert skálán mért értékeket is. A függő változó csoportjaiban nagyjából azanosnak kell lennie a csoportnagyságnak, minden csoportnak legalább két adatsort tartalmaznia kell. A mintanagyságra is figyelnünk kell, a független változók számának kisebb kell lenni, mint a legkisebb csoport esetszáma, a teljes mintanagyság legalább 10-szer nagyobb a független változók számánál. A diszkriminancia elemzés feltételezi a független változók közötti lineáris kapcsolatot.\nAz egyváltozós normalitás vizsgálatára a kiugró értékek vizsgálata javasolt, illetve megfelelő mérési skála (például nem dichotóm változó esetén) a Shapiro–Wilk-próbát is használhatjuk. A többváltozós normalitás vizsgálatához\nA csoportok szétválasztásának egyik megközelítése a Mahalanobis-féle távolságot használja. Az eljárás lényege, hogy az \\(m\\) csoportot tartalmazó minta átlagvektorával becsüljük a csoportok valódi átlagvektorát. Az egyes személyek csoportközéptől való átlagát számoljuk ki a Mahalanobis-féle távolsággal, és minden személyt abba a csoportba sorolunk be ez alapján, amelyhez közelebb esik. Ez lehet az a csoport, amelybe a személy valóban beletartozik, de lehet másik is. A helyes besorolások aránya világosan megmutatja, hogy mennyire jól lehet a csoportokat szétválasztani a használt változók alapján.\n\n# remotes::install_github('hyunsooseol/snowCluster')\n\n\nlibrary(snowCluster)\nvallalat <- rio::import(file = \"adat/diszkriminancia_vezetesi_program.sav\")\nsnowCluster::disc(\n    data = vallalat,\n    dep = SUE,\n    covs = vars(szelköt, elégedett, rendszer),\n    gm = TRUE,\n    coef = TRUE,\n    prop = TRUE,\n    tes = TRUE,\n    plot = TRUE,\n    plot1 = TRUE,\n    plot2 = TRUE)\n\n\nstr(vallalat)\nvallalat$SUE <- factor(vallalat$SUE)\n\nlda_1 <- MASS::lda(SUE ~ szelköt + elégedett + rendszer, data = vallalat)\nlda_1\n\nman_1 <- stats::manova(cbind(szelköt, elégedett, rendszer)~SUE, data=vallalat)\nman_1\nsummary(man_1, test=\"Wilks\")\nsummary.aov(man_1)\n\nF <- 1.1057 # F próbastatisztika érték\np <- 1 # függő változók száma\nn <- 30 # mintaelemszám\nk <- 3  # a független változó csoportjainak a száma\n  \nWilks_1 <-  1 / (1 + (F * p) / (n - k - 1 - p))\nWilks_1\n\n 1 - (F / (F + 27))\n\nahol F az F-érték, df1 pedig az első szab\nanova(lm(szelköt~SUE, data=vallalat), test=\"Wilks\")\n\n\nman_1 <- manova(cbind(szelköt, elégedett, rendszer)~SUE, data=vallalat)\nsummary(man_1, test=\"Wilks\")\nsummary(man_1)\n\n\ninstall.packages(\"klaR\")\ngw_1 <- klaR::greedy.wilks(SUE ~ szelköt + elégedett + rendszer, data = vallalat, output=T)\nunclass(gw_1)\nplot(gw_1)\n\njmv::mancova(\n    data = vallalat,\n    deps = vars(szelköt, elégedett, rendszer),\n    factors = SUE,\n    multivar = \"wilks\",\n    boxM = TRUE,\n    shapiro = TRUE)\n\n??'Wilk'\nrrcov::Wilks.test(SUE ~ szelköt + elégedett + rendszer, data = vallalat)\nrrcov::Wilks.test(x = vallalat[2:4], grouping=vallalat$SUE)\n\nlibrary(klaR)\ndata(iris)\nlibrary(MASS)\niris.d <- iris[,1:4]  # the data    \niris.c <- iris[,5]    # the classes \nsc_obj <- stepclass(iris.d, iris.c, \"lda\", start.vars = \"Sepal.Width\")\nsc_obj\nplot(sc_obj)\n\n## or using formulas:\nsc_obj <- stepclass(Species ~ ., data = iris, method = \"qda\", \n    start.vars = \"Sepal.Width\", criterion = \"AS\")  # same as above \nsc_obj\n\n\ndata <- rio::import(file = \"adat/diszkriminancia_alkalmassag.xlsx\")\ndata <- rio::import(file = \"adat/diszkriminancia_baleset.xlsx\")\nsnowCluster::disc(data = data, dep = baleset, covs = vars(megosztott, pontossag,\n    kockazat, eszleles), gm = TRUE, coef = TRUE, prop = TRUE, tra = TRUE,\n    plot = TRUE, plot1 = TRUE, plot2 = TRUE)\n\n\niris\n\n\n\n\n\nsnowCluster::disc(data = iris, dep = Species, covs = vars(Sepal.Length,\n    Sepal.Width, Petal.Length, Petal.Width), gm = TRUE, coef = TRUE, prop = TRUE,\n    tra = TRUE, plot = TRUE, plot1 = TRUE, plot2 = TRUE)"
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#elméleti-háttér",
    "href": "sec_tobbvaltozos_variancia.html#elméleti-háttér",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.1 Elméleti háttér",
    "text": "9.1 Elméleti háttér\nA MANOVA a többváltozós varianciaelemzés angol megfelelőjéből képzett betűszó (Multivariate ANOVA vagy Multivariate Analysis of Variance). A szokásos ANOVA kiterjesztésének tekinthető, ahol nem egy, hanem kettő vagy több függő változóval dolgozhatunk, de a cél ugyanaz: a független változó több csoportja közötti különbségek elemzése.\nFelmerülhet bennünk, hogy ha több függő változónk van, akkor mindegyikre végezzünk el külön egy-egy hagyományos ANOVA-t, azonban ez az elsőfajú hiba emelkedéséhez vezet. A MANOVA olyan megoldást kínál, amivel több függő változó kombinált információi alapján képes kimutatni a csoportkülönbségeket.\nMivel a MANOVA egynél több függő változót használ, a null- és az ellenhipotézisek kissé megváltoznak:\n\n\\(H_0\\): A csoportok várható érték vektorai minden csoportban azonosak.\n\\(H_1\\): A csoportok várható érték vektorainak legalább egyike eltér egy másiktól."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#példa-vezetési-programok",
    "href": "sec_tobbvaltozos_variancia.html#példa-vezetési-programok",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.2 Példa: Vezetési programok",
    "text": "9.2 Példa: Vezetési programok\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer). Vizsgáljuk meg, hogy a SÜE három csoportja azonosnak tekinthető-e a vizsgált 3 kérdésre (szelkot, elegedett és rendszer) adott válaszok tekintetében.\n\nvezetes <- rio::import(file = \"adat/manova_vezetesi_program.xlsx\")\nvezetes$SUE <- factor(vezetes$SUE)\nstr(vezetes)\n#> 'data.frame':    30 obs. of  4 variables:\n#>  $ SUE      : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1...\n#>  $ szelkot  : num  4 4 5 5 3 3 3 5 3 5 ...\n#>  $ elegedett: num  1 3 4 1 2 2 4 2 1 1 ...\n#>  $ rendszer : num  2 1 2 4 4 3 2 3 4 2 ...\npsych::headTail(vezetes)\n#>      SUE szelkot elegedett rendszer\n#> 1      1       4         1        2\n#> 2      1       4         3        1\n#> 3      1       5         4        2\n#> 4      1       5         1        4\n#> ... <NA>     ...       ...      ...\n#> 27     3       1         1        5\n#> 28     3       5         1        4\n#> 29     3       5         1        5\n#> 30     3       5         3        4\n\nMivel a MANOVA a három stratégiai üzleti egységben (SÜE) a kérdőívek pontszámainak (vagyis a függő változók) átlagainak különbségire kérdez rá, így készítsünk dobozdiagramot mindhárom csoportban\n\nlibrary(ggplot2)\np1 <- ggplot(vezetes, aes(x = SUE, y = szelkot, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\np2 <- ggplot(vezetes, aes(x = SUE, y = elegedett, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\np3 <- ggplot(vezetes, aes(x = SUE, y = rendszer, fill = SUE)) + geom_boxplot() +\n    theme(legend.position = \"top\")\ngridExtra::grid.arrange(p1, p2, p3, nrow = 1)\n\n\n\n\nÚgy tűnik, hogy a mindhárom csoport eléggé különbözik egymástól.\nVégezzük el az egyszempontos többváltozós variancia elemzést. A manova() függvény a formula= argumentumában a kettő vagy több numerikus függő változót és legalább egy független változót vár. A függő változókat most a cbind() függvénnyel fűztük egymás mellé, a független változónk pedig a 3 szintű kategorikus SUE.\n\nman_1 <- manova(formula = cbind(szelkot, elegedett, rendszer) ~ SUE, data = vezetes)\nsummary(man_1)\n#>           Df  Pillai approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.90947   7.2278      6     52 1.211e-05 ***\n#> Residuals 27                                             \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAlapértelmezés szerint a MANOVA az R-ben a Pillai-féle tesztstatisztikáit használja. A p-érték gyakorlatilag nulla, ami azt jelenti, hogy nyugodtan elvethetjük a nullhipotézist: legalább egy csoportátlagvektor eltér a többitől.\nHasználhat más teszteket is, mint például a Wilk-lambda, a Roy-féle vagy a Hotelling-Lawley statisztikákat, de a Pillai-féle a legrobusztosabb.\n\nsummary(man_1, test = \"Wilks\")\n#>           Df  Wilks approx F num Df den Df    Pr(>F)    \n#> SUE        2 0.1894   10.815      6     50 1.102e-07 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(man_1, test = \"Hotelling-Lawley\")\n#>           Df Hotelling-Lawley approx F num Df den Df    Pr(>F...\n#> SUE        2           3.7577   15.031      6     48 1.375e-0...\n#> Residuals 27                                                 ...\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(man_1, test = \"Roy\")\n#>           Df    Roy approx F num Df den Df    Pr(>F)    \n#> SUE        2 3.6133   31.315      3     26 8.724e-09 ***\n#> Residuals 27                                            \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA hatásnagyság kiszámítására MANOVA esetében a parciális Eta négyzet \\((\\eta_p^2)\\) mutatót használhatjuk. Azt méri, hogy a független változó milyen hatással van a függő változókra. Ha az érték 0,14 vagy nagyobb, akkor azt mondhatjuk, hogy a hatás mérete nagy. Ez most 0,45, ami azt jelenti, hogy a hatás mérete nagy.\n\neffectsize::eta_squared(man_1, partial = T)\n#> # Effect Size for ANOVA (Type I)\n#> \n#> Parameter | Eta2 (partial) |       95% CI\n#> -----------------------------------------\n#> SUE       |           0.45 | [0.24, 1.00]\n#> \n#> - One-sided CIs: upper bound fixed at [1.00].\neffectsize::interpret_eta_squared(0.45, partial = T)\n#> [1] \"large\"\n#> (Rules: field2013)\n\nMivel a MANOVA szignifikáns lett, további kérdés, hogy melyik csoport átlagvektora különbözik a többitől? Post-hoc tesztet kell végeznünk, amely esetünkben a lineáris diszkriminancia elemzés és az egyváltozós ANOVA lesz."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#post-hoc-teszt-lda",
    "href": "sec_tobbvaltozos_variancia.html#post-hoc-teszt-lda",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.3 Post-hoc teszt: LDA",
    "text": "9.3 Post-hoc teszt: LDA\nA lineáris diszkriminancia elemzés (LDA) célja, hogy változók olyan lineáris kombinációját találja meg, amely a legjobban elválaszt két vagy több csoportot. Ezáltal képesek leszünk egy olyan pontdiagramot megjeleníteni, amely az X és Y tengely két lineáris diszkriminánst jeleníti meg, a pontokat pedig a független változónak (SUE) megfelelően fogjuk színezni.\nA lineáris diszkriminancia elemzést R-ben a {MASS} csomag lda() függvényével végzünk.\n\nlibrary(MASS)\nlda_1 <- lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\nlda_1\n#> Call:\n#> lda(SUE ~ szelkot + elegedett + rendszer, data = vezetes)\n#> \n#> Prior probabilities of groups:\n#>         1         2         3 \n#> 0.3333333 0.3333333 0.3333333 \n#> \n#> Group means:\n#>   szelkot elegedett rendszer\n#> 1     4.0       2.1      2.7\n#> 2     4.7       3.4      1.5\n#> 3     4.1       1.6      4.7\n#> \n#> Coefficients of linear discriminants:\n#>                   LD1       LD2\n#> szelkot   -0.07056752 0.4959142\n#> elegedett  0.10193972 0.8596451\n#> rendszer  -1.32360357 0.5392379\n#> \n#> Proportion of trace:\n#>    LD1    LD2 \n#> 0.9616 0.0384\n# klaR::greedy.wilks(vasarlas~ertek+attitud+fizetes+kor,data=bio,\n# niveau = 0.15)\n\nA fenti együtthatókból megtudhatjuk hogyan használják fel a függő változókat az LDA döntési szabályának kialakítására. Az LD1 a következőképpen számítható ki:\nA vezetes adatmátrix numerikus változóira magunk is kiszámolhatjuk az LD1 és LDA2 értékét a predict() függvénnyel:\n\nlda_1_pred <- predict(lda_1, method = \"plug-in\")\npsych::headTail(lda_1_pred$x)\n#>       LD1   LD2\n#> 1    1.16 -1.83\n#> 2    2.69 -0.65\n#> 3    1.39  1.25\n#> 4   -1.56 -0.25\n#> ...   ...   ...\n#> 27   -2.6  -1.7\n#> 28  -1.56 -0.25\n#> 29  -2.88  0.29\n#> 30  -1.35  1.47\n\nA post-hoc teszt utolsó lépése a fenti a pontdiagram megjelenítése. Ideális esetben egy vagy több csoport kiemelkedik:\n\nd <- data.frame(lda_1_pred$x, SUE = vezetes$SUE)\npsych::headTail(d)\n#>       LD1   LD2  SUE\n#> 1    1.16 -1.83    1\n#> 2    2.69 -0.65    1\n#> 3    1.39  1.25    1\n#> 4   -1.56 -0.25    1\n#> ...   ...   ... <NA>\n#> 27   -2.6  -1.7    3\n#> 28  -1.56 -0.25    3\n#> 29  -2.88  0.29    3\n#> 30  -1.35  1.47    3\n\n\nggplot(d, aes(x = LD1, y = LD2, colour = SUE)) + geom_point(size = 4)\n\n\n\n\nA képen látható, hogy a harmadik SÜE csoport eltér mindkét másik csoporttól, míg a az első két csoport eltérése egymástól nem mondható markánsnak. Könnyen elképzelhető, hogy a SÜE harmadik csoportja volt a legnagyobb hatással a nullhipotézis elutasítására."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#post-hoc-test-egyváltozós-vizsgálatok",
    "href": "sec_tobbvaltozos_variancia.html#post-hoc-test-egyváltozós-vizsgálatok",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.4 Post-hoc test: egyváltozós vizsgálatok",
    "text": "9.4 Post-hoc test: egyváltozós vizsgálatok\nA statisztikailag szignifikáns egyszempontos MANOVA után az egyváltozós egyszempontos ANOVA-val is vizsgálódhatunk, amely minden függő változót külön-külön vizsgál. A cél az, hogy azonosítsuk azokat a konkrét függő változókat, amelyek hozzájárultak a jelentős globális hatáshoz. A klasszikus ANOVA mellett a Welch-féle változat és a Kruskal–Wallis-próba is használható, a feltételek egyre nagyobb csorbulása esetén. Most a nemparaméteres Kruskal–Wallis-próbát használjuk.\n\nkruskal.test(szelkot ~ SUE, data = vezetes)$p.value\n#> [1] 0.2499069\nkruskal.test(elegedett ~ SUE, data = vezetes)$p.value\n#> [1] 0.003003241\nkruskal.test(rendszer ~ SUE, data = vezetes)$p.value\n#> [1] 1.690362e-05\n\nLátjuk, hogy az elegedett és a rendszer függő változókban nem egyeznek a várható értékek a SÜE egyes csoportjaiban. Megjegyezzük, hogy mivel 3 függő változónk van, a Bonferroni-féle többszörös tesztelési korrekciót alkalmaznunk kell, vagyis a statisztikai szignifikancia szintet csökkenteni kell. Ez úgy történik, hogy a klasszikus alfa szintet (0,05) elosztjuk a tesztek (vagy függő változók, itt 3) számával. Ez p < 0,017-es szignifikancia elfogadási kritériumhoz vezet. A fenti próbák szignifikáns voltán ez most nem változtat.\nA statisztikailag szignifikáns egyváltozós ANOVA-t (esetünkben Kruskal–Wallis-próbát) többszörös páronkénti összehasonlítás követi annak meghatározására, hogy mely csoportok különböznek egymástól. Most a Kruskal–Wallis-próba szokásos utóvizsgálatát a Dunn-próbát fogjuk használni.\n\nlibrary(DescTools)\nDunnTest(formula = szelkot ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff   pval    \n#> 2-1            5.6 0.3179    \n#> 3-1            4.0 0.4964    \n#> 3-2           -1.6 0.6442    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDunnTest(formula = elegedett ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff   pval    \n#> 2-1           8.75 0.0410 *  \n#> 3-1          -3.80 0.3143    \n#> 3-2         -12.55 0.0027 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDunnTest(formula = rendszer ~ SUE, data = vezetes, method = \"holm\")\n#> \n#>  Dunn's test of multiple comparisons using rank sums : holm  \n#> \n#>     mean.rank.diff    pval    \n#> 2-1          -6.95  0.0694 .  \n#> 3-1          10.85  0.0092 ** \n#> 3-2          17.80 9.9e-06 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nA fenti utóvizsgálatok világossá teszik, hogy a harmadik SÜE csoport a rendszer változó esetén mindkét másik csoporttól, az elegedett változó esetén pedig a második csoporttól szignifikánsan eltér. Legjelentősebb mértékben tehűt a harmadik csoport különül el a másik két csoporttól, tehát ez okozza a MANOVA nullhipotézisének elvetését."
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#elemzés-jamovi-ban",
    "href": "sec_tobbvaltozos_variancia.html#elemzés-jamovi-ban",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.5 Elemzés jamovi-ban",
    "text": "9.5 Elemzés jamovi-ban\nA fenti elemzés jamovi-ban is elvégezhető az ANOVA / MANCOVA menüpontok kiválasztásával.\n\n\n\nMANOVA jamovi-ban"
  },
  {
    "objectID": "sec_tobbvaltozos_variancia.html#alkalmazási-feltételek-vizsgálata",
    "href": "sec_tobbvaltozos_variancia.html#alkalmazási-feltételek-vizsgálata",
    "title": "9  Többváltozós varianciaelemzés",
    "section": "9.6 Alkalmazási feltételek vizsgálata",
    "text": "9.6 Alkalmazási feltételek vizsgálata\nA MANOVA statisztikai próbának számos szigorú alkalmazási feltétele van. Néhány az ANOVA-ból jön, például a megfigyelések függetlensége vagy a variancia homogenitása, azonban vannak újdonságok is.\n\nMegfelelő mintanagyság. Ökölszabály: a mintaelemszám mindegyik független változó csoportban nagyobb az függő változók számánál.\n\n\nsummarytools::freq(vezetes$SUE, cumul = FALSE)\n#> Frequencies  \n#> vezetes$SUE  \n#> Type: Factor  \n#> \n#>               Freq   % Valid   % Total\n#> ----------- ------ --------- ---------\n#>           1     10     33.33     33.33\n#>           2     10     33.33     33.33\n#>           3     10     33.33     33.33\n#>        <NA>      0                0.00\n#>       Total     30    100.00    100.00\n\nLátható, hogy a függő változók számát (3) minden csoport elemszáma (10) meghaladja.\n\nA megfigyelések függetlensége. Minden személynek csak egy csoportba kell tartoznia. Az egyes csoportok megfigyelései között nincs kapcsolat. Az ismételt mérések nem megengedettek. A minta kiválasztásának teljesen véletlenszerűnek kell lennie.\nAz egyváltozós vagy többváltozós kiugró értékek hiánya.\n\nAz egydimenziós kiugró értékek dobozdiagramokkal is ellenőrizhetők, ezt korábban elvégeztük, láttuk csak egyetlen részcsoportban van kiugró értékek (a szelkot változó változó esetén a SÜE harmadik csoportjában). Használhatjuk a kényelmes rstatix::identify_outliers() függvényt is.\n\nlibrary(tidyverse)\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(szelkot)\n#> # A tibble: 2 × 6\n#>   SUE   szelkot elegedett rendszer is.outlier is.extreme\n#>   <fct>   <dbl>     <dbl>    <dbl> <lgl>      <lgl>     \n#> 1 3           1         1        5 TRUE       TRUE      \n#> 2 3           1         1        5 TRUE       TRUE\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(elegedett)\n#> [1] SUE        szelkot    elegedett  rendszer   is.outlier\n#> [6] is.extreme\n#> <0 rows> (or 0-length row.names)\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::identify_outliers(rendszer)\n#> [1] SUE        szelkot    elegedett  rendszer   is.outlier\n#> [6] is.extreme\n#> <0 rows> (or 0-length row.names)\n\nA többváltozós kiugró értékek olyan adatpontok, amelyek szokatlan értékkombinációt tartalmaznak a kimeneti (vagy függő) változókon. A Mahalanobis távolságot általában a többváltozós kiugró értékek észlelésére használják. A távolság megmondja, milyen messze van egy megfigyelés a felhő középpontjától, figyelembe véve a felhő alakját (kovariancia) is. A rstatix::mahalanobis_distance() függvény könnyen használható a Mahalanobis-távolság kiszámítására és a többváltozós kiugró értékek megjelölésére. A Mahalanobis-távolságot csoportonként kell kiszámítani:\n\nvezetes %>%\n    group_by(SUE) %>%\n    rstatix::mahalanobis_distance() %>%\n    filter(is.outlier == TRUE) %>%\n    as.data.frame()\n#> [1] szelkot    elegedett  rendszer   mahal.dist is.outlier\n#> <0 rows> (or 0-length row.names)\n\nLátható, hogy nincs többváltozós kiugró érték az adatbázisban.\n\nTöbbváltozós normalitás.\n\nA többváltozós normalitás Shapiro-Wilk tesztjének végrehajtása:\n\nrstatix::mshapiro_test(vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")])\n#> # A tibble: 1 × 2\n#>   statistic   p.value\n#>       <dbl>     <dbl>\n#> 1     0.772 0.0000214\n\nLátható, hogy ez az alkalmazási feltétel nem teljesül.\nAz egyváltozós normalitásokat is érdemes lehet tesztelni:\n\n# egyváltozós Shapiro–Wilk próba több csoportra\nlibrary(onewaytests)\nnor.test(formula = szelkot ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : szelkot and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.7685823 6.009970e-03      Reject\n#> 2     2 0.5941735 4.713464e-05      Reject\n#> 3     3 0.5876023 3.936679e-05      Reject\n#> --------------------------------------------------\nnor.test(formula = elegedett ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : elegedett and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.8236140 2.802300e-02      Reject\n#> 2     2 0.7172415 1.425861e-03      Reject\n#> 3     3 0.5941735 4.713464e-05      Reject\n#> --------------------------------------------------\nnor.test(formula = rendszer ~ SUE, data = vezetes, method = \"SW\")\n#> \n#>   Shapiro-Wilk Normality Test (alpha = 0.05) \n#> -------------------------------------------------- \n#>   data : rendszer and SUE \n#> \n#>   Level Statistic      p.value   Normality\n#> 1     1 0.8737456 1.105101e-01  Not reject\n#> 2     2 0.6552710 2.539627e-04      Reject\n#> 3     3 0.5941735 4.713464e-05      Reject\n#> --------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\nA multikollinearitás hiánya. A függő (eredmény) változók nem korrelálhatnak túlságosan egymással. Egyetlen korreláció sem lehet r = 0,90 feletti.\n\nIdeális esetben az eredményváltozók közötti korreláció mérsékelt, nem túl magas. A 0,9 feletti korreláció a multikollinearitást jelzi, ami a MANOVA esetében problematikus. Másrészt, ha a korreláció túl alacsony, fontolóra kell vennie külön egyszempontos ANOVA futtatását minden függő változóra.\nSzámítsuk ki a páronkénti Pearson-korrelációs együtthatókat a függő változók között.\n\ncor(vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")])\n#>              szelkot  elegedett   rendszer\n#> szelkot    1.0000000  0.1954881 -0.2528624\n#> elegedett  0.1954881  1.0000000 -0.6129079\n#> rendszer  -0.2528624 -0.6129079  1.0000000\n\nLátható, hogy a korrelációs együtthatók nem támogatják a multikollinearitás tényét.\n\nLinearitás az összes függő változó között minden csoportban.\n\nMivel a függő változók közötti páronkénti kapcsolatnak lineárisnak kell lennie minden csoport esetében, ezért érdemes ezt a feltételt vizuálisan ellenőrizni. A {GGally} csomag ggpairs() függvényét használhatjuk.\n\nlibrary(GGally)\nres <- vezetes %>%\n    select(SUE, szelkot, elegedett, rendszer) %>%\n    group_by(SUE) %>%\n    rstatix::doo(~ggpairs(.) + theme_bw(), result = \"plots\")\nres$plots\n#> [[1]]\n#> \n#> [[2]]\n#> \n#> [[3]]\n\n\n\n\n\n\n\n\n\n\nA fenti ábrák megkérdőjelezik a páronkénti lineáris kapcsolatok létezését.\n\nA varianciák homogenitása. A Levene-próba használható a csoportok közötti varianciák egyenlőségének tesztelésére. A Levene-próba nem szignifikáns értékei a varianciák homogenitását támogatják.\n\nAz egyszempontos MANOVA mindegyik függő változó esetében azt feltételezi, hogy a csoportok között egyenlők a varianciák.\n\nDescTools::LeveneTest(szelkot ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  2  0.9755 0.3899\n#>       27\nDescTools::LeveneTest(elegedett ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  2  0.4112  0.667\n#>       27\nDescTools::LeveneTest(rendszer ~ SUE, data = vezetes)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value   Pr(>F)   \n#> group  2     5.6 0.009238 **\n#>       27                    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLátható, hogy a szóráshomogenitás a rendszer változó kivételével teljesül.\n\nVariancia-kovariancia mátrixok homogenitása. A BoxM-próba használható a csoportok közötti kovariancia egyenlőségének ellenőrzésére. Ez egyenértékű a variancia többváltozós homogenitásával. Ez a teszt rendkívül érzékenynek tekinthető. Ezért ennek a tesztnek a szignifikanciáját alfa = 0,001 értéknél határozzuk meg. A {biotools} csomag megvalósított boxM() függvényét használhatjuk.\n\n\nbiotools::boxM(data = vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")], grouping = vezetes$SUE)\n#> \n#>  Box's M-test for Homogeneity of Covariance Matrices\n#> \n#> data:  vezetes[c(\"szelkot\", \"elegedett\", \"rendszer\")]\n#> Chi-Sq (approx.) = 19.607, df = 12, p-value = 0.0749\n\nA teszt statisztikailag nem szignifikáns (azaz p > 0,001), tehát az adatok nem sértették meg a variancia-kovariancia mátrixok homogenitásának feltételezését.\nKiegyensúlyozott a csoportelemszámok esetén nem probléma a variancia-kovariancia mátrixok homogenitásának megsértése miatt, de kiegyensúlyozatlan kialakításnál már problémás lehet."
  },
  {
    "objectID": "sec_logisztikus_regresszio.html",
    "href": "sec_logisztikus_regresszio.html",
    "title": "10  Logisztikus regresszió",
    "section": "",
    "text": "A logisztikus regresszió céljait tekintve megegyezik a diszkriminancia elemzéssel, de sokkal robusztusabb, azaz kevesebb alkalmazási feltétellel rendelkezik. Használható a logisztikus regresszió akkor is, ha a független változók között kategorikus változók is előfordulnak, illetve a normalitásra és homoszkedaszticitásra vonatkozó feltétel megsértésre sem érzékeny a módszer.\nJÖN."
  },
  {
    "objectID": "sec_tobbdimenzios_skalazas.html",
    "href": "sec_tobbdimenzios_skalazas.html",
    "title": "11  Többdimenziós skálázás",
    "section": "",
    "text": "JÖN."
  },
  {
    "objectID": "appendix_linkek.html",
    "href": "appendix_linkek.html",
    "title": "Appendix A — Elérhető videók",
    "section": "",
    "text": "Alapozo jamovi és R videók\n\nJamovi a gyakorlatban\nR a gyakorlatban\n\nJamovi tutorial videók az összes tanult eljáráshoz\n\ndatalab.cc\nAlexander Swan\n\nLineáris regresszió\n\nThe linear regression model\nLinear Regression, Clearly Explained\nR-squared, Clearly Explained\nSimple linear regression in Jamovi\n\nFőkomponens elemzés\n\nPrincipal Component Analysis (PCA)\n\nKlaszterelemzés\n\nFlat and Hierarchical Clustering | The Dendrogram Explained\nK Means Clustering: Pros and Cons of K Means Clustering\nHierarchical Cluster analysis in Jamovi\nK Means Cluster analysis in Jamovi\n\nTöbbszempontos varianciaelemzés\n\nOne Way ANOVA Post hoc test in Jamovi\nOne Way Repeated Measure ANOVA Repeated Measure ANOVA Within Subject ANOVA in Jamovi\nTwo Way ANOVA Post hoc test in Jamovi\nThree Way ANOVA Post hoc test in Jamovi"
  },
  {
    "objectID": "appendix_adatbazisok.html#megbízhatóság-elemzés",
    "href": "appendix_adatbazisok.html#megbízhatóság-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.1 Megbízhatóság elemzés",
    "text": "B.1 Megbízhatóság elemzés\n\nmegbizhatosag_tantargyak.xlsx - fiktív adatbázis 9 tanuló iskolai jegyeivel (Münnich és mtsai. (2006), 2.2. táblázat)\n\nAz adatbázis szerkezete:\n\nmatek - matematika érdemjegy (numerikus: 1-5)\nfizika - fizika érdemjegy (numerikus: 1-5)\ninformatika - informatika érdemjegy (numerikus: 1-5)\nkemia - kémia érdemjegy (numerikus: 1-5)\n\nKapcsolódó állományok:\n\nmegbizhatosag_tantargyak.omv - megbízhatóság elemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#többváltozós-varianciaelemzés",
    "href": "appendix_adatbazisok.html#többváltozós-varianciaelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.2 Többváltozós varianciaelemzés",
    "text": "B.2 Többváltozós varianciaelemzés\n\nmanova_vezetesi_program.xlsx - A szervezeti elkötelezettség, a szervezeti kultúra és az elégedettség eltér a vállalat 3 különböző vezetési irányelvét valló egységében? Az adatbázis Sajtos és Mitev (2007, o. 332) könyvéből származik.\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nAz adatbázis szerkezete:\n\nSUE - a három különböző vezetési irányelvet követő stratégiai üzleti egység (nominális: 1-3)\nszelkot - szervezet elkötelezettség mértéke (likert: 1-5)\nelegedett - szervezettel való elégedettség (likert: 1-5)\nrendszer - szervezet tekintélyelvű jellege (likert: 1-5)\n\nKapcsolódó állományok:\n\nmanova_vezetesi_program.omv - Többváltozós varianciaelemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#diszkriminancia-elemzés",
    "href": "appendix_adatbazisok.html#diszkriminancia-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.3 Diszkriminancia elemzés",
    "text": "B.3 Diszkriminancia elemzés\n\ndiszkriminancia_alkalmassag.xlsx - szalagmunkások adatai (Münnich és mtsai. (2006), 4.1. táblázat)\n\nAz adatbázis szerkezete:\n\nbevalt - a munkás beválásával kapcsolatos információ: bevált? (nominális: “igen”, “nem”)\nfigyelem - a munkás figyelmi képessége (likert: 1-7, a magasabb érték jobb képességeket jelent)\nmonotonia_tures - a munkás monotónia tűrése (likert: 1-7, a magasabb érték jobb képességeket jelent)\n\n\ndiszkriminancia_baleset.xlsx - mely tényezők járulnak hozzá a balesetekhez (Münnich és mtsai. (2006), 4.11. R-forráskód)\n\nAz adatbázis szerkezete:\n\nbaleset - volt már balesete a személynek vagy sem (nominális “nem volt balesete”, “volt baleste”)\nmegosztott - megosztott figyelem (intervallum/arány)\npontossag - a figyelem pontossága (intervallum/arány)\nkockazat - kockázatvállalási hajlandóság (intervallum/arány)\neszleles - észlelés gyorsasága (intervallum/arány)\n\n\ndiszkriminancia_depresszio.xlsx - a postpartum depresszió pszichés és szociális háttere (Münnich és mtsai. (2006), 4.16. R-forráskód)\n\nAz adatbázis szerkezete:\n\nppdepresszio - szülés utáni depresszió jelenléte (nominális: “nincs depresszió”, “van depresszió”)\nszeretet - a személyek mennyire érzik, hogy a szüleik szeretik őket (intervallum/arány)\ntulvedes - mennyire hajlamosak arra a személyek, hogy túlságosan is burokban tartsák, túlvédjék gyerekeiket (intervallum/arány)\nkor - életkor (intervallum/arány)\niskola - az elvégzett iskolai osztályok száma (intervallum/arány)\n\n\ndiszkriminancia_pszichoszomatika.xlsx - a pszichoszomatikus megbetegedéseket vizsgálata (Münnich és mtsai. (2006), 4.21. R-forráskód)\n\nAz adatbázis szerkezete:\n\npszichoszomatika - van valamilyen pszichoszomatikus megbetegedése a személynek? (nominális: “szichoszomatikus megbetegedése van”, ” egészséges”)\nstressz - a személyt ért stressz mértéke (intervallum/arány)\nszorongas - a szorongási szintje (intervallum/arány)\ncoping - a megküzdési stratégiáinak hatékonysága (intervallum/arány)\n\n\ndiszkriminancia_bio.xlsx - kik vásárolnak bio termékeket (Münnich és mtsai. (2006), 4.26. R-forráskód)\n\nAz adatbázis szerkezete:\n\nvasarlas - a biotermékek vásárlásának gyakorisága (ordinális: “soha nem vesz”, “időnként vesz”, “gyakran vesz”)\nertek - minél nagyobb pontszámot kap a skálán, annál jobban értékeli a személy a bio termékeket (intervallum/arány)\nattitud - a magasabb értékek kedvezőbb atttitűdöt jelez a biotermékek iránt (intervallum/arány)\nfizetes - a személy fizetésének nagysága (intervallum/arány)\nkor - a személy életkora(intervallum/arány)\n\n\ndiszkriminancia_vezetesi_program.xlsx - A szervezeti elkötelezettség, a szervezeti kultúra és az elégedettség alapján szétválasztható a vállalat 3 különböző vezetési irányelvét valló egysége? Az adatbázis Sajtos és Mitev (2007, o. 332) könyvéből származik.\nEgy vállalat menedzsmentje szeretné megvizsgálni különböző vezetési programok hatását, ezért három különböző vezetési programot vezetett be három különböző stratégiai üzleti egységben (SÜE). Az első SÜE-ben bevezetett program az egyenlőséget és az individualizmust hangsúlyozta. A második SÜE-ben az egyenlőséget és a csoportmunkát helyzeték középpontba. A harmadik SÜE-ben a bevezetett program egy nagyon hierarchikus vezetési elvet alkalmazott. Később mindhárom SÜE dolgozóinak körében felmérést végeztek, és a kérdések között szerepelt a szervezettel való elkötelezettség mértéke (szelkot), a szervezettel való elégedettség nagysága (elegedett), illetve a rendszer egalitárius vagy tekintélyelvű (autokrata) jellege (rendszer).\n\nAz adatbázis szerkezete:\n\nSUE - a három különböző vezetési irányelvet követő stratégiai üzleti egység (nominális: 1-3)\nszelkot - szervezet elkötelezettség mértéke (likert: 1-5)\nelegedett - szervezettel való elégedettség (likert: 1-5)\nrendszer - szervezet tekintélyelvű jellege (likert: 1-5)\n\nKapcsolódó állományok:\n\ndiszkriminancia_vezetesi_program.omv - diszkriminancia elemzés jamovi-ban"
  },
  {
    "objectID": "appendix_adatbazisok.html#lineáris-regresszió",
    "href": "appendix_adatbazisok.html#lineáris-regresszió",
    "title": "Appendix B — Adatbázisok",
    "section": "B.4 Lineáris regresszió",
    "text": "B.4 Lineáris regresszió\n\nlin_reg_fizetes_elegedettseg_01.omv - konstans oszlopokkal nem tudunk számolni (Münnich és mtsai. (2006) 1.1/A táblázat)\nlin_reg_fizetes_elegedettseg_02.omv- az adatpontok szinte tökéletesen az egyenesre illeszkednek (Münnich és mtsai. (2006) 1.1/B táblázat)\nlin_reg_kapcsolatok_01.omv - nem szisztematikus kapcsolat két változó között (Münnich és mtsai. (2006) 1.5. R-forráskód)\nlin_reg_kapcsolatok_02.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.6. R-forráskód)\nlin_reg_kapcsolatok_03.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.7. R-forráskód)\nlin_reg_kapcsolatok_04.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.8. R-forráskód)\nlin_reg_kapcsolatok_05.omv - szisztematikus (függvényszerű) kapcsolat két változó között (Münnich és mtsai. (2006) 1.9. R-forráskód)\nlin_reg_elegedttseg.omv - a fizetés és a munkahellyel való elégedettség pontdiagramja, egyszerű lineáris regresszió (Münnich és mtsai. (2006) 1.10 R-forráskód)\nlin_reg_fizetes_eletkor_eledettseg_01.omv - többszörös lineáris regresszió, 2 numerikus magyarázó változó (Münnich és mtsai. (2006) 1.2. táblázat)\nlin_reg_intelligencia_testmagassag_eletkor_01.omv - többszörös lineáris regresszió, 2 numerikus magyarázó változó, parciális korreláció magyarázata\n\nminél magasabb valaki, annál intelligensebb\nha bevonjuk az életkor változót, akkor eltűnik az intelligencia és a testmagasság közötti kapcsolat\n\nlin_tizproba.omv - többszörös lineáris regresszió, a legjobb modell keresése, sok numerikus magyarázó változó\nlin_college_success_02.omv - többszörös lineáris regresszió, sok numerikus magyarázó változó, GPA a függő változó, mi magyarázza az egyetemi teljesítményt\nlin_reg_elegedttseg_02.omv - A férfiak vagy a nők elégedettebbek a munkahelyükkel? (Münnich és mtsai. (2006) 1.6.3 probléma), egyetlen kategorikus magyarázó változó 2 értékkel (nem: férfi, nő)\n\nkapcsolat a kétmintás t-próbával\n\nlin_reg_magassag_hajhossz_nem_01.omv - többszörös lineáris regresszió, parciális korreláció 1 numerikus és 1 kategorikus változóval (Münnich és mtsai. (2006) 1.2. táblázat)\n\na testmagasság és a hajhossz között kapcsolat van\nha a személyek nemét is figyelembe vesszük, egyáltalán nincs kapcsolat a testmagasság és a hajhosszúság között\n\nlin_auction.omv - többszörös lineáris regresszió, Simpson paradoxon, párhuzamos regresszió, majd interakció bevonása."
  },
  {
    "objectID": "appendix_adatbazisok.html#főkomponens-elemzés",
    "href": "appendix_adatbazisok.html#főkomponens-elemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.5 Főkomponens elemzés",
    "text": "B.5 Főkomponens elemzés\n\nfokomp_elemzes_tantargyak.omv - 1 főkomponens létrehozása (Münnich és mtsai. (2006) 2.2. táblázat)\nfokomp_real_targyak.omv - példa kidolgozása, 1 főkomponens(Münnich és mtsai. (2006) 2.5.1 Probléma)\nfokomp_kerdoivtervezet.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.2 Probléma)\nfokomp_munkahelyi_tolarencia.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.3 Probléma)\nfokomp_munkahelyi_elegedettseg.omv - példa kidolgozása (Münnich és mtsai. (2006) 2.5.4 Probléma)"
  },
  {
    "objectID": "appendix_adatbazisok.html#faktorelemzés",
    "href": "appendix_adatbazisok.html#faktorelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.6 Faktorelemzés",
    "text": "B.6 Faktorelemzés\n\nfaktor_szorongas.omv - példa (Münnich és mtsai. (2006) 3.1. R-forráskód)\nfaktor_real_human_targyak.omv - példa (Münnich és mtsai. (2006) 3.9. R-forráskód)\nfaktor_bigfive.omv - példa (Münnich és mtsai. (2006) 3.21. R-forráskód)\nfaktor_kockazat.omv - példa (Münnich és mtsai. (2006) 3.7.4 Probléma)\nfaktor_fogkrem.omv - példa (Malhotra és Simon (2008) 617. oldal)"
  },
  {
    "objectID": "appendix_adatbazisok.html#feltáró-faktorelemzés",
    "href": "appendix_adatbazisok.html#feltáró-faktorelemzés",
    "title": "Appendix B — Adatbázisok",
    "section": "B.7 Feltáró faktorelemzés",
    "text": "B.7 Feltáró faktorelemzés\n\nfaktor_fogkrem.xlsx - A kutató arra volt kíváncsi, milyen előnyöket keresnek a fogyasztók a fogrémvásárlásnál. Egy 30 fős mintán a válaszadókat arra kérték, hogy jelezzék, mennyire értenek egyet a következő állításokkal (1 = egyáltalán nem ért egyet; 7 = teljes mértékben egyetért)\n\nAz adatbázis szerkezete:\n\nsorszam: válaszadó sorszáma (id)\nv1: Fontos, hogy olyan fogkrémet vásároljak, amellyel megelőzhető a fogszuvasodás. (likert: 1-7)\nv2: Az olyan fogkrémeket szeretem, amely fényessé teszi a fogaimat. (likert: 1-7)\nv3: Egy fogkrémnek erősítenie kell a fogínyt. (likert: 1-7)\nv4: Az olyan fogkrémeket szeretem, amely friss leheletet biztosít. (likert: 1-7)\nv5: A fog romlásának megelőzése számomra nem fontos elvárás. (likert: 1-7)\nv6: A legfontosabb szempont a fogkrém vásárlásánál a szép fog. (likert: 1-7)\n\nKapcsolódó állományok:\n\nefa_fogkrem.omv - Feltáró faktorelemzés jamovi-ban\n\n\n\n\n\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás. Akadémiai Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika pszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési kézikönyv. Alinea Kiadó."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Appendix C — Irodalomjegyzék",
    "section": "",
    "text": "Carver, C. S. és Scheier, M. F. (2006).\nSzemélyiségpszichológia. Osiris Kiadó.\n\n\nCsallner, A. E. (2015). Bevezetés az SPSS statisztikai programcsomag\nhasználatába. http://www.jgypk.hu/tamop15e/tananyag_html/spss/index.html\n\n\nHorn, J. L. (1965). A rationale and test for the number of factors in\nfactor analysis. Psychometrika, 30, 179–185. https://doi.org/10.1007/BF02289447\n\n\nKárász, J. T., Nagy, O. N., Széll, K. és Takács, S. (2022).\nCronbach-alfa: vele vagy nélküle? Magyar Pszichológiai Szemle,\n77, 81–98. https://doi.org/10.1556/0016.2022.00004\n\n\nKetskeméty, L. és Izsó, L. (2005). Bevezetés az SPSS\nprogramrendszerbe - Módszertani útmutató és feladatgyűjtemény\nstatisztikai elemzésekhez. ELTE Eötvös Kiadó.\n\n\nMalhotra, N. K. és Simon, J. (2008). Marketingkutatás.\nAkadémiai Kiadó.\n\n\nMalkewitz, C. P., Schwall, P., Meesters, C. és Hardt, J. (2023).\nEstimating reliability: A comparison of Cronbach’s α, McDonald’s ωt and\nthe greatest lower bound. Social Sciences & Humanities\nOpen, 7, 100368. https://doi.org/10.1016/j.ssaho.2022.100368\n\n\nMoksony, F. (2006). Gondolatok és adatok. Társadalomtudományi\nelméletek empirikus ellenőrzése. Aula Kiadó.\n\n\nMünnich, Á., Nagy, Á. és Abari, K. (2006). Többváltozós statisztika\npszichológus hallgatók számára. Bölcsész Konzorcium. http://psycho.unideb.hu/statisztika\n\n\nNagy, O. N. (2006). A pszichológiai tesztek reliabilitása. In S. Rózsa,\nO. N. Nagy, és A. Oláh (Szerk.), A pszichológiai mérés alapjai.\nElmélet, módszer és gyakorlati alkalmazás. Bölcsész Konzorcium. https://mek.oszk.hu/05500/05536/05536.pdf\n\n\nRózsa, S., Hupuczi, E., Martin, L., Birkás, B., Hartung, I., Hargitai,\nR., Varga, J., Láng, A., Tiringer, I. és Kállai, J. (2019). A Tellegen\nAbszorpciós Skála részletes pszichometriai elemzése. Mentálhigiéné\nés Pszichoszomatika, 20, 35–77. https://doi.org/10.1556/0406.20.2019.003\n\n\nSajtos, L. és Mitev, A. (2007). SPSS kutatási és adatelemzési\nkézikönyv. Alinea Kiadó.\n\n\nSzékelyi, M. és Barna, I. (2002). Túlélőkészlet az SPSS-hez.\nTöbbváltozós elemzési technikáról társadalomkutatók számára.\nTypotex Kiadó.\n\n\nTakács, S. (2017). Bevezetés a matematikai statisztikába 2.\nTöbbváltozós statisztikai módszerek. Antarész Kiadó.\n\n\nVarga, A. (2019). Többváltozós statisztika dióhéjban:\nVáltozó-orientált módszerek. Pólya Kiadó.\n\n\nWatkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best\nPractice. Journal of Black Psychology, 44, 219–246. https://doi.org/10.1177/0095798418771807"
  }
]